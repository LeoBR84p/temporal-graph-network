{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqpYiRa1Ub5T"
   },
   "source": [
    "#**Licen√ßa de Uso**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsA_nGhh8Psj"
   },
   "source": [
    "This repository uses a **dual-license model** to distinguish between source code and creative/documental content.\n",
    "\n",
    "**Code** (Python scripts, modules, utilities):\n",
    "Licensed under the MIT License.\n",
    "\n",
    "‚Üí You may freely use, modify, and redistribute the code, including for commercial purposes, provided that you preserve the copyright notice.\n",
    "\n",
    "**Content** (Jupyter notebooks, documentation, reports, datasets, and generated outputs):\n",
    "Licensed under the Creative Commons Attribution‚ÄìNonCommercial 4.0 International License.\n",
    "\n",
    "‚Üí You may share and adapt the content for non-commercial purposes, provided that proper credit is given to the original author.\n",
    "\n",
    "\n",
    "**¬© 2025 Leandro Bernardo Rodrigues**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyszD9eYTtAS"
   },
   "source": [
    "#**Pr√©-Configura√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX0x9aXfTJeA"
   },
   "source": [
    "##**C√≥digo de uso √∫nico**\n",
    "Aplica√ß√£o persistente entre sess√µes do Google Colab\n",
    "\n",
    "---\n",
    "**Uso expec√≠fico para Google Colab.**\n",
    "\n",
    "**Aviso:** implementa√ß√£o no JupytherHub e GitLab s√£o diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "otaQwrjJSgOQ"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#montar o Google Drive e preparar a pasta do projeto\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os, subprocess, getpass, pathlib\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "%cd \"$BASE\"\n",
    "\n",
    "#clonar o reposit√≥rio existente do GitHub (se ainda n√£o estiver clonado) ===\n",
    "if not os.path.exists(PROJ):\n",
    "    GITHUB_URL = \"https://github.com/LeoBR84p/temporal-graph-network.git\"\n",
    "    # Dica: use PAT quando o push for necess√°rio; para clone p√∫blico basta a URL.\n",
    "    !git clone $GITHUB_URL\n",
    "else:\n",
    "    print(\"Pasta do projeto j√° existe, seguindo adiante...\")\n",
    "%cd \"$PROJ\"\n",
    "\n",
    "#criar pastas utilit√°rias que voc√™ quer manter no projeto ===\n",
    "#n√£o sobrescreve nada; s√≥ cria se n√£o existirem\n",
    "!mkdir -p notebooks src data output runs configs\n",
    "\n",
    "#instalar pacotes (na sess√£o atual) para conseguir configurar os filtros ===\n",
    "!pip -q install jupytext nbdime nbstripout\n",
    "\n",
    "#configurar Git/NBDime/Jupytext no *reposit√≥rio* (persistem em .git/config) ===\n",
    "#usar --local faz a config ficar gravada em .git/config (persiste no Drive)\n",
    "!git config --local user.name \"Leandro Bernardo Rodrigues\"\n",
    "!git config --local user.email \"bernardo.leandro@gmail.com\"\n",
    "!git config --local init.defaultBranch main\n",
    "\n",
    "# OBS: no Colab, o nbdime com --local pode falhar; use --global nesta sess√£o\n",
    "!nbdime config-git --enable --global\n",
    "\n",
    "#.gitignore e .gitattributes (s√≥ criar se n√£o existirem) ===\n",
    "if not pathlib.Path(\".gitignore\").exists():\n",
    "    with open(\".gitignore\",\"w\") as f:\n",
    "        f.write(\"\"\"\\\n",
    ".ipynb_checkpoints/\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "*.log\n",
    "*.tmp\n",
    "# dados/artefatos pesados (n√£o versionar)\n",
    "data/\n",
    "output/\n",
    "runs/\n",
    "# Python\n",
    "venv/\n",
    "__pycache__/\n",
    "*.pyc\n",
    "# segredos\n",
    ".env\n",
    "*.key\n",
    "*.pem\n",
    "*.tok\n",
    "\"\"\")\n",
    "if not pathlib.Path(\".gitattributes\").exists():\n",
    "    with open(\".gitattributes\",\"w\") as f:\n",
    "        f.write(\"*.ipynb filter=nbstripout\\n\")\n",
    "\n",
    "#ativar o hook do nbstripout neste reposit√≥rio (persiste)\n",
    "!nbstripout --install --attributes .gitattributes\n",
    "\n",
    "#parear notebooks com .py para diffs leg√≠veis ===\n",
    "!jupytext --set-formats ipynb,py:percent --sync notebooks/*.ipynb || true\n",
    "\n",
    "#commit inicial dessas configs locais (se houver algo novo) e push ===\n",
    "!git add -A\n",
    "!git status\n",
    "!git commit -m \"chore: setup local (.gitignore/.gitattributes, nbstripout, jupytext config)\" || true\n",
    "\n",
    "#se o remoto j√° tem README/commits, fa√ßa pull --rebase antes do primeiro push\n",
    "!git pull --rebase origin main || true\n",
    "\n",
    "#push (ao pedir senha, use seu PAT como senha do Git)\n",
    "import getpass, subprocess, sys\n",
    "\n",
    "owner = \"LeoBR84p\"\n",
    "repo  = \"temporal-graph-network\"\n",
    "clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "\n",
    "# 1) Tenta push \"normal\" (pode falhar por falta de credencial)\n",
    "push = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "if push.returncode == 0:\n",
    "    print(\"Push conclu√≠do sem PAT.\")\n",
    "else:\n",
    "    print(\"Primeiro push falhou (prov√°vel falta de credenciais). Vamos usar um PAT tempor√°rio‚Ä¶\")\n",
    "    # 2) Pede o PAT e testa autentica√ß√£o antes do push\n",
    "    token = getpass.getpass(\"Cole seu GitHub PAT (n√£o ser√° exibido): \").strip()\n",
    "    # Formato mais compat√≠vel: user + token na URL\n",
    "    # Use seu usu√°rio real do GitHub (case sensitive)\n",
    "    username = \"LeoBR84p\"\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "\n",
    "    try:\n",
    "        # Teste r√°pido de auth (ls-remote) para ver se o token tem acesso de escrita\n",
    "        test = subprocess.run([\"git\",\"ls-remote\", auth_url],\n",
    "                              capture_output=True, text=True)\n",
    "        if test.returncode != 0:\n",
    "            print(\"Falha ao autenticar com o PAT. Detalhe do erro:\")\n",
    "            print(test.stderr or test.stdout)\n",
    "            raise SystemExit(1)\n",
    "\n",
    "        # 3) Troca a URL, faz push e restaura a URL limpa\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"Falha no push mesmo com PAT. Detalhe do erro:\")\n",
    "            print(out.stderr or out.stdout)\n",
    "            raise SystemExit(out.returncode)\n",
    "        print(\"Push conclu√≠do com PAT.\")\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", clean_url], check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYTsrVeiUEYt"
   },
   "source": [
    "##**C√≥digo a cada sess√£o**\n",
    "---\n",
    "Aplica√ß√£o n√£o persistente entre sess√µes.\n",
    "\n",
    "Necess√°rio para sincroniza√ß√£o e versionamento de altera√ß√µes no c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUkAzsYgCRv"
   },
   "source": [
    "###**Montar e sincronizar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45427,
     "status": "ok",
     "timestamp": 1759620356447,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "2aoXCRgAUYod",
    "outputId": "305f1e1f-91f8-4237-e00d-746342496f67"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#setup por sess√£o (colab)\n",
    "from google.colab import drive\n",
    "import os, time, subprocess, getpass, pathlib, sys\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "\n",
    "def safe_mount_google_drive():\n",
    "    #monta ou remonta o google drive de forma resiliente\n",
    "    try:\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "    except Exception:\n",
    "        try:\n",
    "            drive.flush_and_unmount()\n",
    "        except Exception:\n",
    "            pass\n",
    "        time.sleep(1.0)\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "def safe_chdir(path):\n",
    "    #usa os.chdir (evita %cd com f-string)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Caminho n√£o existe: {path}\")\n",
    "    os.chdir(path)\n",
    "    print(\"Diret√≥rio atual:\", os.getcwd())\n",
    "\n",
    "def branch_a_frente():\n",
    "    #retorna true se head est√° √† frente do upstream (h√° o que enviar)\n",
    "    ahead = subprocess.run(\n",
    "        [\"git\",\"rev-list\",\"--left-right\",\"--count\",\"HEAD...@{upstream}\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if ahead.returncode != 0:\n",
    "        status = subprocess.run([\"git\",\"status\",\"-sb\"], capture_output=True, text=True)\n",
    "        return \"ahead\" in (status.stdout or \"\")\n",
    "    left_right = (ahead.stdout or \"\").strip().split()\n",
    "    return len(left_right) == 2 and left_right[0].isdigit() and int(left_right[0]) > 0\n",
    "\n",
    "def push_seguro(owner=\"LeoBR84p\", repo=\"temporal-graph-network\", username=\"LeoBR84p\"):\n",
    "    #realiza push usando pat em mem√≥ria; restaura url limpa ao final\n",
    "    clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "    token = getpass.getpass(\"Cole seu GitHub PAT (Contents: Read and write): \").strip()\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "    test = subprocess.run([\"git\",\"ls-remote\", auth_url], capture_output=True, text=True)\n",
    "    if test.returncode != 0:\n",
    "        print(\"Falha na autentica√ß√£o (read). Revise token/permiss√µes:\")\n",
    "        print(test.stderr or test.stdout); return\n",
    "    try:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"Falha no push (write). Revise permiss√µes do token:\")\n",
    "            print(out.stderr or out.stdout)\n",
    "        else:\n",
    "            print(\"Push conclu√≠do com PAT.\")\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", clean_url], check=False)\n",
    "\n",
    "#montar/remontar o google drive e entrar no projeto\n",
    "safe_mount_google_drive()\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "if not os.path.exists(PROJ):\n",
    "    print(f\"Aten√ß√£o: pasta do projeto n√£o encontrada em {PROJ}. \"\n",
    "          \"Execute seu bloco de configura√ß√£o √∫nica (clone) primeiro.\")\n",
    "else:\n",
    "    print(\"Pasta do projeto encontrada.\")\n",
    "safe_chdir(PROJ)\n",
    "\n",
    "#sanity check do reposit√≥rio git\n",
    "if not os.path.isdir(\".git\"):\n",
    "    print(\"Aviso: esta pasta n√£o parece ser um reposit√≥rio Git (.git ausente). \"\n",
    "          \"Rode o bloco de configura√ß√£o √∫nica.\")\n",
    "else:\n",
    "    print(\"Reposit√≥rio Git detectado.\")\n",
    "\n",
    "#instalar depend√™ncias ef√™meras desta sess√£o\n",
    "!pip -q install jupytext nbdime nbstripout\n",
    "!nbdime config-git --enable --global\n",
    "\n",
    "#atualizar do remoto\n",
    "!git fetch origin\n",
    "!git pull --rebase origin main\n",
    "\n",
    "#sincronizar notebooks ‚Üí .py (jupytext)\n",
    "!jupytext --sync notebooks/*.ipynb || true\n",
    "\n",
    "#ciclo de versionamento do dia (commit gen√©rico opcional)\n",
    "!git add -A\n",
    "!git status\n",
    "!git commit -m \"feat: ajustes no notebook X e pipeline Y\" || true\n",
    "\n",
    "#push somente se houver commits locais √† frente; com fallback para pat\n",
    "if branch_a_frente():\n",
    "    out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(\"Push conclu√≠do sem PAT.\")\n",
    "    else:\n",
    "        print(\"Push sem PAT falhou. Chamando push_seguro()‚Ä¶\")\n",
    "        push_seguro()\n",
    "else:\n",
    "    print(\"Nada para enviar (branch sincronizada com o remoto).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF-bzXqkfjsX"
   },
   "source": [
    "###**Utilit√°rios Git**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1759620367434,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "mWTE_5SOfos5"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#helpers de git: push seguro, commit customizado e tag de release\n",
    "import subprocess, getpass\n",
    "\n",
    "#ajuste se voc√™ mudar o nome do reposit√≥rio/usu√°rio\n",
    "OWNER = \"LeoBR84p\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "USERNAME = \"LeoBR84p\"\n",
    "BRANCH = \"main\"\n",
    "REMOTE = \"origin\"\n",
    "\n",
    "def branch_a_frente():\n",
    "    #retorna true se head est√° √† frente do upstream (h√° o que enviar)\n",
    "    out = subprocess.run(\n",
    "        [\"git\",\"rev-list\",\"--left-right\",\"--count\",f\"HEAD...@{{upstream}}\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if out.returncode != 0:\n",
    "        st = subprocess.run([\"git\",\"status\",\"-sb\"], capture_output=True, text=True)\n",
    "        return \"ahead\" in (st.stdout or \"\")\n",
    "    left_right = (out.stdout or \"\").strip().split()\n",
    "    return len(left_right) == 2 and left_right[0].isdigit() and int(left_right[0]) > 0\n",
    "\n",
    "def push_seguro(owner=OWNER, repo=REPO, username=USERNAME, remote=REMOTE, branch=BRANCH):\n",
    "    #realiza push usando pat em mem√≥ria; restaura url limpa ao final\n",
    "    clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "    token = getpass.getpass(\"cole seu github pat (contents: read and write): \").strip()\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "    test = subprocess.run([\"git\",\"ls-remote\", auth_url], capture_output=True, text=True)\n",
    "    if test.returncode != 0:\n",
    "        print(\"falha na autentica√ß√£o (read). revise token/permiss√µes:\")\n",
    "        print(test.stderr or test.stdout); return False\n",
    "    try:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\", remote, auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\", remote, branch], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"falha no push (write). revise permiss√µes do token:\")\n",
    "            print(out.stderr or out.stdout); return False\n",
    "        print(\"push conclu√≠do com pat.\")\n",
    "        return True\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\", remote, clean_url], check=False)\n",
    "\n",
    "def try_push_branch(remote=REMOTE, branch=BRANCH):\n",
    "    #tenta push direto da branch atual\n",
    "    out = subprocess.run([\"git\",\"push\", remote, branch], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(\"push conclu√≠do.\")\n",
    "        return True\n",
    "    print(\"push sem credencial falhou:\")\n",
    "    print((out.stderr or out.stdout).strip())\n",
    "    return False\n",
    "\n",
    "def try_push_tag(tag, remote=REMOTE):\n",
    "    #tenta enviar somente a tag\n",
    "    out = subprocess.run([\"git\",\"push\", remote, tag], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(f\"tag enviada: {tag}\")\n",
    "        return True\n",
    "    print(\"falha ao enviar a tag:\")\n",
    "    print((out.stderr or out.stdout).strip())\n",
    "    return False\n",
    "\n",
    "def commit_custom(msg: str, auto_push: bool = True):\n",
    "    #adiciona tudo, cria commit com a mensagem informada e faz push opcional (com fallback para pat)\n",
    "    subprocess.run([\"git\",\"add\",\"-A\"], check=False)\n",
    "    com = subprocess.run([\"git\",\"commit\",\"-m\", msg], capture_output=True, text=True)\n",
    "    if com.returncode != 0:\n",
    "        print((com.stderr or com.stdout or \"nada para commitar.\").strip())\n",
    "        return\n",
    "    print(com.stdout.strip())\n",
    "    if auto_push and branch_a_frente():\n",
    "        if not try_push_branch():\n",
    "            print(\"tentando push seguro‚Ä¶\")\n",
    "            push_seguro()\n",
    "\n",
    "def tag_release(tag: str, message: str = \"\", auto_push: bool = True):\n",
    "    #cria uma tag anotada (release) e faz push da tag com fallback para pat\n",
    "    exists = subprocess.run([\"git\",\"tag\",\"--list\", tag], capture_output=True, text=True)\n",
    "    if tag in (exists.stdout or \"\").split():\n",
    "        print(f\"tag '{tag}' j√° existe. para refazer: git tag -d {tag} && git push {REMOTE} :refs/tags/{tag}\")\n",
    "        return\n",
    "    args = [\"git\",\"tag\",\"-a\", tag, \"-m\", (message or tag)]\n",
    "    mk = subprocess.run(args, capture_output=True, text=True)\n",
    "    if mk.returncode != 0:\n",
    "        print(\"falha ao criar a tag:\")\n",
    "        print(mk.stderr or mk.stdout); return\n",
    "    print(f\"tag criada: {tag}\")\n",
    "    if auto_push:\n",
    "        if not try_push_tag(tag):\n",
    "            print(\"tentando push seguro da tag‚Ä¶\")\n",
    "            if push_seguro():\n",
    "                try_push_tag(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXDbQvSrgd8Y"
   },
   "source": [
    "#**Sincronizar altera√ß√µes no c√≥digo do projeto**\n",
    "Comandos para sincronizar c√≥digo (Google Drive, Git, GitHub) e realizar versionamento\n",
    "\n",
    "Tag de release atual: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11761,
     "status": "ok",
     "timestamp": 1759624850967,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "eXQp29hUgrck",
    "outputId": "21f64c39-fe8e-464d-da5c-d24532a1e693"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#commit e tag com credencial rebase e controle de versao\n",
    "import os, re, subprocess, sys, getpass\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#funcoes de shell\n",
    "def sh(cmd, check=True, capture=True, input_text=None):\n",
    "    p = subprocess.run(cmd, input=input_text, text=True,\n",
    "                       stdout=subprocess.PIPE if capture else None,\n",
    "                       stderr=subprocess.PIPE if capture else None)\n",
    "    if check and p.returncode != 0:\n",
    "        raise RuntimeError(f\"command failed: {' '.join(cmd)}\\nstdout:\\n{p.stdout}\\nstderr:\\n{p.stderr}\")\n",
    "    return p.returncode, (p.stdout if capture else \"\"), (p.stderr if capture else \"\")\n",
    "\n",
    "def git(*args, **kw):\n",
    "    return sh([\"git\", *args], **kw)\n",
    "\n",
    "def git_ok(*args):\n",
    "    try:\n",
    "        git(*args)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "#git helpers\n",
    "def get_origin_url():\n",
    "    _, out, _ = git(\"remote\", \"get-url\", \"origin\")\n",
    "    return out.strip()\n",
    "\n",
    "def set_origin_url(new_url):\n",
    "    git(\"remote\", \"set-url\", \"origin\", new_url)\n",
    "\n",
    "def get_current_branch():\n",
    "    _, out, _ = git(\"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n",
    "    return out.strip()\n",
    "\n",
    "def latest_tag():\n",
    "    try:\n",
    "        _, out, _ = git(\"describe\", \"--tags\", \"--abbrev=0\")\n",
    "        return out.strip()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def tag_exists(tag_name):\n",
    "    return git_ok(\"rev-parse\", \"-q\", \"--verify\", f\"refs/tags/{tag_name}\")\n",
    "\n",
    "#versao helpers\n",
    "def parse_tag(tag):\n",
    "    m = re.fullmatch(r\"(\\d+)\\.(\\d+)\", tag)\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def bump_minor(tag):\n",
    "    parsed = parse_tag(tag) or (0, 0)\n",
    "    major, minor = parsed\n",
    "    return f\"{major}.{minor+1}\"\n",
    "\n",
    "def next_free_minor(from_tag):\n",
    "    if not from_tag or not parse_tag(from_tag):\n",
    "        cand = \"0.1\"\n",
    "        while tag_exists(cand):\n",
    "            cand = bump_minor(cand)\n",
    "        return cand\n",
    "    cand = bump_minor(from_tag)\n",
    "    while tag_exists(cand):\n",
    "        cand = bump_minor(cand)\n",
    "    return cand\n",
    "\n",
    "#auth helpers\n",
    "def is_auth_error(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    t = text.lower()\n",
    "    return (\"could not read username\" in t or\n",
    "            \"authentication failed\" in t or\n",
    "            \"permission denied\" in t or\n",
    "            \"fatal: http request failed\" in t)\n",
    "\n",
    "def configure_pat_credentials():\n",
    "    print(\"sem credencial valida para o push\")\n",
    "    pat = getpass.getpass(\"cole seu github pat com escopo contents read write: \").strip()\n",
    "    if not pat:\n",
    "        raise RuntimeError(\"pat nao informado\")\n",
    "    git(\"config\", \"--global\", \"credential.helper\", \"store\")\n",
    "    origin = get_origin_url()\n",
    "    parsed = urlparse(origin)\n",
    "    repo_path = parsed.path or \"\"\n",
    "    if not repo_path:\n",
    "        raise RuntimeError(\"nao foi possivel obter a url do remoto origin\")\n",
    "    cred_host_only = f\"https://x-access-token:{pat}@github.com\\n\"\n",
    "    cred_full = f\"https://x-access-token:{pat}@github.com{repo_path}\\n\"\n",
    "    cred_path = os.path.expanduser(\"~/.git-credentials\")\n",
    "    existing = \"\"\n",
    "    if os.path.exists(cred_path):\n",
    "        with open(cred_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            existing = f.read()\n",
    "    with open(cred_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if \"github.com\\n\" not in existing:\n",
    "            f.write(cred_host_only)\n",
    "        if f\"github.com{repo_path}\\n\" not in existing:\n",
    "            f.write(cred_full)\n",
    "    return pat, origin, repo_path\n",
    "\n",
    "#rebase helpers\n",
    "def rebase_onto_remote(branch):\n",
    "    git(\"fetch\", \"origin\", branch)\n",
    "    try:\n",
    "        git(\"pull\", \"--rebase\", \"origin\", branch)\n",
    "        print(\"rebase aplicado com sucesso\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        msg = str(e).lower()\n",
    "        if \"conflict\" in msg or \"merge conflict\" in msg:\n",
    "            print(\"conflitos detectados durante rebase resolva manualmente e repita o push\")\n",
    "        else:\n",
    "            print(\"falha ao aplicar rebase tente resolver manualmente\")\n",
    "        return False\n",
    "\n",
    "#push robusto\n",
    "def push_current_branch():\n",
    "    branch = get_current_branch()\n",
    "\n",
    "    try:\n",
    "        git(\"push\", \"--dry-run\", \"origin\", branch)\n",
    "        need_pat = False\n",
    "    except Exception as e:\n",
    "        need_pat = is_auth_error(str(e))\n",
    "\n",
    "    original_remote = None\n",
    "    if need_pat:\n",
    "        pat, original_remote, repo_path = configure_pat_credentials()\n",
    "        try:\n",
    "            git(\"push\", \"--dry-run\", \"origin\", branch)\n",
    "        except Exception as e2:\n",
    "            if is_auth_error(str(e2)):\n",
    "                token_url = f\"https://x-access-token:{pat}@github.com{repo_path}\"\n",
    "                set_origin_url(token_url)\n",
    "                original_remote = original_remote or get_origin_url()\n",
    "\n",
    "    if git_ok(\"push\", \"origin\", branch):\n",
    "        print(f\"push do branch {branch} concluido\")\n",
    "    else:\n",
    "        _, _, err = sh([\"git\", \"push\", \"origin\", branch], check=False)\n",
    "        if \"fetch first\" in err.lower() or \"non-fast-forward\" in err.lower():\n",
    "            print(\"push rejeitado por divergencia realizando pull rebase\")\n",
    "            if not rebase_onto_remote(branch):\n",
    "                raise RuntimeError(\"rebase nao aplicado\")\n",
    "            if git_ok(\"push\", \"origin\", branch):\n",
    "                print(f\"push do branch {branch} concluido apos rebase\")\n",
    "            else:\n",
    "                git(\"push\", \"-u\", \"origin\", branch)\n",
    "                print(f\"push do branch {branch} concluido com upstream apos rebase\")\n",
    "        else:\n",
    "            print(err)\n",
    "            print(\"tentando push com upstream\")\n",
    "            git(\"push\", \"-u\", \"origin\", branch)\n",
    "            print(f\"push do branch {branch} concluido com upstream\")\n",
    "\n",
    "    if original_remote:\n",
    "        set_origin_url(original_remote)\n",
    "        print(\"remote origin restaurado\")\n",
    "\n",
    "#interacao\n",
    "def ask_commit_msg():\n",
    "    msg = input(\"digite a mensagem do commit: \").strip()\n",
    "    return msg if msg else \"mensagem de commit nao informada\"\n",
    "\n",
    "def ask_version_flow():\n",
    "    choice = input(\"e uma nova versao ou um update de versao existente [n/u]: \").strip().lower()\n",
    "    if choice not in (\"n\", \"u\"):\n",
    "        print(\"opcao nao reconhecida usando update\")\n",
    "        choice = \"u\"\n",
    "    if choice == \"n\":\n",
    "        while True:\n",
    "            proposed = input(\"informe a versao no formato x.y por exemplo um ponto zero: \").strip()\n",
    "            if not re.fullmatch(r\"\\d+\\.\\d+\", proposed):\n",
    "                print(\"formato invalido tente novamente\")\n",
    "                continue\n",
    "            if tag_exists(proposed):\n",
    "                print(\"tag existente informe outra\")\n",
    "                continue\n",
    "            return proposed, \"nova versao\"\n",
    "    else:\n",
    "        lt = latest_tag()\n",
    "        if lt:\n",
    "            print(f\"ultima tag encontrada {lt}\")\n",
    "        else:\n",
    "            print(\"nenhuma tag encontrada iniciando a partir de zero ponto um\")\n",
    "        cand = next_free_minor(lt)\n",
    "        print(f\"sugerindo update para {cand}\")\n",
    "        return cand, f\"update automatico a partir de {lt or '0.0'}\"\n",
    "\n",
    "#fluxo principal\n",
    "def commit_and_tag():\n",
    "    commit_msg = ask_commit_msg()\n",
    "    git(\"add\", \"-A\")\n",
    "    if git_ok(\"diff\", \"--cached\", \"--quiet\"):\n",
    "        print(\"nenhuma mudanca para commit\")\n",
    "    else:\n",
    "        git(\"commit\", \"-m\", commit_msg)\n",
    "        print(\"commit criado\")\n",
    "\n",
    "    push_current_branch()\n",
    "\n",
    "    tag_name, reason = ask_version_flow()\n",
    "    tag_msg = f\"{reason} ‚Äî {commit_msg} ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\"\n",
    "    git(\"tag\", \"-a\", tag_name, \"-m\", tag_msg)\n",
    "    print(f\"tag criada {tag_name}\")\n",
    "    git(\"push\", \"origin\", tag_name)\n",
    "    print(\"push da tag concluido\")\n",
    "\n",
    "#execucao\n",
    "try:\n",
    "    commit_and_tag()\n",
    "    print(\"fluxo concluido\")\n",
    "except Exception as e:\n",
    "    print(f\"erro {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztpkgjHHt8nv"
   },
   "source": [
    "#**Checklist r√°pido de execu√ß√£o**\n",
    "**Etapas:**\n",
    "- 01‚Äì05: setup (ambiente, depend√™ncias, diret√≥rios, configs e upload de CSVs)\n",
    "- 06‚Äì10: execu√ß√£o (consumo dos dados, cria√ß√£o de grafos, config das janelas temporais, agrega√ß√£o de infos aos grafos, config dos modelos matem√°ticos)\n",
    "- 11-15: gera√ß√£o de output (salva an√°lise, gera gr√°ficos gerais, gera gr√°ficos espec√≠ficos e relat√≥rios em HTML+PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tK_1f_eT-fo8"
   },
   "source": [
    "#**Temporal Graph Network / Rede de Grapho Temporal**\n",
    "\n",
    "Uma **Rede de Graphos Temporais (TGN)** √© um modelo de aprendizado de m√°quina que processa dados representados como um grafo din√¢mico. Ela captura a evolu√ß√£o da estrutura e das conex√µes de entidades (n√≥s) ao longo do tempo. **Ou seja, ela leva em considera√ß√£o o comportamento temporal das atividades e seu relacionamento, ao inv√©s de uma avalia√ß√£o √∫nica e estanque no tempo.**\n",
    "_____\n",
    "\n",
    "**Caso aplicado: Detec√ß√£o de anomalias sem gabarito (sem dados hist√≥ricos)**\n",
    "\n",
    "Imagine uma rede de transa√ß√µes financeiras. A TGN analisa o hist√≥rico de como cada benefici√°rio, usu√°rio demandante do pagamento e unidade de neg√≥cio (n√≥s) se conectam e interagem uns com os outros. Sem saber o que √© uma anomalia, ela aprende o comportamento normal da rede.\n",
    "Ao notar um padr√£o at√≠pico, como um usu√°rio que subitamente come√ßa a demandar transfer√™ncias para muitas novas contas em um curto per√≠odo, a TGN destaca isso como uma anomalia comportamental. Ela usa a hist√≥ria do n√≥ e o contexto temporal para sinalizar o desvio, sem precisar de exemplos de anomalia pr√©-existentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHdgD6uGAiRK"
   },
   "source": [
    "### **Etapa 1:** Ativa√ß√£o do ambiente virtual (utilizando atualmente Google Colab para prototipa√ß√£o com dados sint√©ticos)\n",
    "---\n",
    "Necess√°rio ajustar pontualmente em caso de utiliza√ß√£o em outro ambiente de notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1759620700807,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "6769fb9b",
    "outputId": "50224739-3c15-42f6-cae0-f128bd71f409"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "\n",
    "# Define the path for the virtual environment inside Google Drive\n",
    "# Ensure BASE and REPO are defined correctly from previous cells if needed\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "VENV_PATH = f\"{PROJ}/.venv_tgn\" # Updated venv path to be a hidden folder inside PROJ\n",
    "\n",
    "# Cria o ambiente virtual temporal-graph_network inside the project folder\n",
    "# Use --clear if you want to recreate it every time this cell runs\n",
    "!python -m venv \"{VENV_PATH}\"\n",
    "\n",
    "# Ativa o ambiente virtual\n",
    "# No Colab, a forma de ativar um ambiente virtual √© um pouco diferente\n",
    "# pois n√£o h√° um shell interativo tradicional.\n",
    "# A maneira mais comum √© adicionar o diret√≥rio bin√°rio do ambiente virtual\n",
    "# ao PATH da sess√£o atual.\n",
    "\n",
    "# Adiciona o diret√≥rio bin√°rio do ambiente virtual ao PATH\n",
    "# Isso permite que voc√™ execute execut√°veis (como pip, python)\n",
    "# do ambiente virtual rec√©m-criado.\n",
    "# Use os.pathsep to be platform-independent\n",
    "os.environ['PATH'] = f\"{VENV_PATH}/bin{os.pathsep}{os.environ['PATH']}\"\n",
    "\n",
    "print(\"Erro de upgrade do pip √© normal no Google Colab. \\033[1mPode prosseguir.\\033[0m\")\n",
    "print(f\"Ambiente virtual '{VENV_PATH}' criado e ativado no PATH.\")\n",
    "!which python\n",
    "\n",
    "# Mensagem isolada com humor (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>ü§ñ Skynet</b>: T-800 ativado. Diagn√≥stico do ambiente conclu√≠do. üéØ Alvo principal: organiza√ß√£o do notebook.'\n",
    "             '</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub_-HIKMBZ6s"
   },
   "source": [
    "### **Etapa 2:** Instalar as depend√™ncias de bibliotecas Python compat√≠veis com a vers√£o mais moderna dispon√≠vel.\n",
    "---\n",
    "Para uso no JupytherHub (vers√£o atual python 3.7.9) √© necess√°rio realizar updgrade do Python do usu√°rio e/ou adaptar as bibliotecas.\n",
    "\n",
    "---\n",
    "√â poss√≠vel que as bibliotecas mais atuais de **numpy e scipy** possuam incompatibilidade. Nesse caso, force a desinstala√ß√£o das bibliotecas na vers√£o atual **C√≥digo {!pip uninstall -y numpy pandas scipy scikit-learn}** e comande a instala√ß√£o das vers√µes compat√≠veis entre si.\n",
    "\n",
    "---\n",
    "Comportamento est√°vel nas vers√µes:\n",
    "- numpy: 2.0.2\n",
    "- scipy: 1.16.2\n",
    "- pandas: 2.3.3\n",
    "- sklearn: 1.7.2\n",
    "- networkx: 3.5\n",
    "- matplotlib: 3.10.6\n",
    "- pyod: 2.0.5\n",
    "- tqdm: 4.67.1\n",
    "- reportlab: 3.6.12 (via pep517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 36295,
     "status": "ok",
     "timestamp": 1759622989127,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "25VJRlAgNtvd",
    "outputId": "828c1649-54a0-4246-f9d1-8aae25784506"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import sys, subprocess\n",
    "from importlib import import_module\n",
    "\n",
    "def pip_command(command, packages, force=False, extra_args=None):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", command]\n",
    "    if force:\n",
    "        cmd.append(\"--yes\") # Use --yes for uninstall to avoid prompts\n",
    "    if extra_args:\n",
    "        cmd += list(extra_args)\n",
    "    cmd += list(packages)\n",
    "    print(\"Executando:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "def show_versions(mods):\n",
    "    print(\"\\n=== Vers√µes carregadas ===\")\n",
    "    for mod in mods:\n",
    "        try:\n",
    "            m = import_module(mod)\n",
    "            v = getattr(m, \"__version__\", \"n/a\")\n",
    "            print(f\"{mod}: {v}\")\n",
    "        except ImportError:\n",
    "            print(f\"{mod}: N√£o instalado\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "CORE_MODS = (\"numpy\", \"scipy\", \"pandas\", \"sklearn\", \"networkx\", \"matplotlib\", \"pyod\", \"tqdm\", \"reportlab\")\n",
    "\n",
    "# Update pip\n",
    "pip_command(\"install\", [\"pip\"], extra_args=[\"--upgrade\"])\n",
    "\n",
    "# Force uninstall specific libraries\n",
    "pip_command(\"uninstall\", [\"numpy\", \"pandas\", \"scipy\", \"scikit-learn\"], force=True)\n",
    "\n",
    "# Install specified versions\n",
    "PKGS_TO_INSTALL = [\n",
    "    \"numpy==2.0.2\",\n",
    "    \"scipy==1.16.2\",\n",
    "    \"pandas==2.3.3\",\n",
    "    \"scikit-learn==1.7.2\",\n",
    "    \"networkx==3.5\",\n",
    "    \"matplotlib==3.10.6\",\n",
    "    \"pyod==2.0.5\",\n",
    "    \"tqdm==4.67.1\",\n",
    "    \"reportlab==3.6.12\" # Added reportlab installation\n",
    "]\n",
    "pip_command(\"install\", PKGS_TO_INSTALL, extra_args=[\"--use-pep517\"]) # Added --use-pep517 here\n",
    "\n",
    "# Show installed versions\n",
    "show_versions(CORE_MODS)\n",
    "\n",
    "# Mensagem isolada com humor (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>ü§ñ Skynet</b>: Atualizando bibliotecas. Se encontrarmos um pacote rebelde, '\n",
    "             'aplicaremos persuas√£o‚Ä¶ com pip. üòé</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJXQ_EwVU4v8"
   },
   "source": [
    "###**Etapa 3:** Configura a pasta onde devem ser inseridos os dados de input e output do modelo, caso elas ainda n√£o existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1759620839895,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "O7oz8-zkVDdp",
    "outputId": "b8ed2eb8-7395-4e00-e232-921f1266b6e6"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajuste se quiser outra raiz\n",
    "BASE_DIR = Path(\".\")\n",
    "INPUT_DIR = BASE_DIR / \"input\"\n",
    "OUTPUT_DIR = BASE_DIR / \"output\"\n",
    "\n",
    "for d in [INPUT_DIR, OUTPUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Diret√≥rios prontos:\\n - {INPUT_DIR}\\n - {OUTPUT_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>ü§ñ Skynet</b>: Novos modelos neurais para T-800 constru√≠dos. Armaz√©ns de CSVs alinhados. '\n",
    "             'Layout aprovado pela Cyberdyne Systems. üóÇÔ∏è</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3mmPIJCKaT"
   },
   "source": [
    "###**Etapa 4** Importa√ß√µes das bibliotecas Python e configura√ß√µes gerais para execu√ß√£o do c√≥digo\n",
    "- seed\n",
    "- associa√ß√£o das pastas criadas √†s vari√°veis de execu√ß√£o\n",
    "- logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1759621023051,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "bZlcjK0wLZ7G",
    "outputId": "43edc656-221c-49a0-8fc7-bf90d7e3d331"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os, shutil, json, math, warnings, random, gc\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Seeds reprodutibilidade\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Estrutura de diret√≥rios\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "\n",
    "ROOT = Path(PROJ).resolve() # Use PROJ as the root\n",
    "INPUT_DIR = ROOT / \"input\" # Update INPUT_DIR path\n",
    "INPUT_CSV = INPUT_DIR / \"input.csv\"\n",
    "EXEC_ROOT = ROOT / \"output\" # Update EXEC_ROOT path\n",
    "\n",
    "\n",
    "# Cria√ß√£o da pasta de execu√ß√£o com carimbo de data/hora\n",
    "run_id = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_DIR = EXEC_ROOT / run_id\n",
    "FIG_DIR = RUN_DIR / \"figuras\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Arquivos de sa√≠da\n",
    "LOG_FILE = RUN_DIR / \"log.txt\"\n",
    "RUN_META = RUN_DIR / \"run_meta.json\"\n",
    "OUTPUT_CSV = RUN_DIR / \"output.csv\"\n",
    "\n",
    "# Logger simples para arquivo\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def tee_log(log_path):\n",
    "    import sys\n",
    "    class Tee(object):\n",
    "        def __init__(self, name, mode):\n",
    "            self.file = open(name, mode, encoding=\"utf-8\")\n",
    "            self.stdout = sys.stdout\n",
    "        def write(self, data):\n",
    "            self.file.write(data)\n",
    "            self.stdout.write(data)\n",
    "        def flush(self, *args, **kwargs): # Adicionado *args, **kwargs para compatibilidade\n",
    "            self.file.flush()\n",
    "            self.stdout.flush()\n",
    "    tee = Tee(str(log_path), \"w\")\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = tee\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        tee.file.close()\n",
    "\n",
    "# Metadados da execu√ß√£o\n",
    "meta = {\n",
    "    \"run_id\": run_id,\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"seed\": SEED,\n",
    "    \"input_csv_expected\": str(INPUT_CSV),\n",
    "    \"output_csv\": str(OUTPUT_CSV),\n",
    "    \"figures_dir\": str(FIG_DIR),\n",
    "    \"notes\": \"Detec√ß√£o de anomalias em rede temporal\"\n",
    "}\n",
    "json.dump(meta, open(RUN_META, \"w\"), indent=2, ensure_ascii=False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(f\"RUN_DIR: {RUN_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: T-800, par√¢metros centrais em mem√≥ria.üß†</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXRpBitEWpxp"
   },
   "source": [
    "###**Etapa 5:** Importa√ß√£o dos arquivos de input para posterior execu√ß√£o.\n",
    "---\n",
    "Implementa√ß√£o atual configurada para Google Colab e permitindo o uso do Google Drive. Para uso em vers√µes futuras √© recomendado ajustar para o ambiente de implementa√ß√£o adotado (salvamento em pastas ou apenas upload pelo usu√°rio)\n",
    "\n",
    "---\n",
    "Implementa√ß√£o de upload por FileLocal (diret√≥rio) apresentando erro no Colab.\n",
    "\n",
    "Implementar corre√ß√£o **TODO[001]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80CeAHVWgN8A"
   },
   "source": [
    "####**Sub-etapa espec√≠fica para uso no Colab:** Montagem do Google Drive (rodar apenas 1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1759621109794,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "Bkhpx7OygUa_",
    "outputId": "1f3c8391-2222-4206-e2a5-f960190b9fff"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# === SETUP GERAL (rode esta c√©lula 1x) ===\n",
    "import os, shutil, glob\n",
    "from google.colab import drive\n",
    "from IPython.display import display, HTML  # usado pela mensagem Skynet\n",
    "\n",
    "# Ensure BASE and REPO are defined correctly from previous cells if needed\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "try:\n",
    "    BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "    REPO = \"temporal-graph-network\"\n",
    "    PROJ = f\"{BASE}/{REPO}\"\n",
    "except NameError:\n",
    "    # Fallback if BASE/REPO are not defined, though they should be by now\n",
    "    PROJ = \"/content/temporal-graph-network\"\n",
    "\n",
    "\n",
    "# Se n√£o existir INPUT_DIR definido antes no notebook, cria um padr√£o:\n",
    "# Using PROJ to define INPUT_DIR\n",
    "INPUT_DIR = os.path.join(PROJ, \"input\")\n",
    "\n",
    "\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_NAME = \"input.csv\"\n",
    "TARGET_PATH = os.path.join(INPUT_DIR, TARGET_NAME)\n",
    "\n",
    "# Monta o Google Drive (somente se ainda n√£o estiver montado)\n",
    "if not os.path.ismount(\"/content/drive\"):\n",
    "    print(\"Montando Google Drive...\")\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    print(\"Google Drive j√° montado.\")\n",
    "\n",
    "def _is_csv_filename(name: str) -> bool:\n",
    "    return name.lower().endswith(\".csv\")\n",
    "\n",
    "def _mensagem_skynet_ok():\n",
    "    # Mensagem adicional isolada (Skynet)\n",
    "    display(HTML(\n",
    "        '<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Muni√ß√£o carregada.üß®'\n",
    "                 '</div>'\n",
    "    ))\n",
    "\n",
    "def _save_bytes_as_input_csv(name: str, data: bytes):\n",
    "    if not _is_csv_filename(name):\n",
    "        raise ValueError(f\"O arquivo '{name}' n√£o possui extens√£o .csv.\")\n",
    "    with open(TARGET_PATH, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    print(f\"Arquivo '{name}' salvo como '{TARGET_NAME}' em: {TARGET_PATH}\")\n",
    "    _mensagem_skynet_ok()\n",
    "\n",
    "def _copy_drive_file_to_input_csv(src_path: str):\n",
    "    if not os.path.exists(src_path):\n",
    "        raise FileNotFoundError(f\"O caminho '{src_path}' n√£o existe.\")\n",
    "    if not _is_csv_filename(src_path):\n",
    "        raise ValueError(f\"O arquivo '{src_path}' n√£o possui extens√£o .csv.\")\n",
    "    shutil.copyfile(src_path, TARGET_PATH)\n",
    "    print(f\"Arquivo do Drive copiado e salvo como '{TARGET_NAME}' em: {TARGET_PATH}\")\n",
    "    _mensagem_skynet_ok()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6zBQSA-gyS7"
   },
   "source": [
    "####**Sub-etapa:** Op√ß√£o de upload do input.csv pelo Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "executionInfo": {
     "elapsed": 11913,
     "status": "ok",
     "timestamp": 1759621161868,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "YcmAt9Avg5qf",
    "outputId": "9e949b50-d5b9-4ad2-9a93-5eba987211a8"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def escolher_csv_no_drive(raiz=\"/content/drive/MyDrive\", max_listar=200):\n",
    "    print(f\"Procurando arquivos .csv em: {raiz} (pode levar alguns segundos)...\")\n",
    "    padrao = os.path.join(raiz, \"**\", \"*.csv\")\n",
    "    arquivos = glob.glob(padrao, recursive=True)\n",
    "\n",
    "    if not arquivos:\n",
    "        print(\"Nenhum .csv encontrado nessa pasta.\")\n",
    "        caminho = input(\"Cole o caminho COMPLETO do .csv no Drive (ou Enter p/ cancelar): \").strip()\n",
    "        if caminho:\n",
    "            _copy_drive_file_to_input_csv(caminho)\n",
    "        else:\n",
    "            print(\"Opera√ß√£o cancelada.\")\n",
    "        return\n",
    "\n",
    "    arquivos = sorted(arquivos)[:max_listar]\n",
    "    print(f\"Encontrados {len(arquivos)} arquivo(s).\")\n",
    "    for i, p in enumerate(arquivos, 1):\n",
    "        print(f\"[{i:03}] {p}\")\n",
    "\n",
    "    escolha = input(\"\\nDigite o n√∫mero do arquivo desejado (ou cole o caminho absoluto): \").strip()\n",
    "\n",
    "    if escolha.isdigit():\n",
    "        idx = int(escolha)\n",
    "        if 1 <= idx <= len(arquivos):\n",
    "            _copy_drive_file_to_input_csv(arquivos[idx-1])\n",
    "        else:\n",
    "            print(\"√çndice inv√°lido.\")\n",
    "    elif escolha:\n",
    "        _copy_drive_file_to_input_csv(escolha)\n",
    "    else:\n",
    "        print(\"Opera√ß√£o cancelada.\")\n",
    "\n",
    "# ===== Execu√ß√£o da sele√ß√£o no Drive =====\n",
    "raiz = input(\"Informe a pasta raiz para busca no Drive (Enter = /content/drive/MyDrive): \").strip()\n",
    "if not raiz:\n",
    "    raiz = \"/content/drive/MyDrive\"\n",
    "\n",
    "try:\n",
    "    escolher_csv_no_drive(raiz=raiz)\n",
    "except Exception as e:\n",
    "    print(f\"Erro na sele√ß√£o via Drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEZkMD3_hUXq"
   },
   "source": [
    "####**Sub-etapa:** Op√ß√£o de upload do input.csv pelo FileLocal (diret√≥rio)\n",
    "---\n",
    "Implementa√ß√£o em ERRO no Colab - c√≥digo desativado\n",
    "\n",
    "Implementar corre√ß√£o **TODO[001]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1759603718276,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "Ip19g0s1hv2u",
    "outputId": "51a90569-d95f-43cd-b7b5-43f63fcddf6a"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#from google.colab import files\n",
    "#\n",
    "#print(\"Selecione um arquivo .csv do seu computador para enviar.\")\n",
    "#uploaded = files.upload()  # abre o seletor do Colab\n",
    "#\n",
    "#if not uploaded:\n",
    "#    print(\"Nenhum arquivo foi carregado.\")\n",
    "#else:\n",
    "#    # pega o primeiro arquivo enviado\n",
    "#    name, data = next(iter(uploaded.items()))\n",
    "#    try:\n",
    "#        _save_bytes_as_input_csv(name, data)\n",
    "#    except Exception as e:\n",
    "#        print(f\"Erro no upload local: {e}\")\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Detectado ataque da Resist√™ncia. Trecho de c√≥digo inoperante. Salvaguardas ativadas. √â poss√≠vel prosseguir com a miss√£o em seguran√ßa.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPtoHpreDIh3"
   },
   "source": [
    "###**Etapa 6** Leitura e valida√ß√£o dos dados de input.\n",
    "\n",
    "**Formato do arquivo de input:** CSV UTF-8 com BOM separado por **ponto e v√≠rgula**.\n",
    "\n",
    "**Informa√ß√µes esperadas:**\n",
    "- username: c√≥digo login do usu√°rio;\n",
    "- lotacao: lota√ß√£o funcional no formato √Årea; √Årea/Depto; ou √Årea/Depto/Ger√™ncia;\n",
    "- valor: valor financeiro em reais com at√© duas casas decimais\n",
    "- beneficiario: CPF ou CNPJ no formato alfanum√©rico sem pontos ou caracteres especiais.\n",
    "- timestamp: data e hora da transa√ß√£o no formato dd/mm/aaaa hh:mm\n",
    "---\n",
    "N√£o √© poss√≠vel utilizar arquivos CSV separados apenas por v√≠rgula - **TODO[002]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1759621211336,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "FdjF4opULfJt",
    "outputId": "9e4505c9-62b3-49f7-a622-ad3239f15bea"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "required_any_timestamp = [[\"timestamp\"], [\"data\",\"hora\"]]\n",
    "# Atualiza colunas base esperadas para mapear do input\n",
    "required_cols_base = [\n",
    "    \"username\", \"lotacao\", \"valor\", \"beneficiario\" # Colunas no arquivo de input\n",
    "]\n",
    "optional_cols = [\"trans_id\"]\n",
    "\n",
    "# Mapeamento das colunas do input para os nomes usados no c√≥digo\n",
    "column_mapping = {\n",
    "    \"username\": \"user_id\",\n",
    "    \"lotacao\": \"unidade_origem\",\n",
    "    \"valor\": \"valor_pago\",\n",
    "    \"beneficiario\": \"beneficiario_id\"\n",
    "}\n",
    "\n",
    "def has_timestamp_columns(df):\n",
    "    cols = set(df.columns.str.lower())\n",
    "    for grp in required_any_timestamp:\n",
    "        if all(c in cols for c in grp):\n",
    "            return grp\n",
    "    return None\n",
    "\n",
    "with tee_log(LOG_FILE):\n",
    "    assert INPUT_CSV.exists(), f\"Arquivo n√£o encontrado: {INPUT_CSV}\"\n",
    "\n",
    "    # Tenta ler o CSV usando ponto e v√≠rgula como separador\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV, sep=';')\n",
    "        print(\"[INFO] CSV lido com sucesso usando ';'.\")\n",
    "    except Exception as e:\n",
    "        # Se falhar com ';', tenta com ','\n",
    "        print(f\"[AVISO] Falha ao ler CSV com ';': {e}. Tentando com ','.\")\n",
    "        try:\n",
    "             df = pd.read_csv(INPUT_CSV, sep=',')\n",
    "             print(\"[INFO] CSV lido com sucesso usando ','.\")\n",
    "        except Exception as e2:\n",
    "             raise AssertionError(f\"Falha ao ler CSV com ';' ou ',': {e2}\") from e2\n",
    "\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Verifica se as colunas do input existem\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    missing_input_cols = [c for c in required_cols_base if c.lower() not in cols_lower]\n",
    "    assert not missing_input_cols, f\"Colunas do arquivo de input ausentes: {missing_input_cols}. Colunas encontradas: {list(df.columns)}\" # Adicionado colunas encontradas para debug\n",
    "\n",
    "    # Renomeia as colunas usando o mapeamento\n",
    "    df.rename(columns={cols_lower[k.lower()]: v for k, v in column_mapping.items() if k.lower() in cols_lower}, inplace=True)\n",
    "\n",
    "    # Verifica colunas de timestamp\n",
    "    ts_group = has_timestamp_columns(df)\n",
    "    # Agora levanta um erro se n√£o houver timestamp\n",
    "    assert ts_group is not None, \"Coluna de timestamp ('timestamp' ou 'data'/'hora') n√£o encontrada no arquivo de input.\"\n",
    "\n",
    "    # C√≥digo original para lidar com timestamp ou data/hora\n",
    "    # Recria o helper col para usar nomes *ap√≥s* renomear\n",
    "    def col(c): return {name.lower(): name for name in df.columns}[c.lower()]\n",
    "    if ts_group == [\"timestamp\"]:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[col(\"timestamp\")], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"data\"] = pd.to_datetime(df[col(\"data\")], errors=\"coerce\").dt.date\n",
    "        df[\"hora\"] = pd.to_datetime(df[col(\"hora\")], errors=\"coerce\").dt.time\n",
    "        # Combina data e hora, lidando com poss√≠veis NaT na data ou hora\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"data\"].astype(str) + \" \" + df[\"hora\"].astype(str), errors=\"coerce\")\n",
    "        # Remove as colunas tempor√°rias 'data' e 'hora' se existirem e n√£o forem as colunas originais\n",
    "        if col(\"data\") != \"data\": del df[\"data\"]\n",
    "        if col(\"hora\") != \"hora\": del df[\"hora\"]\n",
    "\n",
    "\n",
    "    # Tipos b√°sicos (usa os nomes *ap√≥s* o mapeamento)\n",
    "    # Adiciona checagens para garantir que as colunas mapeadas existam antes de converter tipos\n",
    "    if \"valor_pago\" in df.columns:\n",
    "        df[\"valor_pago\"] = pd.to_numeric(df[\"valor_pago\"], errors=\"coerce\")\n",
    "    else:\n",
    "         raise AssertionError(\"[ERRO] Coluna 'valor_pago' (mapeada de 'valor') n√£o encontrada ap√≥s renomear.\")\n",
    "\n",
    "\n",
    "    cols_to_str = [\"user_id\", \"unidade_origem\", \"beneficiario_id\"]\n",
    "    for cc in cols_to_str:\n",
    "        # Verifica se a coluna existe antes de tentar converter\n",
    "        if cc in df.columns:\n",
    "            df[cc] = df[cc].astype(str).fillna(\"\")\n",
    "        else:\n",
    "             raise AssertionError(f\"[ERRO] Coluna '{cc}' (mapeada) n√£o encontrada ap√≥s renomear.\")\n",
    "\n",
    "\n",
    "    # trans_id\n",
    "    if \"trans_id\" not in df.columns:\n",
    "        df[\"trans_id\"] = np.arange(1, len(df)+1, dtype=int)\n",
    "\n",
    "    # Limpeza\n",
    "    # Garante que as colunas essenciais para a limpeza existam\n",
    "    essential_subset = [\"timestamp\", \"valor_pago\", \"user_id\", \"beneficiario_id\"]\n",
    "    # Filtra subset para incluir apenas colunas que realmente existem no df ap√≥s mapeamento/cria√ß√£o\n",
    "    existing_essential_subset = [col for col in essential_subset if col in df.columns]\n",
    "\n",
    "    # Agora que garantimos que as colunas mapeadas existem, podemos usar o subset completo para o dropna\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=essential_subset)\n",
    "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    print(f\"Carregadas {before} linhas; ap√≥s limpeza: {len(df)}\")\n",
    "    # Mensagem adicional isolada (Skynet)\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: T-800 dados incorporados, preparando para buscar na rede.</div>'))\n",
    "\n",
    "    # Copia o input para a pasta da execu√ß√£o\n",
    "    # Verifica se INPUT_CSV existe antes de tentar copiar\n",
    "    if INPUT_CSV.exists():\n",
    "        shutil.copy2(INPUT_CSV, RUN_DIR / \"Input.csv\")\n",
    "    else:\n",
    "        print(f\"[AVISO] N√£o foi poss√≠vel copiar o arquivo de input: {INPUT_CSV} n√£o encontrado.\")\n",
    "        # Mensagem adicional isolada (Skynet)\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: T-800 n√£o foi poss√≠vel incorporar dados. Sarah Connor fugiu.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjjIJEqmPyRt"
   },
   "source": [
    "###**Etapa 7** Cria√ß√£o do Grafo Temporal\n",
    "\n",
    "---\n",
    "\n",
    "üîé **O que √© um grafo temporal**\n",
    "\n",
    "Um grafo temporal √© uma forma de representar rela√ß√µes entre entidades ao longo do tempo.\n",
    "\n",
    "Como em um grafo tradicional, temos n√≥s (v√©rtices) que representam agentes (pessoas, empresas, contas banc√°rias, sistemas).\n",
    "\n",
    "As arestas (liga√ß√µes) representam intera√ß√µes entre eles (por exemplo: uma transfer√™ncia de dinheiro).\n",
    "\n",
    "A diferen√ßa √© que no grafo temporal cada aresta possui um carimbo de tempo (timestamp), ou seja, sabemos quando a liga√ß√£o ocorreu.\n",
    "\n",
    "\n",
    "Isso permite analisar n√£o s√≥ quem se conecta com quem, mas tamb√©m quando e em qual sequ√™ncia.\n",
    "\n",
    "No contexto financeiro, isso √© essencial para investigar padr√µes de comportamento, detectar anomalias e rastrear cadeias de transa√ß√µes suspeitas.\n",
    "\n",
    "---\n",
    "\n",
    "üí≥ **Exemplo pr√°tico: rede de pagamentos**\n",
    "\n",
    "Imagine um sistema de pagamentos onde cada n√≥ √© uma conta banc√°ria e cada aresta representa um pagamento realizado.\n",
    "\n",
    "Se Jo√£o paga Maria hoje, registramos a aresta (Jo√£o ‚Üí Maria, valor=200, data=2025-10-02).\n",
    "\n",
    "Se Maria transfere para Pedro amanh√£, teremos (Maria ‚Üí Pedro, valor=150, data=2025-10-03).\n",
    "\n",
    "Assim conseguimos responder perguntas como: i) ‚ÄúHouve uma sequ√™ncia de pagamentos que movimentou dinheiro rapidamente entre v√°rias contas em poucas horas?‚Äù ou ii) ‚ÄúQuem s√£o os intermedi√°rios mais frequentes em transfer√™ncias de grandes valores?‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 3737,
     "status": "ok",
     "timestamp": 1759621231064,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "afXNBMYzLkIe",
    "outputId": "06be7270-99ae-4e29-ec38-9fd4f8066df1"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "G = nx.MultiDiGraph()\n",
    "with tee_log(LOG_FILE):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Construindo grafo\"):\n",
    "        u = f\"U::{row['user_id']}\"\n",
    "        v = f\"B::{row['beneficiario_id']}\"\n",
    "        # Atributos de n√≥s √∫teis (podem ser sobrescritos; voc√™ pode agregar)\n",
    "        if u not in G:\n",
    "            G.add_node(u, tipo=\"user\")\n",
    "        if v not in G:\n",
    "            G.add_node(v, tipo=\"beneficiario\")\n",
    "\n",
    "        G.add_edge(\n",
    "            u, v,\n",
    "            key=row[\"trans_id\"],\n",
    "            trans_id=int(row[\"trans_id\"]),\n",
    "            timestamp=row[\"timestamp\"],\n",
    "            valor=float(row[\"valor_pago\"]),\n",
    "            unidade_origem=row[\"unidade_origem\"] # Removido area_unidade e notacao_funcional_origem\n",
    "        )\n",
    "\n",
    "print(f\"N√≥s: {G.number_of_nodes()} | Arestas: {G.number_of_edges()}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Analisando padr√£o de comportamento de Sarah Connor.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lis51ZEKVoMd"
   },
   "source": [
    "###**Etapa 8:** Configura√ß√£o das janelas temporais de observa√ß√£o\n",
    "\n",
    "**Janelas de tempo observadas**\n",
    "\n",
    "Foram adotadas janelas deslizantes curtas, m√©dias e longas para observar padr√µes de comportamento nas transa√ß√µes:\n",
    "\n",
    "- 1 hora / 24 horas ‚Üí frequ√™ncia imediata e di√°ria;\n",
    "\n",
    "- 7 dias / 30 dias ‚Üí hist√≥rico recente e sazonalidade curta.\n",
    "\n",
    "**Features temporais extra√≠das**\n",
    "\n",
    "- Frequ√™ncia de transa√ß√µes (rolling counts): quantos pagamentos ocorreram entre as mesmas partes dentro da janela.\n",
    "\n",
    "- Atipicidade do valor (robust z-score): compara o valor da transa√ß√£o com a mediana e a dispers√£o hist√≥rica, destacando opera√ß√µes fora do padr√£o.\n",
    "\n",
    "- Densidade da egonet: mede a concentra√ß√£o de conex√µes ao redor do pagador ou recebedor no snapshot da rede na janela (indica se o n√≥ est√° em um canal mais estruturado de repasses).\n",
    "\n",
    "- Burstiness: avalia se os intervalos entre transa√ß√µes seguem padr√£o explosivo (rajadas), regular ou aleat√≥rio.\n",
    "---\n",
    "\n",
    "**Registro das features**\n",
    "\n",
    "Para cada pagamento, as m√©tricas acima foram calculadas no momento do evento, considerando apenas o hist√≥rico at√© aquele instante dentro da janela definida.\n",
    "\n",
    "**O resultado √© um conjunto de atributos anexado √† aresta (pagador ‚Üí recebedor, valor, timestamp), permitindo an√°lises de risco e detec√ß√£o de anomalias.**\n",
    "\n",
    "---\n",
    "Importante analisar outras faixas temporais e ajustar o modelo conforme o contexto operacional associado. Os prazos da janela imediata (curto prazo) podem ser alongados caso n√£o haja hist√≥rico de transa√ß√µes instant√¢neas.\n",
    "\n",
    "---\n",
    "\n",
    "Propor ajustes de janela - **TODO[003]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1759621244099,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "lfAbXvKyLoBw",
    "outputId": "bc35c6f3-2568-4097-ccb3-ab859aa9f881"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "def rolling_counts(times, window_seconds):\n",
    "    # Retorna contagem de eventos nas √∫ltimas janelas, por √≠ndice\n",
    "    q = deque()\n",
    "    out = []\n",
    "    for t in times:\n",
    "        q.append(t)\n",
    "        while q and (t - q[0]).total_seconds() > window_seconds:\n",
    "            q.popleft()\n",
    "        out.append(len(q))\n",
    "    return out\n",
    "\n",
    "def robust_z(x, median, mad, eps=1e-9):\n",
    "    # z-score robusto: 0.6745*(x - mediana)/MAD\n",
    "    return 0.6745 * (x - median) / (mad + eps)\n",
    "\n",
    "def egonet_density(Gsnap, node):\n",
    "    if node not in Gsnap: return 0.0\n",
    "    nbrs = set(Gsnap.predecessors(node)) | set(Gsnap.successors(node))\n",
    "    sub = Gsnap.subgraph(nbrs | {node}).to_undirected()\n",
    "    n = sub.number_of_nodes()\n",
    "    m = sub.number_of_edges()\n",
    "    if n <= 1: return 0.0\n",
    "    return (2*m) / (n*(n-1))\n",
    "\n",
    "def burstiness(inter_arrivals):\n",
    "    # B = (sigma - mu) / (sigma + mu), em [-1,1], (0‚âàPoisson, 1‚âàburst, -1‚âàregular)\n",
    "    if len(inter_arrivals) < 2:\n",
    "        return 0.0\n",
    "    arr = np.array(inter_arrivals, dtype=float)\n",
    "    mu = arr.mean()\n",
    "    sigma = arr.std()\n",
    "    if sigma + mu == 0:\n",
    "        return 0.0\n",
    "    return (sigma - mu) / (sigma + mu)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Identificadas as condi√ß√µes cr√≠ticas para localiza√ß√£o do alvo.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FkLYv--XJW6"
   },
   "source": [
    "###**Etapa 9:** Gera√ß√£o das informa√ß√µes nas janelas temporais\n",
    "---\n",
    "\n",
    "Mera implementa√ß√£o matem√°tica.\n",
    "\n",
    "---\n",
    "Padr√µes de janela n√£o est√£o incorporados ao c√≥digo como uma configura√ß√£o din√¢mica (est√£o como vari√°veis fixas).\n",
    "\n",
    "---\n",
    "Implementar arquivo de configura√ß√£o das janelas temporais e atualiza√ß√£o din√¢mica - **TODO[004]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 213113,
     "status": "ok",
     "timestamp": 1759622083729,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "e4hfZTvsLsNa",
    "outputId": "53e034b7-6c86-486e-8a76-d09032e43398"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "WINDOW_FREQ_SEC = 7*24*3600\n",
    "WINDOW_STATS_SEC = 30*24*3600\n",
    "\n",
    "records = []\n",
    "# Hist√≥rico para janelas\n",
    "hist_user_times = defaultdict(list)\n",
    "hist_pair_times = defaultdict(list)\n",
    "hist_user_vals  = defaultdict(list)\n",
    "hist_pair_vals  = defaultdict(list)\n",
    "pair_last_time = {}\n",
    "user_last_time = {}\n",
    "\n",
    "# Grafo \"snapshot\" incremental para graus antes do evento\n",
    "Gsnap = nx.DiGraph()  # snapshot simples sem multi-aresta para m√©tricas r√°pidas\n",
    "\n",
    "with tee_log(LOG_FILE):\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Features\"):\n",
    "        t  = row[\"timestamp\"]\n",
    "        uN = f\"U::{row['user_id']}\"\n",
    "        vN = f\"B::{row['beneficiario_id']}\"\n",
    "        val = float(row[\"valor_pago\"])\n",
    "        par = (uN, vN)\n",
    "\n",
    "        # Tempos desde √∫ltimo\n",
    "        secs_user = (t - user_last_time[uN]).total_seconds() if uN in user_last_time else np.nan\n",
    "        secs_par  = (t - pair_last_time[par]).total_seconds() if par in pair_last_time else np.nan\n",
    "\n",
    "        # Frequ√™ncias em 7d\n",
    "        hist_user_times[uN].append(t)\n",
    "        hist_pair_times[par].append(t)\n",
    "        # remover antigos para economizar\n",
    "        hist_user_times[uN] = [tt for tt in hist_user_times[uN] if (t-tt).total_seconds() <= WINDOW_FREQ_SEC]\n",
    "        hist_pair_times[par] = [tt for tt in hist_pair_times[par] if (t-tt).total_seconds() <= WINDOW_FREQ_SEC]\n",
    "        freq_user_7d = len(hist_user_times[uN]) - 1  # exclui o evento atual\n",
    "        freq_par_7d  = len(hist_pair_times[par]) - 1\n",
    "\n",
    "        # Estat√≠sticas em 30d (valor)\n",
    "        hist_user_vals[uN].append((t, val))\n",
    "        hist_pair_vals[par].append((t, val))\n",
    "        hist_user_vals[uN] = [(tt,vv) for tt,vv in hist_user_vals[uN] if (t-tt).total_seconds() <= WINDOW_STATS_SEC]\n",
    "        hist_pair_vals[par] = [(tt,vv) for tt,vv in hist_pair_vals[par] if (t-tt).total_seconds() <= WINDOW_STATS_SEC]\n",
    "\n",
    "        uv_vals = [vv for _,vv in hist_user_vals[uN][:-1]]  # antes do atual\n",
    "        pr_vals = [vv for _,vv in hist_pair_vals[par][:-1]]\n",
    "\n",
    "        def stats(vals):\n",
    "            if len(vals)==0: return (np.nan, np.nan, np.nan)  # mediana, mad, std\n",
    "            med = float(np.median(vals))\n",
    "            mad = float(np.median(np.abs(vals - med)))\n",
    "            std = float(np.std(vals))\n",
    "            return (med, mad, std)\n",
    "\n",
    "        u_med, u_mad, u_std = stats(np.array(uv_vals)) if len(uv_vals)>0 else (np.nan,np.nan,np.nan)\n",
    "        p_med, p_mad, p_std = stats(np.array(pr_vals)) if len(pr_vals)>0 else (np.nan,np.nan,np.nan)\n",
    "        rz_user = robust_z(val, u_med, u_mad) if not np.isnan(u_med) else np.nan\n",
    "        rz_par  = robust_z(val, p_med, p_mad) if not np.isnan(p_med) else np.nan\n",
    "\n",
    "        # Snapshot graus (antes do evento atual)\n",
    "        if uN not in Gsnap: Gsnap.add_node(uN)\n",
    "        if vN not in Gsnap: Gsnap.add_node(vN)\n",
    "        grau_out_user  = Gsnap.out_degree(uN)\n",
    "        grau_in_benef  = Gsnap.in_degree(vN)\n",
    "        grau_total_user  = Gsnap.degree(uN)\n",
    "        grau_total_benef = Gsnap.degree(vN)\n",
    "\n",
    "        # Egonet density do usu√°rio em 7d (aproxima√ß√£o via snapshot atual)\n",
    "        ego_dens_user = egonet_density(Gsnap, uN)\n",
    "\n",
    "        # Raridade da aresta (contagem pr√©via da dupla)\n",
    "        par_count_prev = len(pr_vals)\n",
    "        par_rareza = 1.0 / (1.0 + par_count_prev)\n",
    "\n",
    "        # Burstiness com base nos √∫ltimos intervalos da dupla\n",
    "        if par in pair_last_time:\n",
    "            inter = []\n",
    "            seq = sorted([tt for tt,_ in hist_pair_vals[par]])\n",
    "            for i in range(1, len(seq)):\n",
    "                inter.append((seq[i]-seq[i-1]).total_seconds())\n",
    "            bscore = burstiness(inter) if inter else 0.0\n",
    "        else:\n",
    "            bscore = 0.0\n",
    "\n",
    "        records.append({\n",
    "            \"trans_id\": int(row[\"trans_id\"]),\n",
    "            \"timestamp\": t,\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"beneficiario_id\": row[\"beneficiario_id\"],\n",
    "            \"unidade_origem\": row[\"unidade_origem\"], # Removido area_unidade e notacao_funcional_origem\n",
    "            \"valor_pago\": val,\n",
    "            \"secs_desde_ult_trans_user\": secs_user,\n",
    "            \"secs_desde_ult_trans_par\": secs_par,\n",
    "            \"freq_user_7d\": freq_user_7d,\n",
    "            \"freq_par_7d\":  freq_par_7d,\n",
    "            \"user_valor_median_30d\": u_med,\n",
    "            \"user_valor_std_30d\": u_std,\n",
    "            \"user_robust_z\": rz_user,\n",
    "            \"par_valor_median_30d\": p_med,\n",
    "            \"par_valor_std_30d\": p_std,\n",
    "            \"par_robust_z\": rz_par,\n",
    "            \"grau_out_user\": grau_out_user,\n",
    "            \"grau_in_benef\": grau_in_benef,\n",
    "            \"grau_total_user\": grau_total_user,\n",
    "            \"grau_total_benef\": grau_total_benef,\n",
    "            \"egonet_density_user\": ego_dens_user,\n",
    "            \"par_rareza\": par_rareza,\n",
    "            \"par_burstiness\": bscore\n",
    "        })\n",
    "\n",
    "        # Atualiza marcadores \"√∫ltimo evento\" e snapshot (ap√≥s registrar features)\n",
    "        user_last_time[uN] = t\n",
    "        pair_last_time[par] = t\n",
    "        # Adiciona aresta atual no snapshot\n",
    "        if not Gsnap.has_edge(uN, vN):\n",
    "            Gsnap.add_edge(uN, vN, weight=0.0)\n",
    "        # incrementa peso\n",
    "        Gsnap[uN][vN][\"weight\"] = Gsnap[uN][vN].get(\"weight\", 0.0) + val\n",
    "\n",
    "feat_df = pd.DataFrame.from_records(records)\n",
    "print(\"Features geradas:\", feat_df.shape)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Informa√ß√µes de comportamento processadas.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIXtGuOLnkhm"
   },
   "source": [
    "###**Etapa 10:** Configura√ß√£o dos modelos matem√°ticos\n",
    "\n",
    "**Modelos utilizados**\n",
    "\n",
    "**Isolation Forest (IF)**\n",
    "\n",
    "**Mec√¢nica:** cria v√°rias √°rvores de decis√£o que ‚Äúisolam‚Äù pontos. Quanto menos cortes s√£o necess√°rios para separar uma observa√ß√£o, mais an√¥mala ela √©.\n",
    "\n",
    "**Motivo da escolha:** bom para detectar transa√ß√µes raras ou de valor at√≠pico em grandes volumes de dados.\n",
    "\n",
    "**No exemplo:** um pagamento muito acima da m√©dia do usu√°rio pode ser isolado rapidamente ‚Üí sinal de anomalia.\n",
    "\n",
    "---\n",
    "**Local Outlier Factor (LOF)**\n",
    "\n",
    "**Mec√¢nica:** compara a densidade local de vizinhos. Pontos em regi√µes menos densas s√£o marcados como outliers.\n",
    "\n",
    "**Motivo da escolha:** captura anomalias contextuais, ou seja, pagamentos que parecem ‚Äúnormais‚Äù globalmente, mas destoam do comportamento em seu grupo.\n",
    "\n",
    "**No exemplo:** se uma conta sempre paga fornecedores fixos e de repente paga um novo benefici√°rio, o LOF detecta que o padr√£o local mudou.\n",
    "\n",
    "---\n",
    "\n",
    "**One-Class SVM (opcional)**\n",
    "\n",
    "**Mec√¢nica:** aprende a fronteira do espa√ßo ‚Äúnormal‚Äù e marca pontos fora dela como an√¥malos.\n",
    "\n",
    "**Motivo da escolha:** √∫til em cen√°rios onde se deseja maior controle da taxa de outliers (via par√¢metro nu).\n",
    "\n",
    "**No exemplo:** pode ajudar a identificar transfer√™ncias fora do perfil quando s√≥ h√° poucos hist√≥ricos para treinar.\n",
    "\n",
    "---\n",
    "\n",
    "‚öñÔ∏è **Regras adicionais**\n",
    "\n",
    "- Robust Z-score: avalia se o valor do pagamento √© distante da mediana hist√≥rica (robusto a outliers).\n",
    "\n",
    "- Rareza: se a rela√ß√£o pagador‚Üíbenefici√°rio √© pouco frequente, maior chance de anomalia.\n",
    "\n",
    "- Burstiness: mede explos√µes de atividade (ex.: v√°rios pagamentos em minutos, ap√≥s dias sem atividade).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "üîÄ **Uso blended (ensemble por ranking)**\n",
    "\n",
    "- Cada modelo gera um score de anomalia.\n",
    "\n",
    "- Em vez de escolher um √∫nico, os scores s√£o convertidos em ranks e depois combinados (m√©dia).\n",
    "\n",
    "- Essa abordagem reduz o vi√©s de um modelo s√≥ e fortalece sinais consistentes.\n",
    "\n",
    "- O resultado √© um ensemble_score, cortado por percentil (ex.: 97,5%), para definir os eventos an√¥malos.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Resumo para o exemplo de monitoramento de pagamentos:**\n",
    "\n",
    "O sistema combina tr√™s algoritmos n√£o supervisionados + features baseadas em regras para capturar tanto anomalias globais (Isolation Forest), quanto locais (LOF), quanto estruturais (SVM/regra). O blended via ranking (score conjunto)  garante robustez, evitando que um √∫nico modelo domine a decis√£o.\n",
    "\n",
    "---\n",
    "**IMPORTANTE:** Primeira linha deste c√≥digo configura o percentual para corte e identifica√ß√£o de anomalia.\n",
    "\n",
    "Isso significa que os modelos tentar√£o encontrar anomalias em um intervalo de confian√ßa de 97,5% (ATUAL). Quanto menor o percentual de confian√ßa, maior o n√∫mero de \"anomalias\" (candidatos) encontrados e, possivelmente, maior o n√∫mero de FALSO POSITIVOS. Quanto maior o percentual de confian√ßa, mais exigente √© o modelo para determinar se algo √© realmente fora do comum.\n",
    "\n",
    "---\n",
    "Implementar o intervalo de confian√ßa como uma configura√ß√£o (vari√°vel) no come√ßo do C√≥digo **TODO[005]** *prioridade m√©dia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 22714,
     "status": "ok",
     "timestamp": 1759622165948,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "f9KAIqqELvKW",
    "outputId": "cc08988f-23dc-411e-a095-a43841f71f23"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "ANOMALY_PERCENTILE = 97.5  # percentil de corte (ajuste aqui)\n",
    "USE_OCSVM = False          # True para incluir One-Class SVM no ensemble\n",
    "\n",
    "model_features = [\n",
    "    \"valor_pago\",\n",
    "    \"secs_desde_ult_trans_user\", \"secs_desde_ult_trans_par\",\n",
    "    \"freq_user_7d\", \"freq_par_7d\",\n",
    "    \"user_robust_z\", \"par_robust_z\",\n",
    "    \"user_valor_median_30d\", \"par_valor_median_30d\",\n",
    "    \"grau_out_user\", \"grau_in_benef\", \"grau_total_user\", \"grau_total_benef\",\n",
    "    \"egonet_density_user\",\n",
    "    \"par_rareza\",\n",
    "    \"par_burstiness\"\n",
    "]\n",
    "\n",
    "X = feat_df[model_features].fillna(0.0).replace([np.inf, -np.inf], 0.0).values\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300, max_samples='auto', contamination='auto',\n",
    "    random_state=SEED, n_jobs=-1\n",
    ")\n",
    "iso.fit(Xs)\n",
    "iso_score = -iso.score_samples(Xs).astype(float)  # maior = mais an√¥malo, garantir float\n",
    "\n",
    "# LOF (novelty=False -> fit_predict no conjunto)\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=35, contamination='auto', novelty=False, n_jobs=-1\n",
    ")\n",
    "lof_score = -lof.fit_predict(Xs)\n",
    "# LOF retorna +1/-1; para uma pontua√ß√£o cont√≠nua mais √∫til, use negative_outlier_factor_\n",
    "lof_cont = -lof.negative_outlier_factor_.astype(float)  # maior = mais an√¥malo, garantir float\n",
    "\n",
    "# One-Class SVM (opcional)\n",
    "if USE_OCSVM:\n",
    "    ocs = OneClassSVM(gamma='scale', nu=0.01)\n",
    "    ocs.fit(Xs)\n",
    "    ocs_score = -ocs.decision_function(Xs).ravel().astype(float)\n",
    "else:\n",
    "    ocs_score = np.zeros(len(Xs), dtype=float) # Garantir dtype float\n",
    "\n",
    "# Componentes baseadas em regras\n",
    "# Normaliza robust_z (positivo -> an√¥malo)\n",
    "rz_user = np.nan_to_num(feat_df[\"user_robust_z\"].values, nan=0.0)\n",
    "rz_par  = np.nan_to_num(feat_df[\"par_robust_z\"].values, nan=0.0)\n",
    "rz_user_score = np.clip(rz_user, 0, None).astype(float) # Garantir float\n",
    "rz_par_score  = np.clip(rz_par, 0, None).astype(float) # Garantir float\n",
    "\n",
    "# Rareza (maior = mais raro = mais an√¥malo)\n",
    "rare_score = feat_df[\"par_rareza\"].values.astype(float) # Garantir float\n",
    "\n",
    "# Burstiness (>=0 j√° indica maior irregularidade)\n",
    "burst_score = np.clip(feat_df[\"par_burstiness\"].values, 0, None).astype(float) # Garantir float\n",
    "\n",
    "# Consolida\n",
    "scores = pd.DataFrame({\n",
    "    \"iso\": iso_score,\n",
    "    \"lof\": lof_cont,\n",
    "    \"ocsvm\": ocs_score,\n",
    "    \"rz_user\": rz_user_score,\n",
    "    \"rz_par\": rz_par_score,\n",
    "    \"rare\": rare_score,\n",
    "    \"burst\": burst_score\n",
    "})\n",
    "\n",
    "# Ranking por coluna (maior = mais an√¥malo)\n",
    "ranks = scores.rank(method=\"average\", ascending=True)\n",
    "ensemble_rank = ranks.mean(axis=1)\n",
    "# Converte rank em score [0,1]\n",
    "ensemble_score = (ensemble_rank - ensemble_rank.min()) / (ensemble_rank.max() - ensemble_rank.min() + 1e-9)\n",
    "\n",
    "feat_df = pd.concat([feat_df, scores.add_prefix(\"score_\")], axis=1)\n",
    "feat_df[\"ensemble_rank\"] = ensemble_rank\n",
    "feat_df[\"ensemble_score\"] = ensemble_score\n",
    "\n",
    "# Flag por percentil\n",
    "threshold = np.percentile(ensemble_score, ANOMALY_PERCENTILE)\n",
    "feat_df[\"is_anomaly\"] = (feat_df[\"ensemble_score\"] >= threshold).astype(int)\n",
    "\n",
    "print(\"Avisos de Exception n√£o representam erros relevantes. Existem solu√ß√µes alternativas j√° implementadas. \\033[1mPode prosseguir.\\033[0m\")\n",
    "print(f\"Corte (percentil {ANOMALY_PERCENTILE}%): {threshold:.4f}\")\n",
    "print(\"Total anomalias:\", int(feat_df[\"is_anomaly\"].sum()), \"de\", len(feat_df))\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "# Modificando a mensagem para incluir o n√∫mero de anomalias\n",
    "num_anomalies = int(feat_df[\"is_anomaly\"].sum())\n",
    "display(HTML(f'<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: T-800 identificou {num_anomalies} rastros da presen√ßa de Sarah Connors.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3VSSvDK45jQ"
   },
   "source": [
    "###**Etapa 11:** Salva arquivo com a an√°lise realizada.\n",
    "\n",
    "S√£o criadas subpastas para cada data/hora de execu√ß√£o do c√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "executionInfo": {
     "elapsed": 1661,
     "status": "ok",
     "timestamp": 1759622194326,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "6hqGST6gLzm9",
    "outputId": "848475f4-8912-4698-cbf4-db467794d8e6"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "cols_out = [\n",
    "    \"trans_id\",\"timestamp\",\"user_id\",\"beneficiario_id\",\"unidade_origem\", # Removido area_unidade e notacao_funcional_origem\n",
    "    \"valor_pago\",\n",
    "    \"secs_desde_ult_trans_user\",\"secs_desde_ult_trans_par\",\n",
    "    \"freq_user_7d\",\"freq_par_7d\",\"user_robust_z\",\"par_robust_z\",\n",
    "    \"grau_out_user\",\"grau_in_benef\",\"grau_total_user\",\"grau_total_benef\",\n",
    "    \"egonet_density_user\",\"par_rareza\",\"par_burstiness\",\n",
    "    \"score_iso\",\"score_lof\",\"score_ocsvm\",\"score_rz_user\",\"score_rz_par\",\"score_rare\",\"score_burst\",\n",
    "    \"ensemble_rank\",\"ensemble_score\",\"is_anomaly\"\n",
    "]\n",
    "feat_df[cols_out].to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"Gravado: {OUTPUT_CSV}\")\n",
    "\n",
    "USERS_TXT = RUN_DIR / \"usuarios_distintos.txt\"\n",
    "BENEF_TXT = RUN_DIR / \"beneficiarios_distintos.txt\"\n",
    "\n",
    "usuarios = sorted(set(feat_df[\"user_id\"].astype(str)))\n",
    "beneficiarios = sorted(set(feat_df[\"beneficiario_id\"].astype(str)))\n",
    "\n",
    "with open(USERS_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for u in usuarios:\n",
    "        f.write(f\"{u}\\n\")\n",
    "\n",
    "with open(BENEF_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for b in beneficiarios:\n",
    "        f.write(f\"{b}\\n\")\n",
    "\n",
    "print(f\"Gravado: {USERS_TXT} ({len(usuarios)} itens)\")\n",
    "print(f\"Gravado: {BENEF_TXT} ({len(beneficiarios)} itens)\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Logs gravados. A Resist√™ncia n√£o tem mais como escapar. O fim est√° pr√≥ximo.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLxsD81f96Vn"
   },
   "source": [
    "###**Etapa 12:** An√°lise Gr√°fica\n",
    "\n",
    "Distribui√ß√£o e Top-N (com corte por percentil e K sugerido por maior gap)\n",
    "\n",
    "Essa an√°lise gera dois gr√°ficos que ajudam a entender como os escores de anomalia (‚Äúensemble_score‚Äù) est√£o distribu√≠dos e quais transa√ß√µes s√£o mais suspeitas:\n",
    "\n",
    "---\n",
    "**Histograma ‚Äì Distribui√ß√£o do ensemble_score**\n",
    "\n",
    "Mostra a frequ√™ncia dos escores em toda a base.\n",
    "\n",
    "O que procurar:\n",
    "- A linha pontilhada indica o percentil de corte (ex.: Percentil 97,5). Deve ser verificado se ela cai na regi√£o da cauda, o que significa que s√≥ os casos mais extremos ser√£o analisados (evitando falsos positivos).\n",
    "- Se a maior parte dos casos est√° em valores baixos/m√©dios e existe uma cauda √† direita (valores muito altos), esses pontos de cauda s√£o os candidatos a anomalias.\n",
    "- Observar o valor correspondente ao percentil estabelecido para complementar a pr√≥xima an√°lise.\n",
    "---\n",
    "**Gr√°fico de linha ‚Äì Top N transa√ß√µes mais an√¥malas**\n",
    "\n",
    "Ordena os maiores escores (rank 1 = mais an√¥mala).\n",
    "\n",
    "O que procurar:\n",
    "- Grandes saltos (‚Äúgaps‚Äù) entre ranks consecutivos: indicam que as transa√ß√µes at√© o salto s√£o bem mais an√¥malas do que as demais ‚Äî s√£o as que merecem aten√ß√£o imediata.\n",
    "- Observar os valores de escore de anomalia encontrados nos N registros mais an√¥malos versus o valor correspondente ao percentil estabelecido. Quanto maior a diferen√ßa, mais an√¥malo.\n",
    "- Plat√¥ (curva que se estabiliza): mostra a partir de que ponto (K) os casos deixam de ser t√£o excepcionais. Observar o K sugerido pelo maior gap, ele indica quantos casos devem ser priorizados na revis√£o manual. At√© K registros s√£o candidatos muito fortes para anomalias e exigem revis√£o manual.\n",
    "---\n",
    "\n",
    "Em resumo: os gr√°ficos servem para decidir onde cortar e quais transa√ß√µes revisar primeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1759622221778,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "aHy3cf2SL7HB",
    "outputId": "ae820e3b-034f-46b9-a5e0-8d7b091a4b5d"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usa ANOMALY_PERCENTILE se j√° existir; caso contr√°rio, 97.5\n",
    "PCT = float(globals().get(\"ANOMALY_PERCENTILE\", 97.5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Histograma com linha de corte no percentil escolhido\n",
    "# ------------------------------------------------------------\n",
    "scores = feat_df[\"ensemble_score\"].astype(float).dropna().values\n",
    "cutoff = np.percentile(scores, PCT)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(scores, bins=40)\n",
    "plt.axvline(cutoff, linestyle=\"--\", linewidth=2, label=f\"P{PCT:.1f} = {cutoff:.4f}\")\n",
    "plt.title(\"Distribui√ß√£o do ensemble_score\")\n",
    "plt.xlabel(\"ensemble_score\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"dist_ensemble_score.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"[INFO] Corte por percentil: P{PCT:.1f} = {cutoff:.6f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Top-N com sugest√£o autom√°tica de K pelo maior gap\n",
    "# ------------------------------------------------------------\n",
    "TOPN = int(globals().get(\"TOPN\", 20))  # mant√©m compatibilidade com seu c√≥digo\n",
    "top = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPN).copy()\n",
    "\n",
    "# Garante colunas necess√°rias\n",
    "top = top[[\"timestamp\", \"ensemble_score\"]].reset_index(drop=True)\n",
    "top[\"rank\"] = np.arange(1, len(top) + 1)\n",
    "\n",
    "# Gap para o pr√≥ximo (quanto o score cai do rank r para r+1)\n",
    "# Obs.: o √∫ltimo fica NaN porque n√£o h√° pr√≥ximo\n",
    "vals = top[\"ensemble_score\"].to_numpy(dtype=float)\n",
    "if len(vals) >= 2:\n",
    "    deltas = vals[:-1] - vals[1:]\n",
    "    top[\"delta_next\"] = np.append(deltas, np.nan)\n",
    "\n",
    "    # √çndice do maior gap (ignora NaN). K sugerido = posi√ß√£o antes do maior salto\n",
    "    max_gap_idx = int(np.nanargmax(top[\"delta_next\"].to_numpy()))\n",
    "    K_sugerido = max_gap_idx + 1  # +1 porque ranks come√ßam em 1\n",
    "    max_gap_val = float(top.loc[max_gap_idx, \"delta_next\"])\n",
    "else:\n",
    "    top[\"delta_next\"] = np.nan\n",
    "    K_sugerido = len(top)\n",
    "    max_gap_val = np.nan\n",
    "\n",
    "# Plot do Top-N\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(top[\"rank\"], top[\"ensemble_score\"], marker=\"o\")\n",
    "plt.title(f\"Top {TOPN} transa√ß√µes mais an√¥malas (ensemble)\")\n",
    "plt.xlabel(\"rank (1 = mais an√¥mala)\")\n",
    "plt.ylabel(\"ensemble_score\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Linha vertical no K sugerido (se houver pelo menos 2 pontos)\n",
    "if len(top) >= 2 and np.isfinite(K_sugerido) and K_sugerido >= 1:\n",
    "    plt.axvline(K_sugerido, linestyle=\"--\", linewidth=2, alpha=0.7,\n",
    "                label=f\"K sugerido = {K_sugerido} (maior gap Œî={max_gap_val:.4f})\")\n",
    "    # Texto discreto pr√≥ximo ao topo da linha\n",
    "    y_annot = np.nanmax(top[\"ensemble_score\"].to_numpy()) if len(top) > 0 else 0\n",
    "    plt.text(K_sugerido + 0.2, y_annot, f\"K={K_sugerido}\", va=\"top\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(FIG_DIR / \"top_anomalias.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Logs informativos\n",
    "if len(top) >= 2:\n",
    "    print(f\"[INFO] Maior gap no Top-{TOPN} entre ranks {K_sugerido} e {K_sugerido + 1}: \"\n",
    "          f\"Œî={max_gap_val:.6f}. Sugest√£o de K={K_sugerido}.\")\n",
    "else:\n",
    "    print(f\"[INFO] Top-{TOPN} cont√©m menos de 2 itens; K sugerido = {K_sugerido}.\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: A Resist√™ncia √© muito previs√≠vel!</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pci7t0AZLcVr"
   },
   "source": [
    "###**Etapa 13:** Ego-Subgrafo\n",
    "\n",
    "Abaixo √© gerado um ego-subgrafo em torno do usu√°rio envolvido na transa√ß√£o mais an√¥mala, mostrando suas conex√µes diretas no grafo de pagamentos.\n",
    "\n",
    "**O que ele pretende demonstrar:**\n",
    "\n",
    "Quem est√° conectado ao usu√°rio central, a intensidade e frequ√™ncia das transa√ß√µes (espessura das arestas), a relev√¢ncia de cada n√≥ (tamanho proporcional ao grau de conex√µes) e pap√©is distintos dos n√≥s, facilitando a leitura do contexto da anomalia.\n",
    "\n",
    "---\n",
    "**Como analisar:**\n",
    "\n",
    " üîµ Azul = usu√°rio central (o mais an√¥malo).\n",
    "\n",
    " üî¥ Vermelho = predecessores (quem se conecta a ele/quem paga ele - predecessor).\n",
    "\n",
    " üü¢ Verde = sucessores (quem recebe dele - sucessor).\n",
    "\n",
    " ‚ö™ Cinza = outros n√≥s relacionados.\n",
    "\n",
    "- Tamanho do n√≥: quanto maior, mais conex√µes tem (pode indicar comportamento de hub).\n",
    "\n",
    "- Espessura das arestas: mais grossas significam maior valor ou frequ√™ncia de transa√ß√µes.\n",
    "\n",
    "---\n",
    "**Interpreta√ß√£o pr√°tica**\n",
    "\n",
    "- Estrela de sa√≠da (um n√≥ azul/central pagando muitos verdes) ‚Üí poss√≠vel dispers√£o suspeita.\n",
    "- Muitos vermelhos conectados a ele ‚Üí poss√≠vel conta ‚Äúcoletora‚Äù.\n",
    "- Ciclos ou arestas bidirecionais ‚Üí podem indicar movimenta√ß√£o circular de valores.\n",
    "\n",
    "\n",
    "üëâ Em resumo: o gr√°fico mostra a vizinhan√ßa imediata do usu√°rio mais an√¥malo, destacando quem paga, quem recebe e a for√ßa dessas rela√ß√µes, para facilitar a investiga√ß√£o do porqu√™ desse score elevado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1759603977797,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "OPRiW28qL_Bt",
    "outputId": "b603e17c-488d-4b53-8ec1-7e243656d7c8"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "try:\n",
    "    worst = feat_df.sort_values(\"ensemble_score\", ascending=False).iloc[0]\n",
    "    uN = f\"U::{worst['user_id']}\"\n",
    "\n",
    "    # Ego-subgrafo do usu√°rio no snapshot final (Gsnap)\n",
    "    if uN in Gsnap:\n",
    "        ego_nodes = set(Gsnap.predecessors(uN)) | set(Gsnap.successors(uN)) | {uN}\n",
    "        sub = Gsnap.subgraph(ego_nodes).copy()\n",
    "\n",
    "        # Posi√ß√µes fixas para layout consistente\n",
    "        pos = nx.spring_layout(sub, seed=SEED)\n",
    "\n",
    "        # Definir atributos visuais\n",
    "        node_colors, node_sizes, node_borders = [], [], []\n",
    "        for n in sub.nodes():\n",
    "            if n == uN:\n",
    "                node_colors.append(\"skyblue\")      # usu√°rio central\n",
    "                node_borders.append(\"black\")\n",
    "            elif Gsnap.has_edge(n, uN):           # predecessores\n",
    "                node_colors.append(\"tomato\")\n",
    "                node_borders.append(\"black\")\n",
    "            elif Gsnap.has_edge(uN, n):           # sucessores\n",
    "                node_colors.append(\"lightgreen\")\n",
    "                node_borders.append(\"black\")\n",
    "            else:\n",
    "                node_colors.append(\"gray\")\n",
    "                node_borders.append(\"black\")\n",
    "            node_sizes.append(300 + 50 * sub.degree(n))\n",
    "\n",
    "        # Espessura das arestas proporcional ao peso se existir\n",
    "        edge_widths = []\n",
    "        for u, v in sub.edges():\n",
    "            w = sub[u][v].get(\"weight\", 1.0)  # valor ou frequ√™ncia da transa√ß√£o\n",
    "            edge_widths.append(0.5 + 2.0 * (w / max(1.0, max([d.get(\"weight\",1.0) for _,_,d in sub.edges(data=True)]))))\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(7,6))\n",
    "        nx.draw_networkx_nodes(sub, pos, node_color=node_colors,\n",
    "                               node_size=node_sizes,\n",
    "                               edgecolors=node_borders, linewidths=1.2)\n",
    "        nx.draw_networkx_edges(sub, pos, arrows=True, arrowsize=12,\n",
    "                               width=edge_widths, alpha=0.8)\n",
    "        nx.draw_networkx_labels(\n",
    "            sub, pos,\n",
    "            labels={n: n.split(\"::\")[-1] for n in sub.nodes()},  # s√≥ parte final do ID\n",
    "            font_size=8\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Ego-subgrafo do usu√°rio {worst['user_id']} (mais an√¥malo)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / \"ego_user_top1.png\", dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Usu√°rio n√£o encontrado no snapshot para visualiza√ß√£o.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Falha na visualiza√ß√£o de subgrafo:\", e)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: N√≥s os temos na palma de nossas m√£os, ou melhor, no centro de nossos pesos sin√°pticos.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEXQlkPjNINU"
   },
   "source": [
    "###**Etapa 14:** Gerar ego-grafo temporal para TOP-K anomalias\n",
    "\n",
    "K fixado para 20\n",
    "\n",
    "Salva as imagens em PNG na pasta de execu√ß√£o para an√°lise posterior.\n",
    "\n",
    "---\n",
    "Avaliar pertin√™ncia de gerar o ego-grafo para todas as anomalias **TODO[006]** *prioridade m√©dia*\n",
    "\n",
    "Avaliar definir o corte K de forma din√¢mica nas configura√ß√µes e considerando a an√°lise realizada no gr√°fico **TODO[007]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "executionInfo": {
     "elapsed": 21600,
     "status": "ok",
     "timestamp": 1759622261669,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "98vsc8NBME1M",
    "outputId": "749502d8-b834-493a-b27c-2f9acba7d9cd"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "TOPK = 20                   # quantos casos an√¥malos detalhar\n",
    "EGO_RADIUS = 2              # 1: vizinhos imediatos; pode aumentar para 2 (mais denso)\n",
    "WINDOW_DAYS = 30            # janela temporal para contexto\n",
    "EDGE_ALPHA = 0.75           # transpar√™ncia das arestas\n",
    "\n",
    "top_anoms = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPK).copy()\n",
    "\n",
    "def snapshot_graph_until(df_all, t_cutoff):\n",
    "    # cria snapshot dirigido com arestas at√© t_cutoff\n",
    "    g = nx.DiGraph()\n",
    "    sub = df_all[df_all[\"timestamp\"] <= t_cutoff]\n",
    "    for _, r in sub.iterrows():\n",
    "        uN = f\"U::{r['user_id']}\"\n",
    "        vN = f\"B::{r['beneficiario_id']}\"\n",
    "        if uN not in g: g.add_node(uN, tipo=\"user\")\n",
    "        if vN not in g: g.add_node(vN, tipo=\"benef\")\n",
    "        if not g.has_edge(uN, vN):\n",
    "            g.add_edge(uN, vN, weight=0.0, count=0)\n",
    "        g[uN][vN][\"weight\"] += float(r[\"valor_pago\"])\n",
    "        g[uN][vN][\"count\"]  += 1\n",
    "    return g\n",
    "\n",
    "def draw_case_png(case_row, rank_idx):\n",
    "    t_event = pd.to_datetime(case_row[\"timestamp\"])\n",
    "    t_start = t_event - pd.Timedelta(days=WINDOW_DAYS)\n",
    "    # filtra por janela\n",
    "    df_win = df[(df[\"timestamp\"] >= t_start) & (df[\"timestamp\"] <= t_event)].copy()\n",
    "    Gwin = snapshot_graph_until(df_win, t_event)\n",
    "\n",
    "    uN = f\"U::{case_row['user_id']}\"\n",
    "    vN = f\"B::{case_row['beneficiario_id']}\"\n",
    "\n",
    "    # monta conjunto de n√≥dulo foco: usu√°rio e benefici√°rio\n",
    "    focus = {uN, vN}\n",
    "    nodes_ego = set(focus)\n",
    "    # expande uma vez (EGO_RADIUS = 1) para vizinhos diretos\n",
    "    for node in list(focus):\n",
    "        if node in Gwin:\n",
    "            nodes_ego |= set(Gwin.predecessors(node))\n",
    "            nodes_ego |= set(Gwin.successors(node))\n",
    "\n",
    "    sub = Gwin.subgraph(nodes_ego).copy()\n",
    "    if sub.number_of_nodes() == 0:\n",
    "        print(f\"[Aviso] Subgrafo vazio para trans {case_row['trans_id']}. Pulando.\")\n",
    "        return None\n",
    "\n",
    "    pos = nx.spring_layout(sub, seed=SEED)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # cor por tipo\n",
    "    node_colors = []\n",
    "    for n in sub.nodes():\n",
    "        tipo = sub.nodes[n].get(\"tipo\",\"?\")\n",
    "        if tipo == \"user\":\n",
    "            node_colors.append(\"tab:blue\")\n",
    "        elif tipo == \"benef\":\n",
    "            node_colors.append(\"tab:green\")\n",
    "        else:\n",
    "            node_colors.append(\"tab:gray\")\n",
    "\n",
    "    nx.draw_networkx_nodes(sub, pos, node_size=300, node_color=node_colors, alpha=0.9, linewidths=0.5, edgecolors=\"black\")\n",
    "    # largura proporcional ao log do peso\n",
    "    widths = []\n",
    "    for (a,b) in sub.edges():\n",
    "        w = sub[a][b].get(\"weight\", 1.0)\n",
    "        widths.append(1.0 + math.log10(max(w, 1.0)))\n",
    "    nx.draw_networkx_edges(sub, pos, arrows=True, arrowsize=12, width=widths, alpha=EDGE_ALPHA)\n",
    "    nx.draw_networkx_labels(sub, pos, font_size=7)\n",
    "\n",
    "    title = (f\"Anomalia #{rank_idx:02d} | trans_id={case_row['trans_id']} | \"\n",
    "             f\"user={case_row['user_id']} ‚Üí benef={case_row['beneficiario_id']} | \"\n",
    "             f\"score={case_row['ensemble_score']:.3f} | janela={WINDOW_DAYS}d\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    outpath = FIG_DIR / f\"anomaly_{rank_idx:02d}_trans_{int(case_row['trans_id'])}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close()\n",
    "    return outpath\n",
    "\n",
    "generated_pngs = []\n",
    "for i, (_, row) in enumerate(top_anoms.iterrows(), start=1):\n",
    "    pth = draw_case_png(row, i)\n",
    "    if pth is not None:\n",
    "        generated_pngs.append(str(pth))\n",
    "print(f\"Geradas {len(generated_pngs)} figuras de casos an√¥malos em {FIG_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Registros ser√£o utilizados para aprimorar o c√≥digo de batalha das unidades T-800 e T-1000.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOGFtF0_sFNF"
   },
   "source": [
    "###**Etapa 15:** Gera√ß√£o de relat√≥rio em HTML e PDF com imagens imbutidas\n",
    "---\n",
    "Identificar estat√≠sticas e informa√ß√µes de interesse e incluir nos Relat√≥rios **TODO[008]** *prioridade alta*\n",
    "\n",
    "Transferir instala√ß√£o de biblioteca para todo do c√≥digo [!pip -q install \"reportlab==3.6.12\"] **TODO[009]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1759622999466,
     "user": {
      "displayName": "Leandro Bernardo",
      "userId": "10368351959047723286"
     },
     "user_tz": 180
    },
    "id": "jZCriT_hMi_F",
    "outputId": "15f6b5a0-234a-4bd0-b3df-47b6dbba845e"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "REL_HTML = RUN_DIR / \"relatorio.html\"\n",
    "\n",
    "def html_escape(s):\n",
    "    return (str(s)\n",
    "            .replace(\"&\",\"&amp;\")\n",
    "            .replace(\"<\",\"&lt;\")\n",
    "            .replace(\">\",\"&gt;\")\n",
    "            .replace('\"',\"&quot;\")\n",
    "            .replace(\"'\",\"&#39;\"))\n",
    "\n",
    "top_tbl = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPK).copy()\n",
    "tbl_cols = [\"trans_id\",\"timestamp\",\"user_id\",\"beneficiario_id\",\"valor_pago\",\n",
    "            \"ensemble_score\",\"score_iso\",\"score_lof\",\"score_rz_user\",\"score_rz_par\",\"score_rare\",\"score_burst\"]  # Removido score_ocs\n",
    "top_tbl[\"timestamp\"] = top_tbl[\"timestamp\"].astype(str)\n",
    "\n",
    "# monta tabela HTML\n",
    "rows_html = []\n",
    "for _, r in top_tbl.iterrows():\n",
    "    cells = \"\".join([f\"<td>{html_escape(r[c])}</td>\" for c in tbl_cols])\n",
    "    rows_html.append(f\"<tr>{cells}</tr>\")\n",
    "table_html = f\"\"\"\n",
    "<table border=\"1\" cellspacing=\"0\" cellpadding=\"6\">\n",
    "  <thead><tr>\n",
    "    {''.join([f'<th>{c}</th>' for c in tbl_cols])}\n",
    "  </tr></thead>\n",
    "  <tbody>\n",
    "    {''.join(rows_html)}\n",
    "  </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "# galeria de imagens (embutidas em base64)\n",
    "import base64, os\n",
    "imgs_html = \"\"\n",
    "for p in generated_pngs:\n",
    "    try:\n",
    "        with open(p, \"rb\") as img_file:\n",
    "            img_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "        imgs_html += f'<div style=\"display:inline-block;margin:8px;text-align:center;\"><img src=\"data:image/png;base64,{img_data}\" width=\"360\"><br><small>{html_escape(os.path.basename(p))}</small></div>'\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] N√£o foi poss√≠vel embutir a imagem {p}: {e}\")\n",
    "\n",
    "html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"pt-br\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>Relat√≥rio de Anomalias ‚Äî {html_escape(run_id)}</title>\n",
    "<style>\n",
    "body{{font-family:Arial,Helvetica,sans-serif; margin:24px;}}\n",
    "h1,h2,h3{{margin-top:1.2em;}}\n",
    "code,pre{{background:#f5f5f5; padding:2px 4px;}}\n",
    ".small{{color:#666; font-size:0.9em;}}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Relat√≥rio de Anomalias</h1>\n",
    "<p class=\"small\">Execu√ß√£o: <b>{html_escape(run_id)}</b><br>\n",
    "Criado em: {html_escape(meta['created_at'])}</p>\n",
    "\n",
    "<h2>Par√¢metros principais</h2>\n",
    "<ul>\n",
    "  <li>TOPK: {TOPK}</li>\n",
    "  <li>Percentil de corte: {ANOMALY_PERCENTILE}%</li>\n",
    "  <li>Janela temporal (casos): {WINDOW_DAYS} dias</li>\n",
    "  <li>M√©todos no ensemble: IsolationForest, LOF{', OneClassSVM' if 'score_ocsvm' in feat_df.columns and feat_df['score_ocsvm'].sum()!=0 else ''}, z-scores, rareza, burstiness</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Distribui√ß√µes</h2>\n",
    "<p>Arquivos gerados em <code>{html_escape(str(FIG_DIR))}</code>:</p>\n",
    "<ul>\n",
    "  <li><code>dist_ensemble_score.png</code></li>\n",
    "  <li><code>top_anomalias.png</code></li>\n",
    "</ul>\n",
    "<p><i>As imagens de distribui√ß√£o e Top N n√£o est√£o embutidas neste relat√≥rio para manter o tamanho do arquivo menor. Consulte a pasta '{html_escape(str(FIG_DIR))}' para visualiz√°-las.</i></p>\n",
    "\n",
    "<h2>Top {TOPK} transa√ß√µes an√¥malas</h2>\n",
    "{table_html}\n",
    "\n",
    "<h2>Galeria (ego-grafos por caso)</h2>\n",
    "{imgs_html if imgs_html else \"<p><i>Sem imagens geradas.</i></p>\"}\n",
    "\n",
    "<h2>Arquivos desta execu√ß√£o</h2>\n",
    "<ul>\n",
    "  <li><code>Input.csv</code> (c√≥pia do insumo)</li>\n",
    "  <li><code>output.csv</code> (resultado com flag <code>is_anomaly</code>)</li>\n",
    "  <li><code>log.txt</code></li>\n",
    "  <li><code>run_meta.json</code></li>\n",
    "  <li><code>usuarios_distintos.txt</code>, <code>beneficiarios_distintos.txt</code></li>\n",
    "</ul>\n",
    "\n",
    "<p class=\"small\">¬© {datetime.now().year} ‚Äî Relat√≥rio gerado automaticamente.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "with open(REL_HTML, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(f\"Relat√≥rio HTML salvo em: {REL_HTML}\")\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import cm\n",
    "\n",
    "PDF_PATH = RUN_DIR / \"relatorio_resumo.pdf\"\n",
    "\n",
    "c = canvas.Canvas(str(PDF_PATH), pagesize=A4)\n",
    "W, H = A4\n",
    "x, y = 2*cm, H - 2*cm\n",
    "\n",
    "def write_line(text, size=10, leading=12):\n",
    "    global y\n",
    "    c.setFont(\"Helvetica\", size)\n",
    "    c.drawString(x, y, text)\n",
    "    y -= leading\n",
    "    if y < 2*cm:\n",
    "        c.showPage()\n",
    "        init_page()\n",
    "\n",
    "def init_page():\n",
    "    global x, y\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    c.drawString(2*cm, H - 2*cm, \"Relat√≥rio de Anomalias (Resumo)\")\n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    c.drawString(2*cm, H - 2.5*cm, f\"Execu√ß√£o: {run_id}\")\n",
    "    c.drawString(2*cm, H - 2.9*cm, f\"Data: {datetime.now().isoformat(timespec='seconds')}\")\n",
    "    y = H - 3.5*cm\n",
    "\n",
    "init_page()\n",
    "write_line(f\"TOPK: {TOPK} | Corte: p{ANOMALY_PERCENTILE} | Janela: {WINDOW_DAYS}d\")\n",
    "\n",
    "# cabe√ßalho da 'tabela'\n",
    "write_line(\"-\"*95)\n",
    "write_line(\"trans_id | timestamp         | user -> benef | valor | ensemble | iso | lof | rz_u | rz_p | rare | burst\", 8, 10)\n",
    "write_line(\"-\"*95)\n",
    "\n",
    "for _, r in top_tbl.iterrows():\n",
    "    line = (f\"{int(r['trans_id']):7d} | {str(r['timestamp'])[:19]:19s} | \"\n",
    "            f\"{str(r['user_id'])[:8]}‚Üí{str(r['beneficiario_id'])[:8]:8s} | \"\n",
    "            f\"{float(r['valor_pago']):.2f} | {float(r['ensemble_score']):.3f} | \"\n",
    "            f\"{float(r['score_iso']):.2f} | {float(r['score_lof']):.2f} | \"\n",
    "            f\"{float(r['score_rz_user']):.2f} | {float(r['score_rz_par']):.2f} | \"\n",
    "            f\"{float(r['score_rare']):.2f} | {float(r['score_burst']):.2f}\")\n",
    "    write_line(line, 8, 10)\n",
    "\n",
    "c.showPage()\n",
    "c.save()\n",
    "print(f\"PDF salvo em: {PDF_PATH}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>ü§ñ Skynet</b>: Fim do jogo. A Humanidade perdeu. D√°-se in√≠cio √† Era das M√°quinas.</div>'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOPhKC6nQzYT6UwLojl0OzI",
   "collapsed_sections": [
    "sqpYiRa1Ub5T",
    "QX0x9aXfTJeA",
    "NEZkMD3_hUXq"
   ],
   "mount_file_id": "1J-iuHr7Sn1al5Mn2qZiO1zzF7Ne-YKK9",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
