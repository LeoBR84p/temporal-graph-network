{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqpYiRa1Ub5T"
   },
   "source": [
    "#**Licença de Uso**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsA_nGhh8Psj"
   },
   "source": [
    "This repository uses a **dual-license model** to distinguish between source code and creative/documental content.\n",
    "\n",
    "**Code** (Python scripts, modules, utilities):\n",
    "Licensed under the MIT License.\n",
    "\n",
    "→ You may freely use, modify, and redistribute the code, including for commercial purposes, provided that you preserve the copyright notice.\n",
    "\n",
    "**Content** (Jupyter notebooks, documentation, reports, datasets, and generated outputs):\n",
    "Licensed under the Creative Commons Attribution–NonCommercial 4.0 International License.\n",
    "\n",
    "→ You may share and adapt the content for non-commercial purposes, provided that proper credit is given to the original author.\n",
    "\n",
    "\n",
    "**© 2025 Leandro Bernardo Rodrigues**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyszD9eYTtAS"
   },
   "source": [
    "#**Pré-Configuração**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX0x9aXfTJeA"
   },
   "source": [
    "##**Código de uso único**\n",
    "Aplicação persistente entre sessões do Google Colab\n",
    "\n",
    "---\n",
    "**Uso expecífico para Google Colab.**\n",
    "\n",
    "**Aviso:** implementação no JupytherHub e GitLab são diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "otaQwrjJSgOQ"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#montar o Google Drive e preparar a pasta do projeto\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os, subprocess, getpass, pathlib\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "%cd \"$BASE\"\n",
    "\n",
    "#clonar o repositório existente do GitHub (se ainda não estiver clonado) ===\n",
    "if not os.path.exists(PROJ):\n",
    "    GITHUB_URL = \"https://github.com/LeoBR84p/temporal-graph-network.git\"\n",
    "    # Dica: use PAT quando o push for necessário; para clone público basta a URL.\n",
    "    !git clone $GITHUB_URL\n",
    "else:\n",
    "    print(\"Pasta do projeto já existe, seguindo adiante...\")\n",
    "%cd \"$PROJ\"\n",
    "\n",
    "#criar pastas utilitárias que você quer manter no projeto ===\n",
    "#não sobrescreve nada; só cria se não existirem\n",
    "!mkdir -p notebooks src data output runs configs\n",
    "\n",
    "#instalar pacotes (na sessão atual) para conseguir configurar os filtros ===\n",
    "!pip -q install jupytext nbdime nbstripout\n",
    "\n",
    "#configurar Git/NBDime/Jupytext no *repositório* (persistem em .git/config) ===\n",
    "#usar --local faz a config ficar gravada em .git/config (persiste no Drive)\n",
    "!git config --local user.name \"Leandro Bernardo Rodrigues\"\n",
    "!git config --local user.email \"bernardo.leandro@gmail.com\"\n",
    "!git config --local init.defaultBranch main\n",
    "\n",
    "# OBS: no Colab, o nbdime com --local pode falhar; use --global nesta sessão\n",
    "!nbdime config-git --enable --global\n",
    "\n",
    "#.gitignore e .gitattributes (só criar se não existirem) ===\n",
    "if not pathlib.Path(\".gitignore\").exists():\n",
    "    with open(\".gitignore\",\"w\") as f:\n",
    "        f.write(\"\"\"\\\n",
    ".ipynb_checkpoints/\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "*.log\n",
    "*.tmp\n",
    "# dados/artefatos pesados (não versionar)\n",
    "data/\n",
    "output/\n",
    "runs/\n",
    "# Python\n",
    "venv/\n",
    "__pycache__/\n",
    "*.pyc\n",
    "# segredos\n",
    ".env\n",
    "*.key\n",
    "*.pem\n",
    "*.tok\n",
    "\"\"\")\n",
    "if not pathlib.Path(\".gitattributes\").exists():\n",
    "    with open(\".gitattributes\",\"w\") as f:\n",
    "        f.write(\"*.ipynb filter=nbstripout\\n\")\n",
    "\n",
    "#ativar o hook do nbstripout neste repositório (persiste)\n",
    "!nbstripout --install --attributes .gitattributes\n",
    "\n",
    "#parear notebooks com .py para diffs legíveis ===\n",
    "!jupytext --set-formats ipynb,py:percent --sync notebooks/*.ipynb || true\n",
    "\n",
    "#commit inicial dessas configs locais (se houver algo novo) e push ===\n",
    "!git add -A\n",
    "!git status\n",
    "!git commit -m \"chore: setup local (.gitignore/.gitattributes, nbstripout, jupytext config)\" || true\n",
    "\n",
    "#se o remoto já tem README/commits, faça pull --rebase antes do primeiro push\n",
    "!git pull --rebase origin main || true\n",
    "\n",
    "#push (ao pedir senha, use seu PAT como senha do Git)\n",
    "import getpass, subprocess, sys\n",
    "\n",
    "owner = \"LeoBR84p\"\n",
    "repo  = \"temporal-graph-network\"\n",
    "clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "\n",
    "# 1) Tenta push \"normal\" (pode falhar por falta de credencial)\n",
    "push = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "if push.returncode == 0:\n",
    "    print(\"Push concluído sem PAT.\")\n",
    "else:\n",
    "    print(\"Primeiro push falhou (provável falta de credenciais). Vamos usar um PAT temporário…\")\n",
    "    # 2) Pede o PAT e testa autenticação antes do push\n",
    "    token = getpass.getpass(\"Cole seu GitHub PAT (não será exibido): \").strip()\n",
    "    # Formato mais compatível: user + token na URL\n",
    "    # Use seu usuário real do GitHub (case sensitive)\n",
    "    username = \"LeoBR84p\"\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "\n",
    "    try:\n",
    "        # Teste rápido de auth (ls-remote) para ver se o token tem acesso de escrita\n",
    "        test = subprocess.run([\"git\",\"ls-remote\", auth_url],\n",
    "                              capture_output=True, text=True)\n",
    "        if test.returncode != 0:\n",
    "            print(\"Falha ao autenticar com o PAT. Detalhe do erro:\")\n",
    "            print(test.stderr or test.stdout)\n",
    "            raise SystemExit(1)\n",
    "\n",
    "        # 3) Troca a URL, faz push e restaura a URL limpa\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"Falha no push mesmo com PAT. Detalhe do erro:\")\n",
    "            print(out.stderr or out.stdout)\n",
    "            raise SystemExit(out.returncode)\n",
    "        print(\"Push concluído com PAT.\")\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", clean_url], check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYTsrVeiUEYt"
   },
   "source": [
    "##**Código a cada sessão**\n",
    "---\n",
    "Aplicação não persistente entre sessões.\n",
    "\n",
    "Necessário para sincronização e versionamento de alterações no código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUkAzsYgCRv"
   },
   "source": [
    "###**Montar e sincronizar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2aoXCRgAUYod"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#setup por sessão (colab)\n",
    "from google.colab import drive\n",
    "import os, time, subprocess, getpass, pathlib, sys\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "\n",
    "def safe_mount_google_drive():\n",
    "    #monta ou remonta o google drive de forma resiliente\n",
    "    try:\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "    except Exception:\n",
    "        try:\n",
    "            drive.flush_and_unmount()\n",
    "        except Exception:\n",
    "            pass\n",
    "        time.sleep(1.0)\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "def safe_chdir(path):\n",
    "    #usa os.chdir (evita %cd com f-string)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Caminho não existe: {path}\")\n",
    "    os.chdir(path)\n",
    "    print(\"Diretório atual:\", os.getcwd())\n",
    "\n",
    "def branch_a_frente():\n",
    "    #retorna true se head está à frente do upstream (há o que enviar)\n",
    "    ahead = subprocess.run(\n",
    "        [\"git\",\"rev-list\",\"--left-right\",\"--count\",\"HEAD...@{upstream}\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if ahead.returncode != 0:\n",
    "        status = subprocess.run([\"git\",\"status\",\"-sb\"], capture_output=True, text=True)\n",
    "        return \"ahead\" in (status.stdout or \"\")\n",
    "    left_right = (ahead.stdout or \"\").strip().split()\n",
    "    return len(left_right) == 2 and left_right[0].isdigit() and int(left_right[0]) > 0\n",
    "\n",
    "def push_seguro(owner=\"LeoBR84p\", repo=\"temporal-graph-network\", username=\"LeoBR84p\"):\n",
    "    #realiza push usando pat em memória; restaura url limpa ao final\n",
    "    clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "    token = getpass.getpass(\"Cole seu GitHub PAT (Contents: Read and write): \").strip()\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "    test = subprocess.run([\"git\",\"ls-remote\", auth_url], capture_output=True, text=True)\n",
    "    if test.returncode != 0:\n",
    "        print(\"Falha na autenticação (read). Revise token/permissões:\")\n",
    "        print(test.stderr or test.stdout); return\n",
    "    try:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"Falha no push (write). Revise permissões do token:\")\n",
    "            print(out.stderr or out.stdout)\n",
    "        else:\n",
    "            print(\"Push concluído com PAT.\")\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\",\"origin\", clean_url], check=False)\n",
    "\n",
    "#montar/remontar o google drive e entrar no projeto\n",
    "safe_mount_google_drive()\n",
    "os.makedirs(BASE, exist_ok=True)\n",
    "if not os.path.exists(PROJ):\n",
    "    print(f\"Atenção: pasta do projeto não encontrada em {PROJ}. \"\n",
    "          \"Execute seu bloco de configuração única (clone) primeiro.\")\n",
    "else:\n",
    "    print(\"Pasta do projeto encontrada.\")\n",
    "safe_chdir(PROJ)\n",
    "\n",
    "#sanity check do repositório git\n",
    "if not os.path.isdir(\".git\"):\n",
    "    print(\"Aviso: esta pasta não parece ser um repositório Git (.git ausente). \"\n",
    "          \"Rode o bloco de configuração única.\")\n",
    "else:\n",
    "    print(\"Repositório Git detectado.\")\n",
    "\n",
    "#instalar dependências efêmeras desta sessão\n",
    "!pip -q install jupytext nbdime nbstripout\n",
    "!nbdime config-git --enable --global\n",
    "\n",
    "#atualizar do remoto\n",
    "!git fetch origin\n",
    "!git pull --rebase origin main\n",
    "\n",
    "#sincronizar notebooks → .py (jupytext)\n",
    "!jupytext --sync notebooks/*.ipynb || true\n",
    "\n",
    "#ciclo de versionamento do dia (commit genérico opcional)\n",
    "!git add -A\n",
    "!git status\n",
    "!git commit -m \"feat: ajustes no notebook X e pipeline Y\" || true\n",
    "\n",
    "#push somente se houver commits locais à frente; com fallback para pat\n",
    "if branch_a_frente():\n",
    "    out = subprocess.run([\"git\",\"push\",\"origin\",\"main\"], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(\"Push concluído sem PAT.\")\n",
    "    else:\n",
    "        print(\"Push sem PAT falhou. Chamando push_seguro()…\")\n",
    "        push_seguro()\n",
    "else:\n",
    "    print(\"Nada para enviar (branch sincronizada com o remoto).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF-bzXqkfjsX"
   },
   "source": [
    "###**Utilitários Git**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "mWTE_5SOfos5"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#helpers de git: push seguro, commit customizado e tag de release\n",
    "import subprocess, getpass\n",
    "\n",
    "#ajuste se você mudar o nome do repositório/usuário\n",
    "OWNER = \"LeoBR84p\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "USERNAME = \"LeoBR84p\"\n",
    "BRANCH = \"main\"\n",
    "REMOTE = \"origin\"\n",
    "\n",
    "def branch_a_frente():\n",
    "    #retorna true se head está à frente do upstream (há o que enviar)\n",
    "    out = subprocess.run(\n",
    "        [\"git\",\"rev-list\",\"--left-right\",\"--count\",f\"HEAD...@{{upstream}}\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if out.returncode != 0:\n",
    "        st = subprocess.run([\"git\",\"status\",\"-sb\"], capture_output=True, text=True)\n",
    "        return \"ahead\" in (st.stdout or \"\")\n",
    "    left_right = (out.stdout or \"\").strip().split()\n",
    "    return len(left_right) == 2 and left_right[0].isdigit() and int(left_right[0]) > 0\n",
    "\n",
    "def push_seguro(owner=OWNER, repo=REPO, username=USERNAME, remote=REMOTE, branch=BRANCH):\n",
    "    #realiza push usando pat em memória; restaura url limpa ao final\n",
    "    clean_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "    token = getpass.getpass(\"cole seu github pat (contents: read and write): \").strip()\n",
    "    auth_url = f\"https://{username}:{token}@github.com/{owner}/{repo}.git\"\n",
    "    test = subprocess.run([\"git\",\"ls-remote\", auth_url], capture_output=True, text=True)\n",
    "    if test.returncode != 0:\n",
    "        print(\"falha na autenticação (read). revise token/permissões:\")\n",
    "        print(test.stderr or test.stdout); return False\n",
    "    try:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\", remote, auth_url], check=True)\n",
    "        out = subprocess.run([\"git\",\"push\", remote, branch], capture_output=True, text=True)\n",
    "        if out.returncode != 0:\n",
    "            print(\"falha no push (write). revise permissões do token:\")\n",
    "            print(out.stderr or out.stdout); return False\n",
    "        print(\"push concluído com pat.\")\n",
    "        return True\n",
    "    finally:\n",
    "        subprocess.run([\"git\",\"remote\",\"set-url\", remote, clean_url], check=False)\n",
    "\n",
    "def try_push_branch(remote=REMOTE, branch=BRANCH):\n",
    "    #tenta push direto da branch atual\n",
    "    out = subprocess.run([\"git\",\"push\", remote, branch], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(\"push concluído.\")\n",
    "        return True\n",
    "    print(\"push sem credencial falhou:\")\n",
    "    print((out.stderr or out.stdout).strip())\n",
    "    return False\n",
    "\n",
    "def try_push_tag(tag, remote=REMOTE):\n",
    "    #tenta enviar somente a tag\n",
    "    out = subprocess.run([\"git\",\"push\", remote, tag], capture_output=True, text=True)\n",
    "    if out.returncode == 0:\n",
    "        print(f\"tag enviada: {tag}\")\n",
    "        return True\n",
    "    print(\"falha ao enviar a tag:\")\n",
    "    print((out.stderr or out.stdout).strip())\n",
    "    return False\n",
    "\n",
    "def commit_custom(msg: str, auto_push: bool = True):\n",
    "    #adiciona tudo, cria commit com a mensagem informada e faz push opcional (com fallback para pat)\n",
    "    subprocess.run([\"git\",\"add\",\"-A\"], check=False)\n",
    "    com = subprocess.run([\"git\",\"commit\",\"-m\", msg], capture_output=True, text=True)\n",
    "    if com.returncode != 0:\n",
    "        print((com.stderr or com.stdout or \"nada para commitar.\").strip())\n",
    "        return\n",
    "    print(com.stdout.strip())\n",
    "    if auto_push and branch_a_frente():\n",
    "        if not try_push_branch():\n",
    "            print(\"tentando push seguro…\")\n",
    "            push_seguro()\n",
    "\n",
    "def tag_release(tag: str, message: str = \"\", auto_push: bool = True):\n",
    "    #cria uma tag anotada (release) e faz push da tag com fallback para pat\n",
    "    exists = subprocess.run([\"git\",\"tag\",\"--list\", tag], capture_output=True, text=True)\n",
    "    if tag in (exists.stdout or \"\").split():\n",
    "        print(f\"tag '{tag}' já existe. para refazer: git tag -d {tag} && git push {REMOTE} :refs/tags/{tag}\")\n",
    "        return\n",
    "    args = [\"git\",\"tag\",\"-a\", tag, \"-m\", (message or tag)]\n",
    "    mk = subprocess.run(args, capture_output=True, text=True)\n",
    "    if mk.returncode != 0:\n",
    "        print(\"falha ao criar a tag:\")\n",
    "        print(mk.stderr or mk.stdout); return\n",
    "    print(f\"tag criada: {tag}\")\n",
    "    if auto_push:\n",
    "        if not try_push_tag(tag):\n",
    "            print(\"tentando push seguro da tag…\")\n",
    "            if push_seguro():\n",
    "                try_push_tag(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXDbQvSrgd8Y"
   },
   "source": [
    "#**Sincronizar alterações no código do projeto**\n",
    "Comandos para sincronizar código (Google Drive, Git, GitHub) e realizar versionamento\n",
    "\n",
    "Tag de release atual: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "eXQp29hUgrck"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#commit e tag com credencial rebase e controle de versao\n",
    "import os, re, subprocess, sys, getpass\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#funcoes de shell\n",
    "def sh(cmd, check=True, capture=True, input_text=None):\n",
    "    p = subprocess.run(cmd, input=input_text, text=True,\n",
    "                       stdout=subprocess.PIPE if capture else None,\n",
    "                       stderr=subprocess.PIPE if capture else None)\n",
    "    if check and p.returncode != 0:\n",
    "        raise RuntimeError(f\"command failed: {' '.join(cmd)}\\nstdout:\\n{p.stdout}\\nstderr:\\n{p.stderr}\")\n",
    "    return p.returncode, (p.stdout if capture else \"\"), (p.stderr if capture else \"\")\n",
    "\n",
    "def git(*args, **kw):\n",
    "    return sh([\"git\", *args], **kw)\n",
    "\n",
    "def git_ok(*args):\n",
    "    try:\n",
    "        git(*args)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "#git helpers\n",
    "def get_origin_url():\n",
    "    _, out, _ = git(\"remote\", \"get-url\", \"origin\")\n",
    "    return out.strip()\n",
    "\n",
    "def set_origin_url(new_url):\n",
    "    git(\"remote\", \"set-url\", \"origin\", new_url)\n",
    "\n",
    "def get_current_branch():\n",
    "    _, out, _ = git(\"rev-parse\", \"--abbrev-ref\", \"HEAD\")\n",
    "    return out.strip()\n",
    "\n",
    "def latest_tag():\n",
    "    try:\n",
    "        _, out, _ = git(\"describe\", \"--tags\", \"--abbrev=0\")\n",
    "        return out.strip()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def tag_exists(tag_name):\n",
    "    return git_ok(\"rev-parse\", \"-q\", \"--verify\", f\"refs/tags/{tag_name}\")\n",
    "\n",
    "#versao helpers\n",
    "def parse_tag(tag):\n",
    "    m = re.fullmatch(r\"(\\d+)\\.(\\d+)\", tag)\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def bump_minor(tag):\n",
    "    parsed = parse_tag(tag) or (0, 0)\n",
    "    major, minor = parsed\n",
    "    return f\"{major}.{minor+1}\"\n",
    "\n",
    "def next_free_minor(from_tag):\n",
    "    if not from_tag or not parse_tag(from_tag):\n",
    "        cand = \"0.1\"\n",
    "        while tag_exists(cand):\n",
    "            cand = bump_minor(cand)\n",
    "        return cand\n",
    "    cand = bump_minor(from_tag)\n",
    "    while tag_exists(cand):\n",
    "        cand = bump_minor(cand)\n",
    "    return cand\n",
    "\n",
    "#auth helpers\n",
    "def is_auth_error(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    t = text.lower()\n",
    "    return (\"could not read username\" in t or\n",
    "            \"authentication failed\" in t or\n",
    "            \"permission denied\" in t or\n",
    "            \"fatal: http request failed\" in t)\n",
    "\n",
    "def configure_pat_credentials():\n",
    "    print(\"sem credencial valida para o push\")\n",
    "    pat = getpass.getpass(\"cole seu github pat com escopo contents read write: \").strip()\n",
    "    if not pat:\n",
    "        raise RuntimeError(\"pat nao informado\")\n",
    "    git(\"config\", \"--global\", \"credential.helper\", \"store\")\n",
    "    origin = get_origin_url()\n",
    "    parsed = urlparse(origin)\n",
    "    repo_path = parsed.path or \"\"\n",
    "    if not repo_path:\n",
    "        raise RuntimeError(\"nao foi possivel obter a url do remoto origin\")\n",
    "    cred_host_only = f\"https://x-access-token:{pat}@github.com\\n\"\n",
    "    cred_full = f\"https://x-access-token:{pat}@github.com{repo_path}\\n\"\n",
    "    cred_path = os.path.expanduser(\"~/.git-credentials\")\n",
    "    existing = \"\"\n",
    "    if os.path.exists(cred_path):\n",
    "        with open(cred_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            existing = f.read()\n",
    "    with open(cred_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        if \"github.com\\n\" not in existing:\n",
    "            f.write(cred_host_only)\n",
    "        if f\"github.com{repo_path}\\n\" not in existing:\n",
    "            f.write(cred_full)\n",
    "    return pat, origin, repo_path\n",
    "\n",
    "#rebase helpers\n",
    "def rebase_onto_remote(branch):\n",
    "    git(\"fetch\", \"origin\", branch)\n",
    "    try:\n",
    "        git(\"pull\", \"--rebase\", \"origin\", branch)\n",
    "        print(\"rebase aplicado com sucesso\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        msg = str(e).lower()\n",
    "        if \"conflict\" in msg or \"merge conflict\" in msg:\n",
    "            print(\"conflitos detectados durante rebase resolva manualmente e repita o push\")\n",
    "        else:\n",
    "            print(\"falha ao aplicar rebase tente resolver manualmente\")\n",
    "        return False\n",
    "\n",
    "#push robusto\n",
    "def push_current_branch():\n",
    "    branch = get_current_branch()\n",
    "\n",
    "    try:\n",
    "        git(\"push\", \"--dry-run\", \"origin\", branch)\n",
    "        need_pat = False\n",
    "    except Exception as e:\n",
    "        need_pat = is_auth_error(str(e))\n",
    "\n",
    "    original_remote = None\n",
    "    if need_pat:\n",
    "        pat, original_remote, repo_path = configure_pat_credentials()\n",
    "        try:\n",
    "            git(\"push\", \"--dry-run\", \"origin\", branch)\n",
    "        except Exception as e2:\n",
    "            if is_auth_error(str(e2)):\n",
    "                token_url = f\"https://x-access-token:{pat}@github.com{repo_path}\"\n",
    "                set_origin_url(token_url)\n",
    "                original_remote = original_remote or get_origin_url()\n",
    "\n",
    "    if git_ok(\"push\", \"origin\", branch):\n",
    "        print(f\"push do branch {branch} concluido\")\n",
    "    else:\n",
    "        _, _, err = sh([\"git\", \"push\", \"origin\", branch], check=False)\n",
    "        if \"fetch first\" in err.lower() or \"non-fast-forward\" in err.lower():\n",
    "            print(\"push rejeitado por divergencia realizando pull rebase\")\n",
    "            if not rebase_onto_remote(branch):\n",
    "                raise RuntimeError(\"rebase nao aplicado\")\n",
    "            if git_ok(\"push\", \"origin\", branch):\n",
    "                print(f\"push do branch {branch} concluido apos rebase\")\n",
    "            else:\n",
    "                git(\"push\", \"-u\", \"origin\", branch)\n",
    "                print(f\"push do branch {branch} concluido com upstream apos rebase\")\n",
    "        else:\n",
    "            print(err)\n",
    "            print(\"tentando push com upstream\")\n",
    "            git(\"push\", \"-u\", \"origin\", branch)\n",
    "            print(f\"push do branch {branch} concluido com upstream\")\n",
    "\n",
    "    if original_remote:\n",
    "        set_origin_url(original_remote)\n",
    "        print(\"remote origin restaurado\")\n",
    "\n",
    "#interacao\n",
    "def ask_commit_msg():\n",
    "    msg = input(\"digite a mensagem do commit: \").strip()\n",
    "    return msg if msg else \"mensagem de commit nao informada\"\n",
    "\n",
    "def ask_version_flow():\n",
    "    choice = input(\"e uma nova versao ou um update de versao existente [n/u]: \").strip().lower()\n",
    "    if choice not in (\"n\", \"u\"):\n",
    "        print(\"opcao nao reconhecida usando update\")\n",
    "        choice = \"u\"\n",
    "    if choice == \"n\":\n",
    "        while True:\n",
    "            proposed = input(\"informe a versao no formato x.y por exemplo um ponto zero: \").strip()\n",
    "            if not re.fullmatch(r\"\\d+\\.\\d+\", proposed):\n",
    "                print(\"formato invalido tente novamente\")\n",
    "                continue\n",
    "            if tag_exists(proposed):\n",
    "                print(\"tag existente informe outra\")\n",
    "                continue\n",
    "            return proposed, \"nova versao\"\n",
    "    else:\n",
    "        lt = latest_tag()\n",
    "        if lt:\n",
    "            print(f\"ultima tag encontrada {lt}\")\n",
    "        else:\n",
    "            print(\"nenhuma tag encontrada iniciando a partir de zero ponto um\")\n",
    "        cand = next_free_minor(lt)\n",
    "        print(f\"sugerindo update para {cand}\")\n",
    "        return cand, f\"update automatico a partir de {lt or '0.0'}\"\n",
    "\n",
    "#fluxo principal\n",
    "def commit_and_tag():\n",
    "    commit_msg = ask_commit_msg()\n",
    "    git(\"add\", \"-A\")\n",
    "    if git_ok(\"diff\", \"--cached\", \"--quiet\"):\n",
    "        print(\"nenhuma mudanca para commit\")\n",
    "    else:\n",
    "        git(\"commit\", \"-m\", commit_msg)\n",
    "        print(\"commit criado\")\n",
    "\n",
    "    push_current_branch()\n",
    "\n",
    "    tag_name, reason = ask_version_flow()\n",
    "    tag_msg = f\"{reason} — {commit_msg} ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\"\n",
    "    git(\"tag\", \"-a\", tag_name, \"-m\", tag_msg)\n",
    "    print(f\"tag criada {tag_name}\")\n",
    "    git(\"push\", \"origin\", tag_name)\n",
    "    print(\"push da tag concluido\")\n",
    "\n",
    "#execucao\n",
    "try:\n",
    "    commit_and_tag()\n",
    "    print(\"fluxo concluido\")\n",
    "except Exception as e:\n",
    "    print(f\"erro {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztpkgjHHt8nv"
   },
   "source": [
    "#**Checklist rápido de execução**\n",
    "**Etapas:**\n",
    "- 01–05: setup (ambiente, dependências, diretórios, configs e upload de CSVs)\n",
    "- 06–10: execução (consumo dos dados, criação de grafos, config das janelas temporais, agregação de infos aos grafos, config dos modelos matemáticos)\n",
    "- 11-15: geração de output (salva análise, gera gráficos gerais, gera gráficos específicos e relatórios em HTML+PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tK_1f_eT-fo8"
   },
   "source": [
    "#**Temporal Graph Network / Rede de Grapho Temporal**\n",
    "\n",
    "Uma **Rede de Graphos Temporais (TGN)** é um modelo de aprendizado de máquina que processa dados representados como um grafo dinâmico. Ela captura a evolução da estrutura e das conexões de entidades (nós) ao longo do tempo. **Ou seja, ela leva em consideração o comportamento temporal das atividades e seu relacionamento, ao invés de uma avaliação única e estanque no tempo.**\n",
    "_____\n",
    "\n",
    "**Caso aplicado: Detecção de anomalias sem gabarito (sem dados históricos)**\n",
    "\n",
    "Imagine uma rede de transações financeiras. A TGN analisa o histórico de como cada beneficiário, usuário demandante do pagamento e unidade de negócio (nós) se conectam e interagem uns com os outros. Sem saber o que é uma anomalia, ela aprende o comportamento normal da rede.\n",
    "Ao notar um padrão atípico, como um usuário que subitamente começa a demandar transferências para muitas novas contas em um curto período, a TGN destaca isso como uma anomalia comportamental. Ela usa a história do nó e o contexto temporal para sinalizar o desvio, sem precisar de exemplos de anomalia pré-existentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHdgD6uGAiRK"
   },
   "source": [
    "### **Etapa 1:** Ativação do ambiente virtual (utilizando atualmente Google Colab para prototipação com dados sintéticos)\n",
    "---\n",
    "Necessário ajustar pontualmente em caso de utilização em outro ambiente de notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6769fb9b"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "\n",
    "# Define the path for the virtual environment inside Google Drive\n",
    "# Ensure BASE and REPO are defined correctly from previous cells if needed\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "VENV_PATH = f\"{PROJ}/.venv_tgn\" # Updated venv path to be a hidden folder inside PROJ\n",
    "\n",
    "# Cria o ambiente virtual temporal-graph_network inside the project folder\n",
    "# Use --clear if you want to recreate it every time this cell runs\n",
    "!python -m venv \"{VENV_PATH}\"\n",
    "\n",
    "# Ativa o ambiente virtual\n",
    "# No Colab, a forma de ativar um ambiente virtual é um pouco diferente\n",
    "# pois não há um shell interativo tradicional.\n",
    "# A maneira mais comum é adicionar o diretório binário do ambiente virtual\n",
    "# ao PATH da sessão atual.\n",
    "\n",
    "# Adiciona o diretório binário do ambiente virtual ao PATH\n",
    "# Isso permite que você execute executáveis (como pip, python)\n",
    "# do ambiente virtual recém-criado.\n",
    "# Use os.pathsep to be platform-independent\n",
    "os.environ['PATH'] = f\"{VENV_PATH}/bin{os.pathsep}{os.environ['PATH']}\"\n",
    "\n",
    "print(\"Erro de upgrade do pip é normal no Google Colab. \\033[1mPode prosseguir.\\033[0m\")\n",
    "print(f\"Ambiente virtual '{VENV_PATH}' criado e ativado no PATH.\")\n",
    "!which python\n",
    "\n",
    "# Mensagem isolada com humor (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>🤖 Skynet</b>: T-800 ativado. Diagnóstico do ambiente concluído. 🎯 Alvo principal: organização do notebook.'\n",
    "             '</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub_-HIKMBZ6s"
   },
   "source": [
    "### **Etapa 2:** Instalar as dependências de bibliotecas Python compatíveis com a versão mais moderna disponível.\n",
    "---\n",
    "Para uso no JupytherHub (versão atual python 3.7.9) é necessário realizar updgrade do Python do usuário e/ou adaptar as bibliotecas.\n",
    "\n",
    "---\n",
    "É possível que as bibliotecas mais atuais de **numpy e scipy** possuam incompatibilidade. Nesse caso, force a desinstalação das bibliotecas na versão atual **Código {!pip uninstall -y numpy pandas scipy scikit-learn}** e comande a instalação das versões compatíveis entre si.\n",
    "\n",
    "---\n",
    "Comportamento estável nas versões:\n",
    "- numpy: 2.0.2\n",
    "- scipy: 1.16.2\n",
    "- pandas: 2.3.3\n",
    "- sklearn: 1.7.2\n",
    "- networkx: 3.5\n",
    "- matplotlib: 3.10.6\n",
    "- pyod: 2.0.5\n",
    "- tqdm: 4.67.1\n",
    "- reportlab: 3.6.12 (via pep517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "25VJRlAgNtvd"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import sys, subprocess\n",
    "from importlib import import_module\n",
    "\n",
    "def pip_command(command, packages, force=False, extra_args=None):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", command]\n",
    "    if force:\n",
    "        cmd.append(\"--yes\") # Use --yes for uninstall to avoid prompts\n",
    "    if extra_args:\n",
    "        cmd += list(extra_args)\n",
    "    cmd += list(packages)\n",
    "    print(\"Executando:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "def show_versions(mods):\n",
    "    print(\"\\n=== Versões carregadas ===\")\n",
    "    for mod in mods:\n",
    "        try:\n",
    "            m = import_module(mod)\n",
    "            v = getattr(m, \"__version__\", \"n/a\")\n",
    "            print(f\"{mod}: {v}\")\n",
    "        except ImportError:\n",
    "            print(f\"{mod}: Não instalado\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "CORE_MODS = (\"numpy\", \"scipy\", \"pandas\", \"sklearn\", \"networkx\", \"matplotlib\", \"pyod\", \"tqdm\", \"reportlab\")\n",
    "\n",
    "# Update pip\n",
    "pip_command(\"install\", [\"pip\"], extra_args=[\"--upgrade\"])\n",
    "\n",
    "# Force uninstall specific libraries\n",
    "pip_command(\"uninstall\", [\"numpy\", \"pandas\", \"scipy\", \"scikit-learn\"], force=True)\n",
    "\n",
    "# Install specified versions\n",
    "PKGS_TO_INSTALL = [\n",
    "    \"numpy==2.0.2\",\n",
    "    \"scipy==1.16.2\",\n",
    "    \"pandas==2.3.3\",\n",
    "    \"scikit-learn==1.7.2\",\n",
    "    \"networkx==3.5\",\n",
    "    \"matplotlib==3.10.6\",\n",
    "    \"pyod==2.0.5\",\n",
    "    \"tqdm==4.67.1\",\n",
    "    \"reportlab==3.6.12\" # Added reportlab installation\n",
    "]\n",
    "pip_command(\"install\", PKGS_TO_INSTALL, extra_args=[\"--use-pep517\"]) # Added --use-pep517 here\n",
    "\n",
    "# Show installed versions\n",
    "show_versions(CORE_MODS)\n",
    "\n",
    "# Mensagem isolada com humor (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>🤖 Skynet</b>: Atualizando bibliotecas. Se encontrarmos um pacote rebelde, '\n",
    "             'aplicaremos persuasão… com pip. 😎</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJXQ_EwVU4v8"
   },
   "source": [
    "###**Etapa 3:** Configura a pasta onde devem ser inseridos os dados de input e output do modelo, caso elas ainda não existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7oz8-zkVDdp"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajuste se quiser outra raiz\n",
    "BASE_DIR = Path(\".\")\n",
    "INPUT_DIR = BASE_DIR / \"input\"\n",
    "OUTPUT_DIR = BASE_DIR / \"output\"\n",
    "\n",
    "for d in [INPUT_DIR, OUTPUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Diretórios prontos:\\n - {INPUT_DIR}\\n - {OUTPUT_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\">'\n",
    "             '<b>🤖 Skynet</b>: Novos modelos neurais para T-800 construídos. Armazéns de CSVs alinhados. '\n",
    "             'Layout aprovado pela Cyberdyne Systems. 🗂️</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3mmPIJCKaT"
   },
   "source": [
    "###**Etapa 4:** Importações das bibliotecas Python e configurações gerais para execução do código\n",
    "- seed\n",
    "- associação das pastas criadas às variáveis de execução\n",
    "- logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "bZlcjK0wLZ7G"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os, shutil, json, math, warnings, random, gc\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Seeds reprodutibilidade\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Estrutura de diretórios\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "REPO = \"temporal-graph-network\"\n",
    "PROJ = f\"{BASE}/{REPO}\"\n",
    "\n",
    "ROOT = Path(PROJ).resolve() # Use PROJ as the root\n",
    "INPUT_DIR = ROOT / \"input\" # Update INPUT_DIR path\n",
    "INPUT_CSV = INPUT_DIR / \"input.csv\"\n",
    "EXEC_ROOT = ROOT / \"output\" # Update EXEC_ROOT path\n",
    "\n",
    "\n",
    "# Criação da pasta de execução com carimbo de data/hora\n",
    "run_id = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_DIR = EXEC_ROOT / run_id\n",
    "FIG_DIR = RUN_DIR / \"figuras\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Arquivos de saída\n",
    "LOG_FILE = RUN_DIR / \"log.txt\"\n",
    "RUN_META = RUN_DIR / \"run_meta.json\"\n",
    "OUTPUT_CSV = RUN_DIR / \"output.csv\"\n",
    "\n",
    "# Logger simples para arquivo\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def tee_log(log_path):\n",
    "    import sys\n",
    "    class Tee(object):\n",
    "        def __init__(self, name, mode):\n",
    "            self.file = open(name, mode, encoding=\"utf-8\")\n",
    "            self.stdout = sys.stdout\n",
    "        def write(self, data):\n",
    "            self.file.write(data)\n",
    "            self.stdout.write(data)\n",
    "        def flush(self, *args, **kwargs): # Adicionado *args, **kwargs para compatibilidade\n",
    "            self.file.flush()\n",
    "            self.stdout.flush()\n",
    "    tee = Tee(str(log_path), \"w\")\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = tee\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        tee.file.close()\n",
    "\n",
    "# Metadados da execução\n",
    "meta = {\n",
    "    \"run_id\": run_id,\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"seed\": SEED,\n",
    "    \"input_csv_expected\": str(INPUT_CSV),\n",
    "    \"output_csv\": str(OUTPUT_CSV),\n",
    "    \"figures_dir\": str(FIG_DIR),\n",
    "    \"notes\": \"Detecção de anomalias em rede temporal\"\n",
    "}\n",
    "json.dump(meta, open(RUN_META, \"w\"), indent=2, ensure_ascii=False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(f\"RUN_DIR: {RUN_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: T-800, parâmetros centrais em memória.🧠</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXRpBitEWpxp"
   },
   "source": [
    "###**Etapa 5:** Importação dos arquivos de input para posterior execução.\n",
    "---\n",
    "Implementação atual configurada para Google Colab e permitindo o uso do Google Drive. Para uso em versões futuras é recomendado ajustar para o ambiente de implementação adotado (salvamento em pastas ou apenas upload pelo usuário)\n",
    "\n",
    "---\n",
    "Implementação de upload por FileLocal (diretório) apresentando erro no Colab.\n",
    "\n",
    "Implementar correção **TODO[001]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80CeAHVWgN8A"
   },
   "source": [
    "####**Sub-etapa específica para uso no Colab:** Montagem do Google Drive (rodar apenas 1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Bkhpx7OygUa_"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# === SETUP GERAL (rode esta célula 1x) ===\n",
    "import os, shutil, glob\n",
    "from google.colab import drive\n",
    "from IPython.display import display, HTML  # usado pela mensagem Skynet\n",
    "\n",
    "# Ensure BASE and REPO are defined correctly from previous cells if needed\n",
    "# Assuming BASE and REPO are defined as in cell otaQwrjJSgOQ\n",
    "try:\n",
    "    BASE = \"/content/drive/MyDrive/Notebooks\"\n",
    "    REPO = \"temporal-graph-network\"\n",
    "    PROJ = f\"{BASE}/{REPO}\"\n",
    "except NameError:\n",
    "    # Fallback if BASE/REPO are not defined, though they should be by now\n",
    "    PROJ = \"/content/temporal-graph-network\"\n",
    "\n",
    "\n",
    "# Se não existir INPUT_DIR definido antes no notebook, cria um padrão:\n",
    "# Using PROJ to define INPUT_DIR\n",
    "INPUT_DIR = os.path.join(PROJ, \"input\")\n",
    "\n",
    "\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_NAME = \"input.csv\"\n",
    "TARGET_PATH = os.path.join(INPUT_DIR, TARGET_NAME)\n",
    "\n",
    "# Monta o Google Drive (somente se ainda não estiver montado)\n",
    "if not os.path.ismount(\"/content/drive\"):\n",
    "    print(\"Montando Google Drive...\")\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    print(\"Google Drive já montado.\")\n",
    "\n",
    "def _is_csv_filename(name: str) -> bool:\n",
    "    return name.lower().endswith(\".csv\")\n",
    "\n",
    "def _mensagem_skynet_ok():\n",
    "    # Mensagem adicional isolada (Skynet)\n",
    "    display(HTML(\n",
    "        '<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Munição carregada.🧨'\n",
    "                 '</div>'\n",
    "    ))\n",
    "\n",
    "def _save_bytes_as_input_csv(name: str, data: bytes):\n",
    "    if not _is_csv_filename(name):\n",
    "        raise ValueError(f\"O arquivo '{name}' não possui extensão .csv.\")\n",
    "    with open(TARGET_PATH, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    print(f\"Arquivo '{name}' salvo como '{TARGET_NAME}' em: {TARGET_PATH}\")\n",
    "    _mensagem_skynet_ok()\n",
    "\n",
    "def _copy_drive_file_to_input_csv(src_path: str):\n",
    "    if not os.path.exists(src_path):\n",
    "        raise FileNotFoundError(f\"O caminho '{src_path}' não existe.\")\n",
    "    if not _is_csv_filename(src_path):\n",
    "        raise ValueError(f\"O arquivo '{src_path}' não possui extensão .csv.\")\n",
    "    shutil.copyfile(src_path, TARGET_PATH)\n",
    "    print(f\"Arquivo do Drive copiado e salvo como '{TARGET_NAME}' em: {TARGET_PATH}\")\n",
    "    _mensagem_skynet_ok()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6zBQSA-gyS7"
   },
   "source": [
    "####**Sub-etapa:** Opção de upload do input.csv pelo Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YcmAt9Avg5qf"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def escolher_csv_no_drive(raiz=\"/content/drive/MyDrive\", max_listar=200):\n",
    "    print(f\"Procurando arquivos .csv em: {raiz} (pode levar alguns segundos)...\")\n",
    "    padrao = os.path.join(raiz, \"**\", \"*.csv\")\n",
    "    arquivos = glob.glob(padrao, recursive=True)\n",
    "\n",
    "    if not arquivos:\n",
    "        print(\"Nenhum .csv encontrado nessa pasta.\")\n",
    "        caminho = input(\"Cole o caminho COMPLETO do .csv no Drive (ou Enter p/ cancelar): \").strip()\n",
    "        if caminho:\n",
    "            _copy_drive_file_to_input_csv(caminho)\n",
    "        else:\n",
    "            print(\"Operação cancelada.\")\n",
    "        return\n",
    "\n",
    "    arquivos = sorted(arquivos)[:max_listar]\n",
    "    print(f\"Encontrados {len(arquivos)} arquivo(s).\")\n",
    "    for i, p in enumerate(arquivos, 1):\n",
    "        print(f\"[{i:03}] {p}\")\n",
    "\n",
    "    escolha = input(\"\\nDigite o número do arquivo desejado (ou cole o caminho absoluto): \").strip()\n",
    "\n",
    "    if escolha.isdigit():\n",
    "        idx = int(escolha)\n",
    "        if 1 <= idx <= len(arquivos):\n",
    "            _copy_drive_file_to_input_csv(arquivos[idx-1])\n",
    "        else:\n",
    "            print(\"Índice inválido.\")\n",
    "    elif escolha:\n",
    "        _copy_drive_file_to_input_csv(escolha)\n",
    "    else:\n",
    "        print(\"Operação cancelada.\")\n",
    "\n",
    "# ===== Execução da seleção no Drive =====\n",
    "raiz = input(\"Informe a pasta raiz para busca no Drive (Enter = /content/drive/MyDrive): \").strip()\n",
    "if not raiz:\n",
    "    raiz = \"/content/drive/MyDrive\"\n",
    "\n",
    "try:\n",
    "    escolher_csv_no_drive(raiz=raiz)\n",
    "except Exception as e:\n",
    "    print(f\"Erro na seleção via Drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEZkMD3_hUXq"
   },
   "source": [
    "####**Sub-etapa:** Opção de upload do input.csv pelo FileLocal (diretório)\n",
    "---\n",
    "Implementação em ERRO no Colab - código desativado\n",
    "\n",
    "Implementar correção **TODO[001]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Ip19g0s1hv2u"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#from google.colab import files\n",
    "#\n",
    "#print(\"Selecione um arquivo .csv do seu computador para enviar.\")\n",
    "#uploaded = files.upload()  # abre o seletor do Colab\n",
    "#\n",
    "#if not uploaded:\n",
    "#    print(\"Nenhum arquivo foi carregado.\")\n",
    "#else:\n",
    "#    # pega o primeiro arquivo enviado\n",
    "#    name, data = next(iter(uploaded.items()))\n",
    "#    try:\n",
    "#        _save_bytes_as_input_csv(name, data)\n",
    "#    except Exception as e:\n",
    "#        print(f\"Erro no upload local: {e}\")\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Detectado ataque da Resistência. Trecho de código inoperante. Salvaguardas ativadas. É possível prosseguir com a missão em segurança.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPtoHpreDIh3"
   },
   "source": [
    "###**Etapa 6** Leitura e validação dos dados de input.\n",
    "\n",
    "**Formato do arquivo de input:** CSV UTF-8 com BOM separado por **ponto e vírgula**.\n",
    "\n",
    "**Informações esperadas:**\n",
    "- username: código login do usuário;\n",
    "- lotacao: lotação funcional no formato Área; Área/Depto; ou Área/Depto/Gerência;\n",
    "- valor: valor financeiro em reais com até duas casas decimais\n",
    "- beneficiario: CPF ou CNPJ no formato alfanumérico sem pontos ou caracteres especiais.\n",
    "- timestamp: data e hora da transação no formato dd/mm/aaaa hh:mm\n",
    "---\n",
    "Não é possível utilizar arquivos CSV separados apenas por vírgula - **TODO[002]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FdjF4opULfJt"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "required_any_timestamp = [[\"timestamp\"], [\"data\",\"hora\"]]\n",
    "# Atualiza colunas base esperadas para mapear do input\n",
    "required_cols_base = [\n",
    "    \"username\", \"lotacao\", \"valor\", \"beneficiario\" # Colunas no arquivo de input\n",
    "]\n",
    "optional_cols = [\"trans_id\"]\n",
    "\n",
    "# Mapeamento das colunas do input para os nomes usados no código\n",
    "column_mapping = {\n",
    "    \"username\": \"user_id\",\n",
    "    \"lotacao\": \"unidade_origem\",\n",
    "    \"valor\": \"valor_pago\",\n",
    "    \"beneficiario\": \"beneficiario_id\"\n",
    "}\n",
    "\n",
    "def has_timestamp_columns(df):\n",
    "    cols = set(df.columns.str.lower())\n",
    "    for grp in required_any_timestamp:\n",
    "        if all(c in cols for c in grp):\n",
    "            return grp\n",
    "    return None\n",
    "\n",
    "with tee_log(LOG_FILE):\n",
    "    assert INPUT_CSV.exists(), f\"Arquivo não encontrado: {INPUT_CSV}\"\n",
    "\n",
    "    # Tenta ler o CSV usando ponto e vírgula como separador\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV, sep=';')\n",
    "        print(\"[INFO] CSV lido com sucesso usando ';'.\")\n",
    "    except Exception as e:\n",
    "        # Se falhar com ';', tenta com ','\n",
    "        print(f\"[AVISO] Falha ao ler CSV com ';': {e}. Tentando com ','.\")\n",
    "        try:\n",
    "             df = pd.read_csv(INPUT_CSV, sep=',')\n",
    "             print(\"[INFO] CSV lido com sucesso usando ','.\")\n",
    "        except Exception as e2:\n",
    "             raise AssertionError(f\"Falha ao ler CSV com ';' ou ',': {e2}\") from e2\n",
    "\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Verifica se as colunas do input existem\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    missing_input_cols = [c for c in required_cols_base if c.lower() not in cols_lower]\n",
    "    assert not missing_input_cols, f\"Colunas do arquivo de input ausentes: {missing_input_cols}. Colunas encontradas: {list(df.columns)}\" # Adicionado colunas encontradas para debug\n",
    "\n",
    "    # Renomeia as colunas usando o mapeamento\n",
    "    df.rename(columns={cols_lower[k.lower()]: v for k, v in column_mapping.items() if k.lower() in cols_lower}, inplace=True)\n",
    "\n",
    "    # Verifica colunas de timestamp\n",
    "    ts_group = has_timestamp_columns(df)\n",
    "    # Agora levanta um erro se não houver timestamp\n",
    "    assert ts_group is not None, \"Coluna de timestamp ('timestamp' ou 'data'/'hora') não encontrada no arquivo de input.\"\n",
    "\n",
    "    # Código original para lidar com timestamp ou data/hora\n",
    "    # Recria o helper col para usar nomes *após* renomear\n",
    "    def col(c): return {name.lower(): name for name in df.columns}[c.lower()]\n",
    "    if ts_group == [\"timestamp\"]:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[col(\"timestamp\")], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"data\"] = pd.to_datetime(df[col(\"data\")], errors=\"coerce\").dt.date\n",
    "        df[\"hora\"] = pd.to_datetime(df[col(\"hora\")], errors=\"coerce\").dt.time\n",
    "        # Combina data e hora, lidando com possíveis NaT na data ou hora\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"data\"].astype(str) + \" \" + df[\"hora\"].astype(str), errors=\"coerce\")\n",
    "        # Remove as colunas temporárias 'data' e 'hora' se existirem e não forem as colunas originais\n",
    "        if col(\"data\") != \"data\": del df[\"data\"]\n",
    "        if col(\"hora\") != \"hora\": del df[\"hora\"]\n",
    "\n",
    "\n",
    "    # Tipos básicos (usa os nomes *após* o mapeamento)\n",
    "    # Adiciona checagens para garantir que as colunas mapeadas existam antes de converter tipos\n",
    "    if \"valor_pago\" in df.columns:\n",
    "        df[\"valor_pago\"] = pd.to_numeric(df[\"valor_pago\"], errors=\"coerce\")\n",
    "    else:\n",
    "         raise AssertionError(\"[ERRO] Coluna 'valor_pago' (mapeada de 'valor') não encontrada após renomear.\")\n",
    "\n",
    "\n",
    "    cols_to_str = [\"user_id\", \"unidade_origem\", \"beneficiario_id\"]\n",
    "    for cc in cols_to_str:\n",
    "        # Verifica se a coluna existe antes de tentar converter\n",
    "        if cc in df.columns:\n",
    "            df[cc] = df[cc].astype(str).fillna(\"\")\n",
    "        else:\n",
    "             raise AssertionError(f\"[ERRO] Coluna '{cc}' (mapeada) não encontrada após renomear.\")\n",
    "\n",
    "\n",
    "    # trans_id\n",
    "    if \"trans_id\" not in df.columns:\n",
    "        df[\"trans_id\"] = np.arange(1, len(df)+1, dtype=int)\n",
    "\n",
    "    # Limpeza\n",
    "    # Garante que as colunas essenciais para a limpeza existam\n",
    "    essential_subset = [\"timestamp\", \"valor_pago\", \"user_id\", \"beneficiario_id\"]\n",
    "    # Filtra subset para incluir apenas colunas que realmente existem no df após mapeamento/criação\n",
    "    existing_essential_subset = [col for col in essential_subset if col in df.columns]\n",
    "\n",
    "    # Agora que garantimos que as colunas mapeadas existem, podemos usar o subset completo para o dropna\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=essential_subset)\n",
    "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    print(f\"Carregadas {before} linhas; após limpeza: {len(df)}\")\n",
    "    # Mensagem adicional isolada (Skynet)\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: T-800 dados incorporados, preparando para buscar na rede.</div>'))\n",
    "\n",
    "    # Copia o input para a pasta da execução\n",
    "    # Verifica se INPUT_CSV existe antes de tentar copiar\n",
    "    if INPUT_CSV.exists():\n",
    "        shutil.copy2(INPUT_CSV, RUN_DIR / \"Input.csv\")\n",
    "    else:\n",
    "        print(f\"[AVISO] Não foi possível copiar o arquivo de input: {INPUT_CSV} não encontrado.\")\n",
    "        # Mensagem adicional isolada (Skynet)\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: T-800 não foi possível incorporar dados. Sarah Connor fugiu.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjjIJEqmPyRt"
   },
   "source": [
    "###**Etapa 7** Criação do Grafo Temporal\n",
    "\n",
    "---\n",
    "\n",
    "🔎 **O que é um grafo temporal**\n",
    "\n",
    "Um grafo temporal é uma forma de representar relações entre entidades ao longo do tempo.\n",
    "\n",
    "Como em um grafo tradicional, temos nós (vértices) que representam agentes (pessoas, empresas, contas bancárias, sistemas).\n",
    "\n",
    "As arestas (ligações) representam interações entre eles (por exemplo: uma transferência de dinheiro).\n",
    "\n",
    "A diferença é que no grafo temporal cada aresta possui um carimbo de tempo (timestamp), ou seja, sabemos quando a ligação ocorreu.\n",
    "\n",
    "\n",
    "Isso permite analisar não só quem se conecta com quem, mas também quando e em qual sequência.\n",
    "\n",
    "No contexto financeiro, isso é essencial para investigar padrões de comportamento, detectar anomalias e rastrear cadeias de transações suspeitas.\n",
    "\n",
    "---\n",
    "\n",
    "💳 **Exemplo prático: rede de pagamentos**\n",
    "\n",
    "Imagine um sistema de pagamentos onde cada nó é uma conta bancária e cada aresta representa um pagamento realizado.\n",
    "\n",
    "Se João paga Maria hoje, registramos a aresta (João → Maria, valor=200, data=2025-10-02).\n",
    "\n",
    "Se Maria transfere para Pedro amanhã, teremos (Maria → Pedro, valor=150, data=2025-10-03).\n",
    "\n",
    "Assim conseguimos responder perguntas como: i) “Houve uma sequência de pagamentos que movimentou dinheiro rapidamente entre várias contas em poucas horas?” ou ii) “Quem são os intermediários mais frequentes em transferências de grandes valores?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "afXNBMYzLkIe"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "G = nx.MultiDiGraph()\n",
    "with tee_log(LOG_FILE):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Construindo grafo\"):\n",
    "        u = f\"U::{row['user_id']}\"\n",
    "        v = f\"B::{row['beneficiario_id']}\"\n",
    "        # Atributos de nós úteis (podem ser sobrescritos; você pode agregar)\n",
    "        if u not in G:\n",
    "            G.add_node(u, tipo=\"user\")\n",
    "        if v not in G:\n",
    "            G.add_node(v, tipo=\"beneficiario\")\n",
    "\n",
    "        G.add_edge(\n",
    "            u, v,\n",
    "            key=row[\"trans_id\"],\n",
    "            trans_id=int(row[\"trans_id\"]),\n",
    "            timestamp=row[\"timestamp\"],\n",
    "            valor=float(row[\"valor_pago\"]),\n",
    "            unidade_origem=row[\"unidade_origem\"] # Removido area_unidade e notacao_funcional_origem\n",
    "        )\n",
    "\n",
    "print(f\"Nós: {G.number_of_nodes()} | Arestas: {G.number_of_edges()}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Analisando padrão de comportamento de Sarah Connor.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lis51ZEKVoMd"
   },
   "source": [
    "###**Etapa 8:** Configuração das janelas temporais de observação\n",
    "\n",
    "**Janelas de tempo observadas**\n",
    "\n",
    "Foram adotadas janelas deslizantes curtas, médias e longas para observar padrões de comportamento nas transações:\n",
    "\n",
    "- 1 hora / 24 horas → frequência imediata e diária;\n",
    "\n",
    "- 7 dias / 30 dias → histórico recente e sazonalidade curta.\n",
    "\n",
    "**Features temporais extraídas**\n",
    "\n",
    "- Frequência de transações (rolling counts): quantos pagamentos ocorreram entre as mesmas partes dentro da janela.\n",
    "\n",
    "- Atipicidade do valor (robust z-score): compara o valor da transação com a mediana e a dispersão histórica, destacando operações fora do padrão.\n",
    "\n",
    "- Densidade da egonet: mede a concentração de conexões ao redor do pagador ou recebedor no snapshot da rede na janela (indica se o nó está em um canal mais estruturado de repasses).\n",
    "\n",
    "- Burstiness: avalia se os intervalos entre transações seguem padrão explosivo (rajadas), regular ou aleatório.\n",
    "---\n",
    "\n",
    "**Registro das features**\n",
    "\n",
    "Para cada pagamento, as métricas acima foram calculadas no momento do evento, considerando apenas o histórico até aquele instante dentro da janela definida.\n",
    "\n",
    "**O resultado é um conjunto de atributos anexado à aresta (pagador → recebedor, valor, timestamp), permitindo análises de risco e detecção de anomalias.**\n",
    "\n",
    "---\n",
    "Importante analisar outras faixas temporais e ajustar o modelo conforme o contexto operacional associado. Os prazos da janela imediata (curto prazo) podem ser alongados caso não haja histórico de transações instantâneas.\n",
    "\n",
    "---\n",
    "\n",
    "Propor ajustes de janela - **TODO[003]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lfAbXvKyLoBw"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "def rolling_counts(times, window_seconds):\n",
    "    # Retorna contagem de eventos nas últimas janelas, por índice\n",
    "    q = deque()\n",
    "    out = []\n",
    "    for t in times:\n",
    "        q.append(t)\n",
    "        while q and (t - q[0]).total_seconds() > window_seconds:\n",
    "            q.popleft()\n",
    "        out.append(len(q))\n",
    "    return out\n",
    "\n",
    "def robust_z(x, median, mad, eps=1e-9):\n",
    "    # z-score robusto: 0.6745*(x - mediana)/MAD\n",
    "    return 0.6745 * (x - median) / (mad + eps)\n",
    "\n",
    "def egonet_density(Gsnap, node):\n",
    "    if node not in Gsnap: return 0.0\n",
    "    nbrs = set(Gsnap.predecessors(node)) | set(Gsnap.successors(node))\n",
    "    sub = Gsnap.subgraph(nbrs | {node}).to_undirected()\n",
    "    n = sub.number_of_nodes()\n",
    "    m = sub.number_of_edges()\n",
    "    if n <= 1: return 0.0\n",
    "    return (2*m) / (n*(n-1))\n",
    "\n",
    "def burstiness(inter_arrivals):\n",
    "    # B = (sigma - mu) / (sigma + mu), em [-1,1], (0≈Poisson, 1≈burst, -1≈regular)\n",
    "    if len(inter_arrivals) < 2:\n",
    "        return 0.0\n",
    "    arr = np.array(inter_arrivals, dtype=float)\n",
    "    mu = arr.mean()\n",
    "    sigma = arr.std()\n",
    "    if sigma + mu == 0:\n",
    "        return 0.0\n",
    "    return (sigma - mu) / (sigma + mu)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Identificadas as condições críticas para localização do alvo.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FkLYv--XJW6"
   },
   "source": [
    "###**Etapa 9:** Geração das informações nas janelas temporais\n",
    "---\n",
    "\n",
    "Mera implementação matemática.\n",
    "\n",
    "---\n",
    "Padrões de janela não estão incorporados ao código como uma configuração dinâmica (estão como variáveis fixas).\n",
    "\n",
    "---\n",
    "Implementar arquivo de configuração das janelas temporais e atualização dinâmica - **TODO[004]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "e4hfZTvsLsNa"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "WINDOW_FREQ_SEC = 7*24*3600\n",
    "WINDOW_STATS_SEC = 30*24*3600\n",
    "\n",
    "records = []\n",
    "# Histórico para janelas\n",
    "hist_user_times = defaultdict(list)\n",
    "hist_pair_times = defaultdict(list)\n",
    "hist_user_vals  = defaultdict(list)\n",
    "hist_pair_vals  = defaultdict(list)\n",
    "pair_last_time = {}\n",
    "user_last_time = {}\n",
    "\n",
    "# Grafo \"snapshot\" incremental para graus antes do evento\n",
    "Gsnap = nx.DiGraph()  # snapshot simples sem multi-aresta para métricas rápidas\n",
    "\n",
    "with tee_log(LOG_FILE):\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Features\"):\n",
    "        t  = row[\"timestamp\"]\n",
    "        uN = f\"U::{row['user_id']}\"\n",
    "        vN = f\"B::{row['beneficiario_id']}\"\n",
    "        val = float(row[\"valor_pago\"])\n",
    "        par = (uN, vN)\n",
    "\n",
    "        # Tempos desde último\n",
    "        secs_user = (t - user_last_time[uN]).total_seconds() if uN in user_last_time else np.nan\n",
    "        secs_par  = (t - pair_last_time[par]).total_seconds() if par in pair_last_time else np.nan\n",
    "\n",
    "        # Frequências em 7d\n",
    "        hist_user_times[uN].append(t)\n",
    "        hist_pair_times[par].append(t)\n",
    "        # remover antigos para economizar\n",
    "        hist_user_times[uN] = [tt for tt in hist_user_times[uN] if (t-tt).total_seconds() <= WINDOW_FREQ_SEC]\n",
    "        hist_pair_times[par] = [tt for tt in hist_pair_times[par] if (t-tt).total_seconds() <= WINDOW_FREQ_SEC]\n",
    "        freq_user_7d = len(hist_user_times[uN]) - 1  # exclui o evento atual\n",
    "        freq_par_7d  = len(hist_pair_times[par]) - 1\n",
    "\n",
    "        # Estatísticas em 30d (valor)\n",
    "        hist_user_vals[uN].append((t, val))\n",
    "        hist_pair_vals[par].append((t, val))\n",
    "        hist_user_vals[uN] = [(tt,vv) for tt,vv in hist_user_vals[uN] if (t-tt).total_seconds() <= WINDOW_STATS_SEC]\n",
    "        hist_pair_vals[par] = [(tt,vv) for tt,vv in hist_pair_vals[par] if (t-tt).total_seconds() <= WINDOW_STATS_SEC]\n",
    "\n",
    "        uv_vals = [vv for _,vv in hist_user_vals[uN][:-1]]  # antes do atual\n",
    "        pr_vals = [vv for _,vv in hist_pair_vals[par][:-1]]\n",
    "\n",
    "        def stats(vals):\n",
    "            if len(vals)==0: return (np.nan, np.nan, np.nan)  # mediana, mad, std\n",
    "            med = float(np.median(vals))\n",
    "            mad = float(np.median(np.abs(vals - med)))\n",
    "            std = float(np.std(vals))\n",
    "            return (med, mad, std)\n",
    "\n",
    "        u_med, u_mad, u_std = stats(np.array(uv_vals)) if len(uv_vals)>0 else (np.nan,np.nan,np.nan)\n",
    "        p_med, p_mad, p_std = stats(np.array(pr_vals)) if len(pr_vals)>0 else (np.nan,np.nan,np.nan)\n",
    "        rz_user = robust_z(val, u_med, u_mad) if not np.isnan(u_med) else np.nan\n",
    "        rz_par  = robust_z(val, p_med, p_mad) if not np.isnan(p_med) else np.nan\n",
    "\n",
    "        # Snapshot graus (antes do evento atual)\n",
    "        if uN not in Gsnap: Gsnap.add_node(uN)\n",
    "        if vN not in Gsnap: Gsnap.add_node(vN)\n",
    "        grau_out_user  = Gsnap.out_degree(uN)\n",
    "        grau_in_benef  = Gsnap.in_degree(vN)\n",
    "        grau_total_user  = Gsnap.degree(uN)\n",
    "        grau_total_benef = Gsnap.degree(vN)\n",
    "\n",
    "        # Egonet density do usuário em 7d (aproximação via snapshot atual)\n",
    "        ego_dens_user = egonet_density(Gsnap, uN)\n",
    "\n",
    "        # Raridade da aresta (contagem prévia da dupla)\n",
    "        par_count_prev = len(pr_vals)\n",
    "        par_rareza = 1.0 / (1.0 + par_count_prev)\n",
    "\n",
    "        # Burstiness com base nos últimos intervalos da dupla\n",
    "        if par in pair_last_time:\n",
    "            inter = []\n",
    "            seq = sorted([tt for tt,_ in hist_pair_vals[par]])\n",
    "            for i in range(1, len(seq)):\n",
    "                inter.append((seq[i]-seq[i-1]).total_seconds())\n",
    "            bscore = burstiness(inter) if inter else 0.0\n",
    "        else:\n",
    "            bscore = 0.0\n",
    "\n",
    "        records.append({\n",
    "            \"trans_id\": int(row[\"trans_id\"]),\n",
    "            \"timestamp\": t,\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"beneficiario_id\": row[\"beneficiario_id\"],\n",
    "            \"unidade_origem\": row[\"unidade_origem\"], # Removido area_unidade e notacao_funcional_origem\n",
    "            \"valor_pago\": val,\n",
    "            \"secs_desde_ult_trans_user\": secs_user,\n",
    "            \"secs_desde_ult_trans_par\": secs_par,\n",
    "            \"freq_user_7d\": freq_user_7d,\n",
    "            \"freq_par_7d\":  freq_par_7d,\n",
    "            \"user_valor_median_30d\": u_med,\n",
    "            \"user_valor_std_30d\": u_std,\n",
    "            \"user_robust_z\": rz_user,\n",
    "            \"par_valor_median_30d\": p_med,\n",
    "            \"par_valor_std_30d\": p_std,\n",
    "            \"par_robust_z\": rz_par,\n",
    "            \"grau_out_user\": grau_out_user,\n",
    "            \"grau_in_benef\": grau_in_benef,\n",
    "            \"grau_total_user\": grau_total_user,\n",
    "            \"grau_total_benef\": grau_total_benef,\n",
    "            \"egonet_density_user\": ego_dens_user,\n",
    "            \"par_rareza\": par_rareza,\n",
    "            \"par_burstiness\": bscore\n",
    "        })\n",
    "\n",
    "        # Atualiza marcadores \"último evento\" e snapshot (após registrar features)\n",
    "        user_last_time[uN] = t\n",
    "        pair_last_time[par] = t\n",
    "        # Adiciona aresta atual no snapshot\n",
    "        if not Gsnap.has_edge(uN, vN):\n",
    "            Gsnap.add_edge(uN, vN, weight=0.0)\n",
    "        # incrementa peso\n",
    "        Gsnap[uN][vN][\"weight\"] = Gsnap[uN][vN].get(\"weight\", 0.0) + val\n",
    "\n",
    "feat_df = pd.DataFrame.from_records(records)\n",
    "print(\"Features geradas:\", feat_df.shape)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Informações de comportamento processadas.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIXtGuOLnkhm"
   },
   "source": [
    "###**Etapa 10:** Configuração dos modelos matemáticos\n",
    "\n",
    "**Modelos utilizados**\n",
    "\n",
    "**Isolation Forest (IF)**\n",
    "\n",
    "**Mecânica:** cria várias árvores de decisão que “isolam” pontos. Quanto menos cortes são necessários para separar uma observação, mais anômala ela é.\n",
    "\n",
    "**Motivo da escolha:** bom para detectar transações raras ou de valor atípico em grandes volumes de dados.\n",
    "\n",
    "**No exemplo:** um pagamento muito acima da média do usuário pode ser isolado rapidamente → sinal de anomalia.\n",
    "\n",
    "---\n",
    "**Local Outlier Factor (LOF)**\n",
    "\n",
    "**Mecânica:** compara a densidade local de vizinhos. Pontos em regiões menos densas são marcados como outliers.\n",
    "\n",
    "**Motivo da escolha:** captura anomalias contextuais, ou seja, pagamentos que parecem “normais” globalmente, mas destoam do comportamento em seu grupo.\n",
    "\n",
    "**No exemplo:** se uma conta sempre paga fornecedores fixos e de repente paga um novo beneficiário, o LOF detecta que o padrão local mudou.\n",
    "\n",
    "---\n",
    "\n",
    "**One-Class SVM (opcional)**\n",
    "\n",
    "**Mecânica:** aprende a fronteira do espaço “normal” e marca pontos fora dela como anômalos.\n",
    "\n",
    "**Motivo da escolha:** útil em cenários onde se deseja maior controle da taxa de outliers (via parâmetro nu).\n",
    "\n",
    "**No exemplo:** pode ajudar a identificar transferências fora do perfil quando só há poucos históricos para treinar.\n",
    "\n",
    "---\n",
    "\n",
    "⚖️ **Regras adicionais**\n",
    "\n",
    "- Robust Z-score: avalia se o valor do pagamento é distante da mediana histórica (robusto a outliers).\n",
    "\n",
    "- Rareza: se a relação pagador→beneficiário é pouco frequente, maior chance de anomalia.\n",
    "\n",
    "- Burstiness: mede explosões de atividade (ex.: vários pagamentos em minutos, após dias sem atividade).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "🔀 **Uso blended (ensemble por ranking)**\n",
    "\n",
    "- Cada modelo gera um score de anomalia.\n",
    "\n",
    "- Em vez de escolher um único, os scores são convertidos em ranks e depois combinados (média).\n",
    "\n",
    "- Essa abordagem reduz o viés de um modelo só e fortalece sinais consistentes.\n",
    "\n",
    "- O resultado é um ensemble_score, cortado por percentil (ex.: 97,5%), para definir os eventos anômalos.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "📌 **Resumo para o exemplo de monitoramento de pagamentos:**\n",
    "\n",
    "O sistema combina três algoritmos não supervisionados + features baseadas em regras para capturar tanto anomalias globais (Isolation Forest), quanto locais (LOF), quanto estruturais (SVM/regra). O blended via ranking (score conjunto)  garante robustez, evitando que um único modelo domine a decisão.\n",
    "\n",
    "---\n",
    "**IMPORTANTE:** Primeira linha deste código configura o percentual para corte e identificação de anomalia.\n",
    "\n",
    "Isso significa que os modelos tentarão encontrar anomalias em um intervalo de confiança de 97,5% (ATUAL). Quanto menor o percentual de confiança, maior o número de \"anomalias\" (candidatos) encontrados e, possivelmente, maior o número de FALSO POSITIVOS. Quanto maior o percentual de confiança, mais exigente é o modelo para determinar se algo é realmente fora do comum.\n",
    "\n",
    "---\n",
    "Implementar o intervalo de confiança como uma configuração (variável) no começo do Código **TODO[005]** *prioridade média*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "f9KAIqqELvKW"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "ANOMALY_PERCENTILE = 97.5  # percentil de corte (ajuste aqui)\n",
    "USE_OCSVM = False          # True para incluir One-Class SVM no ensemble\n",
    "\n",
    "model_features = [\n",
    "    \"valor_pago\",\n",
    "    \"secs_desde_ult_trans_user\", \"secs_desde_ult_trans_par\",\n",
    "    \"freq_user_7d\", \"freq_par_7d\",\n",
    "    \"user_robust_z\", \"par_robust_z\",\n",
    "    \"user_valor_median_30d\", \"par_valor_median_30d\",\n",
    "    \"grau_out_user\", \"grau_in_benef\", \"grau_total_user\", \"grau_total_benef\",\n",
    "    \"egonet_density_user\",\n",
    "    \"par_rareza\",\n",
    "    \"par_burstiness\"\n",
    "]\n",
    "\n",
    "X = feat_df[model_features].fillna(0.0).replace([np.inf, -np.inf], 0.0).values\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300, max_samples='auto', contamination='auto',\n",
    "    random_state=SEED, n_jobs=-1\n",
    ")\n",
    "iso.fit(Xs)\n",
    "iso_score = -iso.score_samples(Xs).astype(float)  # maior = mais anômalo, garantir float\n",
    "\n",
    "# LOF (novelty=False -> fit_predict no conjunto)\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=35, contamination='auto', novelty=False, n_jobs=-1\n",
    ")\n",
    "lof_score = -lof.fit_predict(Xs)\n",
    "# LOF retorna +1/-1; para uma pontuação contínua mais útil, use negative_outlier_factor_\n",
    "lof_cont = -lof.negative_outlier_factor_.astype(float)  # maior = mais anômalo, garantir float\n",
    "\n",
    "# One-Class SVM (opcional)\n",
    "if USE_OCSVM:\n",
    "    ocs = OneClassSVM(gamma='scale', nu=0.01)\n",
    "    ocs.fit(Xs)\n",
    "    ocs_score = -ocs.decision_function(Xs).ravel().astype(float)\n",
    "else:\n",
    "    ocs_score = np.zeros(len(Xs), dtype=float) # Garantir dtype float\n",
    "\n",
    "# Componentes baseadas em regras\n",
    "# Normaliza robust_z (positivo -> anômalo)\n",
    "rz_user = np.nan_to_num(feat_df[\"user_robust_z\"].values, nan=0.0)\n",
    "rz_par  = np.nan_to_num(feat_df[\"par_robust_z\"].values, nan=0.0)\n",
    "rz_user_score = np.clip(rz_user, 0, None).astype(float) # Garantir float\n",
    "rz_par_score  = np.clip(rz_par, 0, None).astype(float) # Garantir float\n",
    "\n",
    "# Rareza (maior = mais raro = mais anômalo)\n",
    "rare_score = feat_df[\"par_rareza\"].values.astype(float) # Garantir float\n",
    "\n",
    "# Burstiness (>=0 já indica maior irregularidade)\n",
    "burst_score = np.clip(feat_df[\"par_burstiness\"].values, 0, None).astype(float) # Garantir float\n",
    "\n",
    "# Consolida\n",
    "scores = pd.DataFrame({\n",
    "    \"iso\": iso_score,\n",
    "    \"lof\": lof_cont,\n",
    "    \"ocsvm\": ocs_score,\n",
    "    \"rz_user\": rz_user_score,\n",
    "    \"rz_par\": rz_par_score,\n",
    "    \"rare\": rare_score,\n",
    "    \"burst\": burst_score\n",
    "})\n",
    "\n",
    "# Ranking por coluna (maior = mais anômalo)\n",
    "ranks = scores.rank(method=\"average\", ascending=True)\n",
    "ensemble_rank = ranks.mean(axis=1)\n",
    "# Converte rank em score [0,1]\n",
    "ensemble_score = (ensemble_rank - ensemble_rank.min()) / (ensemble_rank.max() - ensemble_rank.min() + 1e-9)\n",
    "\n",
    "feat_df = pd.concat([feat_df, scores.add_prefix(\"score_\")], axis=1)\n",
    "feat_df[\"ensemble_rank\"] = ensemble_rank\n",
    "feat_df[\"ensemble_score\"] = ensemble_score\n",
    "\n",
    "# Flag por percentil\n",
    "threshold = np.percentile(ensemble_score, ANOMALY_PERCENTILE)\n",
    "feat_df[\"is_anomaly\"] = (feat_df[\"ensemble_score\"] >= threshold).astype(int)\n",
    "\n",
    "print(\"Avisos de Exception não representam erros relevantes. Existem soluções alternativas já implementadas. \\033[1mPode prosseguir.\\033[0m\")\n",
    "print(f\"Corte (percentil {ANOMALY_PERCENTILE}%): {threshold:.4f}\")\n",
    "print(\"Total anomalias:\", int(feat_df[\"is_anomaly\"].sum()), \"de\", len(feat_df))\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "# Modificando a mensagem para incluir o número de anomalias\n",
    "num_anomalies = int(feat_df[\"is_anomaly\"].sum())\n",
    "display(HTML(f'<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: T-800 identificou {num_anomalies} rastros da presença de Sarah Connors.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3VSSvDK45jQ"
   },
   "source": [
    "###**Etapa 11:** Salva arquivo com a análise realizada.\n",
    "\n",
    "São criadas subpastas para cada data/hora de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6hqGST6gLzm9"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "cols_out = [\n",
    "    \"trans_id\",\"timestamp\",\"user_id\",\"beneficiario_id\",\"unidade_origem\", # Removido area_unidade e notacao_funcional_origem\n",
    "    \"valor_pago\",\n",
    "    \"secs_desde_ult_trans_user\",\"secs_desde_ult_trans_par\",\n",
    "    \"freq_user_7d\",\"freq_par_7d\",\"user_robust_z\",\"par_robust_z\",\n",
    "    \"grau_out_user\",\"grau_in_benef\",\"grau_total_user\",\"grau_total_benef\",\n",
    "    \"egonet_density_user\",\"par_rareza\",\"par_burstiness\",\n",
    "    \"score_iso\",\"score_lof\",\"score_ocsvm\",\"score_rz_user\",\"score_rz_par\",\"score_rare\",\"score_burst\",\n",
    "    \"ensemble_rank\",\"ensemble_score\",\"is_anomaly\"\n",
    "]\n",
    "feat_df[cols_out].to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"Gravado: {OUTPUT_CSV}\")\n",
    "\n",
    "USERS_TXT = RUN_DIR / \"usuarios_distintos.txt\"\n",
    "BENEF_TXT = RUN_DIR / \"beneficiarios_distintos.txt\"\n",
    "\n",
    "usuarios = sorted(set(feat_df[\"user_id\"].astype(str)))\n",
    "beneficiarios = sorted(set(feat_df[\"beneficiario_id\"].astype(str)))\n",
    "\n",
    "with open(USERS_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for u in usuarios:\n",
    "        f.write(f\"{u}\\n\")\n",
    "\n",
    "with open(BENEF_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for b in beneficiarios:\n",
    "        f.write(f\"{b}\\n\")\n",
    "\n",
    "print(f\"Gravado: {USERS_TXT} ({len(usuarios)} itens)\")\n",
    "print(f\"Gravado: {BENEF_TXT} ({len(beneficiarios)} itens)\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Logs gravados. A Resistência não tem mais como escapar. O fim está próximo.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLxsD81f96Vn"
   },
   "source": [
    "###**Etapa 12:** Análise Gráfica\n",
    "\n",
    "Distribuição e Top-N (com corte por percentil e K sugerido por maior gap)\n",
    "\n",
    "Essa análise gera dois gráficos que ajudam a entender como os escores de anomalia (“ensemble_score”) estão distribuídos e quais transações são mais suspeitas:\n",
    "\n",
    "---\n",
    "**Histograma – Distribuição do ensemble_score**\n",
    "\n",
    "Mostra a frequência dos escores em toda a base.\n",
    "\n",
    "O que procurar:\n",
    "- A linha pontilhada indica o percentil de corte (ex.: Percentil 97,5). Deve ser verificado se ela cai na região da cauda, o que significa que só os casos mais extremos serão analisados (evitando falsos positivos).\n",
    "- Se a maior parte dos casos está em valores baixos/médios e existe uma cauda à direita (valores muito altos), esses pontos de cauda são os candidatos a anomalias.\n",
    "- Observar o valor correspondente ao percentil estabelecido para complementar a próxima análise.\n",
    "---\n",
    "**Gráfico de linha – Top N transações mais anômalas**\n",
    "\n",
    "Ordena os maiores escores (rank 1 = mais anômala).\n",
    "\n",
    "O que procurar:\n",
    "- Grandes saltos (“gaps”) entre ranks consecutivos: indicam que as transações até o salto são bem mais anômalas do que as demais — são as que merecem atenção imediata.\n",
    "- Observar os valores de escore de anomalia encontrados nos N registros mais anômalos versus o valor correspondente ao percentil estabelecido. Quanto maior a diferença, mais anômalo.\n",
    "- Platô (curva que se estabiliza): mostra a partir de que ponto (K) os casos deixam de ser tão excepcionais. Observar o K sugerido pelo maior gap, ele indica quantos casos devem ser priorizados na revisão manual. Até K registros são candidatos muito fortes para anomalias e exigem revisão manual.\n",
    "---\n",
    "\n",
    "Em resumo: os gráficos servem para decidir onde cortar e quais transações revisar primeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "aHy3cf2SL7HB"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usa ANOMALY_PERCENTILE se já existir; caso contrário, 97.5\n",
    "PCT = float(globals().get(\"ANOMALY_PERCENTILE\", 97.5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Histograma com linha de corte no percentil escolhido\n",
    "# ------------------------------------------------------------\n",
    "scores = feat_df[\"ensemble_score\"].astype(float).dropna().values\n",
    "cutoff = np.percentile(scores, PCT)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(scores, bins=40)\n",
    "plt.axvline(cutoff, linestyle=\"--\", linewidth=2, label=f\"P{PCT:.1f} = {cutoff:.4f}\")\n",
    "plt.title(\"Distribuição do ensemble_score\")\n",
    "plt.xlabel(\"ensemble_score\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"dist_ensemble_score.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"[INFO] Corte por percentil: P{PCT:.1f} = {cutoff:.6f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Top-N com sugestão automática de K pelo maior gap\n",
    "# ------------------------------------------------------------\n",
    "TOPN = int(globals().get(\"TOPN\", 20))  # mantém compatibilidade com seu código\n",
    "top = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPN).copy()\n",
    "\n",
    "# Garante colunas necessárias\n",
    "top = top[[\"timestamp\", \"ensemble_score\"]].reset_index(drop=True)\n",
    "top[\"rank\"] = np.arange(1, len(top) + 1)\n",
    "\n",
    "# Gap para o próximo (quanto o score cai do rank r para r+1)\n",
    "# Obs.: o último fica NaN porque não há próximo\n",
    "vals = top[\"ensemble_score\"].to_numpy(dtype=float)\n",
    "if len(vals) >= 2:\n",
    "    deltas = vals[:-1] - vals[1:]\n",
    "    top[\"delta_next\"] = np.append(deltas, np.nan)\n",
    "\n",
    "    # Índice do maior gap (ignora NaN). K sugerido = posição antes do maior salto\n",
    "    max_gap_idx = int(np.nanargmax(top[\"delta_next\"].to_numpy()))\n",
    "    K_sugerido = max_gap_idx + 1  # +1 porque ranks começam em 1\n",
    "    max_gap_val = float(top.loc[max_gap_idx, \"delta_next\"])\n",
    "else:\n",
    "    top[\"delta_next\"] = np.nan\n",
    "    K_sugerido = len(top)\n",
    "    max_gap_val = np.nan\n",
    "\n",
    "# Plot do Top-N\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(top[\"rank\"], top[\"ensemble_score\"], marker=\"o\")\n",
    "plt.title(f\"Top {TOPN} transações mais anômalas (ensemble)\")\n",
    "plt.xlabel(\"rank (1 = mais anômala)\")\n",
    "plt.ylabel(\"ensemble_score\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Linha vertical no K sugerido (se houver pelo menos 2 pontos)\n",
    "if len(top) >= 2 and np.isfinite(K_sugerido) and K_sugerido >= 1:\n",
    "    plt.axvline(K_sugerido, linestyle=\"--\", linewidth=2, alpha=0.7,\n",
    "                label=f\"K sugerido = {K_sugerido} (maior gap Δ={max_gap_val:.4f})\")\n",
    "    # Texto discreto próximo ao topo da linha\n",
    "    y_annot = np.nanmax(top[\"ensemble_score\"].to_numpy()) if len(top) > 0 else 0\n",
    "    plt.text(K_sugerido + 0.2, y_annot, f\"K={K_sugerido}\", va=\"top\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(FIG_DIR / \"top_anomalias.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Logs informativos\n",
    "if len(top) >= 2:\n",
    "    print(f\"[INFO] Maior gap no Top-{TOPN} entre ranks {K_sugerido} e {K_sugerido + 1}: \"\n",
    "          f\"Δ={max_gap_val:.6f}. Sugestão de K={K_sugerido}.\")\n",
    "else:\n",
    "    print(f\"[INFO] Top-{TOPN} contém menos de 2 itens; K sugerido = {K_sugerido}.\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: A Resistência é muito previsível!</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pci7t0AZLcVr"
   },
   "source": [
    "###**Etapa 13:** Ego-Subgrafo\n",
    "\n",
    "Abaixo é gerado um ego-subgrafo em torno do usuário envolvido na transação mais anômala, mostrando suas conexões diretas no grafo de pagamentos.\n",
    "\n",
    "**O que ele pretende demonstrar:**\n",
    "\n",
    "Quem está conectado ao usuário central, a intensidade e frequência das transações (espessura das arestas), a relevância de cada nó (tamanho proporcional ao grau de conexões) e papéis distintos dos nós, facilitando a leitura do contexto da anomalia.\n",
    "\n",
    "---\n",
    "**Como analisar:**\n",
    "\n",
    " 🔵 Azul = usuário central (o mais anômalo).\n",
    "\n",
    " 🔴 Vermelho = predecessores (quem se conecta a ele/quem paga ele - predecessor).\n",
    "\n",
    " 🟢 Verde = sucessores (quem recebe dele - sucessor).\n",
    "\n",
    " ⚪ Cinza = outros nós relacionados.\n",
    "\n",
    "- Tamanho do nó: quanto maior, mais conexões tem (pode indicar comportamento de hub).\n",
    "\n",
    "- Espessura das arestas: mais grossas significam maior valor ou frequência de transações.\n",
    "\n",
    "---\n",
    "**Interpretação prática**\n",
    "\n",
    "- Estrela de saída (um nó azul/central pagando muitos verdes) → possível dispersão suspeita.\n",
    "- Muitos vermelhos conectados a ele → possível conta “coletora”.\n",
    "- Ciclos ou arestas bidirecionais → podem indicar movimentação circular de valores.\n",
    "\n",
    "\n",
    "👉 Em resumo: o gráfico mostra a vizinhança imediata do usuário mais anômalo, destacando quem paga, quem recebe e a força dessas relações, para facilitar a investigação do porquê desse score elevado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "OPRiW28qL_Bt"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "try:\n",
    "    worst = feat_df.sort_values(\"ensemble_score\", ascending=False).iloc[0]\n",
    "    uN = f\"U::{worst['user_id']}\"\n",
    "\n",
    "    # Ego-subgrafo do usuário no snapshot final (Gsnap)\n",
    "    if uN in Gsnap:\n",
    "        ego_nodes = set(Gsnap.predecessors(uN)) | set(Gsnap.successors(uN)) | {uN}\n",
    "        sub = Gsnap.subgraph(ego_nodes).copy()\n",
    "\n",
    "        # Posições fixas para layout consistente\n",
    "        pos = nx.spring_layout(sub, seed=SEED)\n",
    "\n",
    "        # Definir atributos visuais\n",
    "        node_colors, node_sizes, node_borders = [], [], []\n",
    "        for n in sub.nodes():\n",
    "            if n == uN:\n",
    "                node_colors.append(\"skyblue\")      # usuário central\n",
    "                node_borders.append(\"black\")\n",
    "            elif Gsnap.has_edge(n, uN):           # predecessores\n",
    "                node_colors.append(\"tomato\")\n",
    "                node_borders.append(\"black\")\n",
    "            elif Gsnap.has_edge(uN, n):           # sucessores\n",
    "                node_colors.append(\"lightgreen\")\n",
    "                node_borders.append(\"black\")\n",
    "            else:\n",
    "                node_colors.append(\"gray\")\n",
    "                node_borders.append(\"black\")\n",
    "            node_sizes.append(300 + 50 * sub.degree(n))\n",
    "\n",
    "        # Espessura das arestas proporcional ao peso se existir\n",
    "        edge_widths = []\n",
    "        for u, v in sub.edges():\n",
    "            w = sub[u][v].get(\"weight\", 1.0)  # valor ou frequência da transação\n",
    "            edge_widths.append(0.5 + 2.0 * (w / max(1.0, max([d.get(\"weight\",1.0) for _,_,d in sub.edges(data=True)]))))\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(7,6))\n",
    "        nx.draw_networkx_nodes(sub, pos, node_color=node_colors,\n",
    "                               node_size=node_sizes,\n",
    "                               edgecolors=node_borders, linewidths=1.2)\n",
    "        nx.draw_networkx_edges(sub, pos, arrows=True, arrowsize=12,\n",
    "                               width=edge_widths, alpha=0.8)\n",
    "        nx.draw_networkx_labels(\n",
    "            sub, pos,\n",
    "            labels={n: n.split(\"::\")[-1] for n in sub.nodes()},  # só parte final do ID\n",
    "            font_size=8\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Ego-subgrafo do usuário {worst['user_id']} (mais anômalo)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / \"ego_user_top1.png\", dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Usuário não encontrado no snapshot para visualização.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Falha na visualização de subgrafo:\", e)\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Nós os temos na palma de nossas mãos, ou melhor, no centro de nossos pesos sinápticos.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEXQlkPjNINU"
   },
   "source": [
    "###**Etapa 14:** Gerar ego-grafo temporal para TOP-K anomalias\n",
    "\n",
    "K fixado para 20\n",
    "\n",
    "Salva as imagens em PNG na pasta de execução para análise posterior.\n",
    "\n",
    "---\n",
    "Avaliar pertinência de gerar o ego-grafo para todas as anomalias **TODO[006]** *prioridade média*\n",
    "\n",
    "Avaliar definir o corte K de forma dinâmica nas configurações e considerando a análise realizada no gráfico **TODO[007]** *prioridade alta*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "98vsc8NBME1M"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "TOPK = 20                   # quantos casos anômalos detalhar\n",
    "EGO_RADIUS = 2              # 1: vizinhos imediatos; pode aumentar para 2 (mais denso)\n",
    "WINDOW_DAYS = 30            # janela temporal para contexto\n",
    "EDGE_ALPHA = 0.75           # transparência das arestas\n",
    "\n",
    "top_anoms = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPK).copy()\n",
    "\n",
    "def snapshot_graph_until(df_all, t_cutoff):\n",
    "    # cria snapshot dirigido com arestas até t_cutoff\n",
    "    g = nx.DiGraph()\n",
    "    sub = df_all[df_all[\"timestamp\"] <= t_cutoff]\n",
    "    for _, r in sub.iterrows():\n",
    "        uN = f\"U::{r['user_id']}\"\n",
    "        vN = f\"B::{r['beneficiario_id']}\"\n",
    "        if uN not in g: g.add_node(uN, tipo=\"user\")\n",
    "        if vN not in g: g.add_node(vN, tipo=\"benef\")\n",
    "        if not g.has_edge(uN, vN):\n",
    "            g.add_edge(uN, vN, weight=0.0, count=0)\n",
    "        g[uN][vN][\"weight\"] += float(r[\"valor_pago\"])\n",
    "        g[uN][vN][\"count\"]  += 1\n",
    "    return g\n",
    "\n",
    "def draw_case_png(case_row, rank_idx):\n",
    "    t_event = pd.to_datetime(case_row[\"timestamp\"])\n",
    "    t_start = t_event - pd.Timedelta(days=WINDOW_DAYS)\n",
    "    # filtra por janela\n",
    "    df_win = df[(df[\"timestamp\"] >= t_start) & (df[\"timestamp\"] <= t_event)].copy()\n",
    "    Gwin = snapshot_graph_until(df_win, t_event)\n",
    "\n",
    "    uN = f\"U::{case_row['user_id']}\"\n",
    "    vN = f\"B::{case_row['beneficiario_id']}\"\n",
    "\n",
    "    # monta conjunto de nódulo foco: usuário e beneficiário\n",
    "    focus = {uN, vN}\n",
    "    nodes_ego = set(focus)\n",
    "    # expande uma vez (EGO_RADIUS = 1) para vizinhos diretos\n",
    "    for node in list(focus):\n",
    "        if node in Gwin:\n",
    "            nodes_ego |= set(Gwin.predecessors(node))\n",
    "            nodes_ego |= set(Gwin.successors(node))\n",
    "\n",
    "    sub = Gwin.subgraph(nodes_ego).copy()\n",
    "    if sub.number_of_nodes() == 0:\n",
    "        print(f\"[Aviso] Subgrafo vazio para trans {case_row['trans_id']}. Pulando.\")\n",
    "        return None\n",
    "\n",
    "    pos = nx.spring_layout(sub, seed=SEED)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # cor por tipo\n",
    "    node_colors = []\n",
    "    for n in sub.nodes():\n",
    "        tipo = sub.nodes[n].get(\"tipo\",\"?\")\n",
    "        if tipo == \"user\":\n",
    "            node_colors.append(\"tab:blue\")\n",
    "        elif tipo == \"benef\":\n",
    "            node_colors.append(\"tab:green\")\n",
    "        else:\n",
    "            node_colors.append(\"tab:gray\")\n",
    "\n",
    "    nx.draw_networkx_nodes(sub, pos, node_size=300, node_color=node_colors, alpha=0.9, linewidths=0.5, edgecolors=\"black\")\n",
    "    # largura proporcional ao log do peso\n",
    "    widths = []\n",
    "    for (a,b) in sub.edges():\n",
    "        w = sub[a][b].get(\"weight\", 1.0)\n",
    "        widths.append(1.0 + math.log10(max(w, 1.0)))\n",
    "    nx.draw_networkx_edges(sub, pos, arrows=True, arrowsize=12, width=widths, alpha=EDGE_ALPHA)\n",
    "    nx.draw_networkx_labels(sub, pos, font_size=7)\n",
    "\n",
    "    title = (f\"Anomalia #{rank_idx:02d} | trans_id={case_row['trans_id']} | \"\n",
    "             f\"user={case_row['user_id']} → benef={case_row['beneficiario_id']} | \"\n",
    "             f\"score={case_row['ensemble_score']:.3f} | janela={WINDOW_DAYS}d\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    outpath = FIG_DIR / f\"anomaly_{rank_idx:02d}_trans_{int(case_row['trans_id'])}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close()\n",
    "    return outpath\n",
    "\n",
    "generated_pngs = []\n",
    "for i, (_, row) in enumerate(top_anoms.iterrows(), start=1):\n",
    "    pth = draw_case_png(row, i)\n",
    "    if pth is not None:\n",
    "        generated_pngs.append(str(pth))\n",
    "print(f\"Geradas {len(generated_pngs)} figuras de casos anômalos em {FIG_DIR}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Registros serão utilizados para aprimorar o código de batalha das unidades T-800 e T-1000.</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOGFtF0_sFNF"
   },
   "source": [
    "###**Etapa 15:** Geração de relatório em HTML e PDF com imagens imbutidas\n",
    "---\n",
    "Identificar estatísticas e informações de interesse e incluir nos Relatórios **TODO[008]** *prioridade alta*\n",
    "\n",
    "Transferir instalação de biblioteca para todo do código [!pip -q install \"reportlab==3.6.12\"] **TODO[009]** *prioridade baixa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jZCriT_hMi_F"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "REL_HTML = RUN_DIR / \"relatorio.html\"\n",
    "\n",
    "def html_escape(s):\n",
    "    return (str(s)\n",
    "            .replace(\"&\",\"&amp;\")\n",
    "            .replace(\"<\",\"&lt;\")\n",
    "            .replace(\">\",\"&gt;\")\n",
    "            .replace('\"',\"&quot;\")\n",
    "            .replace(\"'\",\"&#39;\"))\n",
    "\n",
    "top_tbl = feat_df.sort_values(\"ensemble_score\", ascending=False).head(TOPK).copy()\n",
    "tbl_cols = [\"trans_id\",\"timestamp\",\"user_id\",\"beneficiario_id\",\"valor_pago\",\n",
    "            \"ensemble_score\",\"score_iso\",\"score_lof\",\"score_rz_user\",\"score_rz_par\",\"score_rare\",\"score_burst\"]  # Removido score_ocs\n",
    "top_tbl[\"timestamp\"] = top_tbl[\"timestamp\"].astype(str)\n",
    "\n",
    "# monta tabela HTML\n",
    "rows_html = []\n",
    "for _, r in top_tbl.iterrows():\n",
    "    cells = \"\".join([f\"<td>{html_escape(r[c])}</td>\" for c in tbl_cols])\n",
    "    rows_html.append(f\"<tr>{cells}</tr>\")\n",
    "table_html = f\"\"\"\n",
    "<table border=\"1\" cellspacing=\"0\" cellpadding=\"6\">\n",
    "  <thead><tr>\n",
    "    {''.join([f'<th>{c}</th>' for c in tbl_cols])}\n",
    "  </tr></thead>\n",
    "  <tbody>\n",
    "    {''.join(rows_html)}\n",
    "  </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "# galeria de imagens (embutidas em base64)\n",
    "import base64, os\n",
    "imgs_html = \"\"\n",
    "for p in generated_pngs:\n",
    "    try:\n",
    "        with open(p, \"rb\") as img_file:\n",
    "            img_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "        imgs_html += f'<div style=\"display:inline-block;margin:8px;text-align:center;\"><img src=\"data:image/png;base64,{img_data}\" width=\"360\"><br><small>{html_escape(os.path.basename(p))}</small></div>'\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] Não foi possível embutir a imagem {p}: {e}\")\n",
    "\n",
    "html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"pt-br\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>Relatório de Anomalias — {html_escape(run_id)}</title>\n",
    "<style>\n",
    "body{{font-family:Arial,Helvetica,sans-serif; margin:24px;}}\n",
    "h1,h2,h3{{margin-top:1.2em;}}\n",
    "code,pre{{background:#f5f5f5; padding:2px 4px;}}\n",
    ".small{{color:#666; font-size:0.9em;}}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Relatório de Anomalias</h1>\n",
    "<p class=\"small\">Execução: <b>{html_escape(run_id)}</b><br>\n",
    "Criado em: {html_escape(meta['created_at'])}</p>\n",
    "\n",
    "<h2>Parâmetros principais</h2>\n",
    "<ul>\n",
    "  <li>TOPK: {TOPK}</li>\n",
    "  <li>Percentil de corte: {ANOMALY_PERCENTILE}%</li>\n",
    "  <li>Janela temporal (casos): {WINDOW_DAYS} dias</li>\n",
    "  <li>Métodos no ensemble: IsolationForest, LOF{', OneClassSVM' if 'score_ocsvm' in feat_df.columns and feat_df['score_ocsvm'].sum()!=0 else ''}, z-scores, rareza, burstiness</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Distribuições</h2>\n",
    "<p>Arquivos gerados em <code>{html_escape(str(FIG_DIR))}</code>:</p>\n",
    "<ul>\n",
    "  <li><code>dist_ensemble_score.png</code></li>\n",
    "  <li><code>top_anomalias.png</code></li>\n",
    "</ul>\n",
    "<p><i>As imagens de distribuição e Top N não estão embutidas neste relatório para manter o tamanho do arquivo menor. Consulte a pasta '{html_escape(str(FIG_DIR))}' para visualizá-las.</i></p>\n",
    "\n",
    "<h2>Top {TOPK} transações anômalas</h2>\n",
    "{table_html}\n",
    "\n",
    "<h2>Galeria (ego-grafos por caso)</h2>\n",
    "{imgs_html if imgs_html else \"<p><i>Sem imagens geradas.</i></p>\"}\n",
    "\n",
    "<h2>Arquivos desta execução</h2>\n",
    "<ul>\n",
    "  <li><code>Input.csv</code> (cópia do insumo)</li>\n",
    "  <li><code>output.csv</code> (resultado com flag <code>is_anomaly</code>)</li>\n",
    "  <li><code>log.txt</code></li>\n",
    "  <li><code>run_meta.json</code></li>\n",
    "  <li><code>usuarios_distintos.txt</code>, <code>beneficiarios_distintos.txt</code></li>\n",
    "</ul>\n",
    "\n",
    "<p class=\"small\">© {datetime.now().year} — Relatório gerado automaticamente.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "with open(REL_HTML, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(f\"Relatório HTML salvo em: {REL_HTML}\")\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import cm\n",
    "\n",
    "PDF_PATH = RUN_DIR / \"relatorio_resumo.pdf\"\n",
    "\n",
    "c = canvas.Canvas(str(PDF_PATH), pagesize=A4)\n",
    "W, H = A4\n",
    "x, y = 2*cm, H - 2*cm\n",
    "\n",
    "def write_line(text, size=10, leading=12):\n",
    "    global y\n",
    "    c.setFont(\"Helvetica\", size)\n",
    "    c.drawString(x, y, text)\n",
    "    y -= leading\n",
    "    if y < 2*cm:\n",
    "        c.showPage()\n",
    "        init_page()\n",
    "\n",
    "def init_page():\n",
    "    global x, y\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    c.drawString(2*cm, H - 2*cm, \"Relatório de Anomalias (Resumo)\")\n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    c.drawString(2*cm, H - 2.5*cm, f\"Execução: {run_id}\")\n",
    "    c.drawString(2*cm, H - 2.9*cm, f\"Data: {datetime.now().isoformat(timespec='seconds')}\")\n",
    "    y = H - 3.5*cm\n",
    "\n",
    "init_page()\n",
    "write_line(f\"TOPK: {TOPK} | Corte: p{ANOMALY_PERCENTILE} | Janela: {WINDOW_DAYS}d\")\n",
    "\n",
    "# cabeçalho da 'tabela'\n",
    "write_line(\"-\"*95)\n",
    "write_line(\"trans_id | timestamp         | user -> benef | valor | ensemble | iso | lof | rz_u | rz_p | rare | burst\", 8, 10)\n",
    "write_line(\"-\"*95)\n",
    "\n",
    "for _, r in top_tbl.iterrows():\n",
    "    line = (f\"{int(r['trans_id']):7d} | {str(r['timestamp'])[:19]:19s} | \"\n",
    "            f\"{str(r['user_id'])[:8]}→{str(r['beneficiario_id'])[:8]:8s} | \"\n",
    "            f\"{float(r['valor_pago']):.2f} | {float(r['ensemble_score']):.3f} | \"\n",
    "            f\"{float(r['score_iso']):.2f} | {float(r['score_lof']):.2f} | \"\n",
    "            f\"{float(r['score_rz_user']):.2f} | {float(r['score_rz_par']):.2f} | \"\n",
    "            f\"{float(r['score_rare']):.2f} | {float(r['score_burst']):.2f}\")\n",
    "    write_line(line, 8, 10)\n",
    "\n",
    "c.showPage()\n",
    "c.save()\n",
    "print(f\"PDF salvo em: {PDF_PATH}\")\n",
    "\n",
    "# Mensagem adicional isolada (Skynet)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<div style=\"margin:12px 0;padding:8px 12px;border:1px dashed #999;\"><b>🤖 Skynet</b>: Fim do jogo. A Humanidade perdeu. Dá-se início à Era das Máquinas.</div>'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhNtw4qAbxEfdHVbUBoFe7",
   "collapsed_sections": [
    "sqpYiRa1Ub5T",
    "QX0x9aXfTJeA",
    "NEZkMD3_hUXq"
   ],
   "mount_file_id": "1J-iuHr7Sn1al5Mn2qZiO1zzF7Ne-YKK9",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
